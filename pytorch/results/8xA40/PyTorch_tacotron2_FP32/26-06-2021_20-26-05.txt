train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 20:26:07.165690 - PARAMETER output : ./ 
DLL 2021-06-26 20:26:07.165770 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 20:26:07.165798 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 20:26:07.165819 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 20:26:07.165839 - PARAMETER anneal_steps : None 
DLL 2021-06-26 20:26:07.165862 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 20:26:07.165881 - PARAMETER epochs : 2 
DLL 2021-06-26 20:26:07.165900 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 20:26:07.165918 - PARAMETER checkpoint_path :  
DLL 2021-06-26 20:26:07.165938 - PARAMETER resume_from_last : False 
DLL 2021-06-26 20:26:07.165958 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 20:26:07.165978 - PARAMETER amp : False 
DLL 2021-06-26 20:26:07.165997 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 20:26:07.166016 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 20:26:07.166034 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 20:26:07.166051 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 20:26:07.166068 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 20:26:07.166087 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 20:26:07.166106 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 20:26:07.166124 - PARAMETER batch_size : 136 
DLL 2021-06-26 20:26:07.166142 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 20:26:07.166159 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 20:26:07.166177 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-06-26 20:26:07.166194 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 20:26:07.166211 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 20:26:07.166232 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 20:26:07.166249 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 20:26:07.166266 - PARAMETER filter_length : 1024 
DLL 2021-06-26 20:26:07.166283 - PARAMETER hop_length : 256 
DLL 2021-06-26 20:26:07.166300 - PARAMETER win_length : 1024 
DLL 2021-06-26 20:26:07.166316 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 20:26:07.166333 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 20:26:07.166350 - PARAMETER rank : 0 
DLL 2021-06-26 20:26:07.166367 - PARAMETER world_size : 8 
DLL 2021-06-26 20:26:07.166386 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 20:26:07.166403 - PARAMETER group_name : group_name 
DLL 2021-06-26 20:26:07.166419 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 20:26:07.166436 - PARAMETER bench_class :  
DLL 2021-06-26 20:26:07.166454 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 20:26:35.465062 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-06-26 20:27:10.159526 - (0, 0) train_loss : 46.91067886352539 
DLL 2021-06-26 20:27:15.182670 - (0, 0) train_items_per_sec : 15514.940798230165 
DLL 2021-06-26 20:27:15.182761 - (0, 0) train_iter_time : 39.71765074799987 
DLL 2021-06-26 20:27:15.243301 - (0,) train_items_per_sec : 15514.940798230165 
DLL 2021-06-26 20:27:15.243393 - (0,) train_loss : 46.91067886352539 
DLL 2021-06-26 20:27:15.243616 - (0,) train_epoch_time : 42.5681439559994 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 20:27:16.366042 - (0, 1, 0) val_items_per_sec : 94470.94947572604 
DLL 2021-06-26 20:27:16.460625 - (0,) val_loss : 48.146995544433594 
DLL 2021-06-26 20:27:16.460727 - (0,) val_items_per_sec : 94470.94947572604 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-06-26 20:27:19.885382 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-06-26 20:27:25.716657 - (1, 0) train_loss : 47.131935119628906 
DLL 2021-06-26 20:27:28.236090 - (1, 0) train_items_per_sec : 74154.03677300937 
DLL 2021-06-26 20:27:28.236183 - (1, 0) train_iter_time : 8.350765877999947 
DLL 2021-06-26 20:27:28.327552 - (1,) train_items_per_sec : 74154.03677300937 
DLL 2021-06-26 20:27:28.327657 - (1,) train_loss : 47.131935119628906 
DLL 2021-06-26 20:27:28.327689 - (1,) train_epoch_time : 11.139649623000878 
DLL 2021-06-26 20:27:29.550424 - (1, 2, 0) val_items_per_sec : 87358.64373989198 
DLL 2021-06-26 20:27:29.657274 - (1,) val_loss : 48.147064208984375 
DLL 2021-06-26 20:27:29.657381 - (1,) val_items_per_sec : 87358.64373989198 
DLL 2021-06-26 20:27:29.659758 - () run_time : 73.36584812699948 
DLL 2021-06-26 20:27:29.659801 - () val_loss : 48.147064208984375 
DLL 2021-06-26 20:27:29.659828 - () train_items_per_sec : 74154.03677300937 
DONE!
