train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 19:26:45.426004 - PARAMETER output : ./ 
DLL 2021-06-26 19:26:45.426077 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 19:26:45.426104 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 19:26:45.426125 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 19:26:45.426144 - PARAMETER anneal_steps : None 
DLL 2021-06-26 19:26:45.426164 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 19:26:45.426183 - PARAMETER epochs : 2 
DLL 2021-06-26 19:26:45.426202 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 19:26:45.426220 - PARAMETER checkpoint_path :  
DLL 2021-06-26 19:26:45.426237 - PARAMETER resume_from_last : False 
DLL 2021-06-26 19:26:45.426257 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 19:26:45.426276 - PARAMETER amp : False 
DLL 2021-06-26 19:26:45.426294 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 19:26:45.426312 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 19:26:45.426328 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 19:26:45.426345 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 19:26:45.426362 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 19:26:45.426379 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 19:26:45.426398 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 19:26:45.426415 - PARAMETER batch_size : 148 
DLL 2021-06-26 19:26:45.426433 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 19:26:45.426450 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 19:26:45.426467 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_2500_filelist.txt 
DLL 2021-06-26 19:26:45.426483 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 19:26:45.426500 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 19:26:45.426520 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 19:26:45.426537 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 19:26:45.426553 - PARAMETER filter_length : 1024 
DLL 2021-06-26 19:26:45.426569 - PARAMETER hop_length : 256 
DLL 2021-06-26 19:26:45.426585 - PARAMETER win_length : 1024 
DLL 2021-06-26 19:26:45.426602 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 19:26:45.426618 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 19:26:45.426635 - PARAMETER rank : 0 
DLL 2021-06-26 19:26:45.426652 - PARAMETER world_size : 8 
DLL 2021-06-26 19:26:45.426668 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 19:26:45.426684 - PARAMETER group_name : group_name 
DLL 2021-06-26 19:26:45.426700 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 19:26:45.426716 - PARAMETER bench_class :  
DLL 2021-06-26 19:26:45.426733 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 19:27:15.011415 - (0, 0) glob_iter/iters_per_epoch : 0/2 
DLL 2021-06-26 19:27:52.883647 - (0, 0) train_loss : 46.78305435180664 
DLL 2021-06-26 19:27:56.059368 - (0, 0) train_items_per_sec : 16363.743317747241 
DLL 2021-06-26 19:27:56.059458 - (0, 0) train_iter_time : 41.04800392899779 
DLL 2021-06-26 19:27:56.078059 - (0, 1) glob_iter/iters_per_epoch : 1/2 
DLL 2021-06-26 19:28:05.388050 - (0, 1) train_loss : 46.4892463684082 
DLL 2021-06-26 19:28:08.213017 - (0, 1) train_items_per_sec : 54947.63631826042 
DLL 2021-06-26 19:28:08.213106 - (0, 1) train_iter_time : 12.134971486997529 
DLL 2021-06-26 19:28:08.271711 - (0,) train_items_per_sec : 35655.689818003826 
DLL 2021-06-26 19:28:08.271814 - (0,) train_loss : 46.4892463684082 
DLL 2021-06-26 19:28:08.271844 - (0,) train_epoch_time : 56.151881060999585 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 19:28:09.429330 - (0, 2, 0) val_items_per_sec : 90043.87030584877 
DLL 2021-06-26 19:28:09.502001 - (0,) val_loss : 48.224510192871094 
DLL 2021-06-26 19:28:09.502090 - (0,) val_items_per_sec : 90043.87030584877 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-26 19:28:13.070512 - (1, 0) glob_iter/iters_per_epoch : 2/2 
DLL 2021-06-26 19:28:14.203108 - (1, 0) train_loss : 46.694435119628906 
DLL 2021-06-26 19:28:16.968575 - (1, 0) train_items_per_sec : 171848.15549588818 
DLL 2021-06-26 19:28:16.968658 - (1, 0) train_iter_time : 3.898115740998037 
DLL 2021-06-26 19:28:16.996321 - (1, 1) glob_iter/iters_per_epoch : 3/2 
DLL 2021-06-26 19:28:18.796068 - (1, 1) train_loss : 46.29647445678711 
DLL 2021-06-26 19:28:21.482579 - (1, 1) train_items_per_sec : 147599.76970153704 
DLL 2021-06-26 19:28:21.482802 - (1, 1) train_iter_time : 4.486226511999121 
DLL 2021-06-26 19:28:21.569868 - (1,) train_items_per_sec : 159723.9625987126 
DLL 2021-06-26 19:28:21.569934 - (1,) train_loss : 46.29647445678711 
DLL 2021-06-26 19:28:21.569961 - (1,) train_epoch_time : 11.535228368997196 
DLL 2021-06-26 19:28:22.755122 - (1, 4, 0) val_items_per_sec : 96250.13827189278 
DLL 2021-06-26 19:28:22.852080 - (1,) val_loss : 48.22633743286133 
DLL 2021-06-26 19:28:22.852221 - (1,) val_items_per_sec : 96250.13827189278 
DLL 2021-06-26 19:28:22.854038 - () run_time : 87.48745704199973 
DLL 2021-06-26 19:28:22.854115 - () val_loss : 48.22633743286133 
DLL 2021-06-26 19:28:22.854156 - () train_items_per_sec : 159723.9625987126 
DONE!
