train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2021-06-26 16:55:01.388835 - PARAMETER output : ./ 
DLL 2021-06-26 16:55:01.388905 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 16:55:01.388929 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 16:55:01.388949 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 16:55:01.388966 - PARAMETER anneal_steps : None 
DLL 2021-06-26 16:55:01.388983 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 16:55:01.389000 - PARAMETER epochs : 2 
DLL 2021-06-26 16:55:01.389017 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 16:55:01.389033 - PARAMETER checkpoint_path :  
DLL 2021-06-26 16:55:01.389049 - PARAMETER resume_from_last : False 
DLL 2021-06-26 16:55:01.389066 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 16:55:01.389084 - PARAMETER amp : False 
DLL 2021-06-26 16:55:01.389100 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 16:55:01.389116 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 16:55:01.389132 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 16:55:01.389147 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 16:55:01.389162 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 16:55:01.389177 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 16:55:01.389194 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 16:55:01.389209 - PARAMETER batch_size : 148 
DLL 2021-06-26 16:55:01.389225 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 16:55:01.389240 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 16:55:01.389255 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-06-26 16:55:01.389271 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 16:55:01.389286 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 16:55:01.389304 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 16:55:01.389320 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 16:55:01.389343 - PARAMETER filter_length : 1024 
DLL 2021-06-26 16:55:01.389359 - PARAMETER hop_length : 256 
DLL 2021-06-26 16:55:01.389374 - PARAMETER win_length : 1024 
DLL 2021-06-26 16:55:01.389389 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 16:55:01.389404 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 16:55:01.389419 - PARAMETER rank : 0 
DLL 2021-06-26 16:55:01.389434 - PARAMETER world_size : 2 
DLL 2021-06-26 16:55:01.389449 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 16:55:01.389463 - PARAMETER group_name : group_name 
DLL 2021-06-26 16:55:01.389478 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 16:55:01.389492 - PARAMETER bench_class :  
DLL 2021-06-26 16:55:01.389507 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 16:55:17.298950 - (0, 0) glob_iter/iters_per_epoch : 0/4 
DLL 2021-06-26 16:55:36.218346 - (0, 0) train_loss : 47.69031524658203 
DLL 2021-06-26 16:55:41.921081 - (0, 0) train_items_per_sec : 6842.692049740834 
DLL 2021-06-26 16:55:41.921196 - (0, 0) train_iter_time : 24.622180681999453 
DLL 2021-06-26 16:55:41.930212 - (0, 1) glob_iter/iters_per_epoch : 1/4 
DLL 2021-06-26 16:55:43.912621 - (0, 1) train_loss : 46.689720153808594 
DLL 2021-06-26 16:55:46.526089 - (0, 1) train_items_per_sec : 36351.00532218671 
DLL 2021-06-26 16:55:46.526180 - (0, 1) train_iter_time : 4.5958838970000215 
DLL 2021-06-26 16:55:46.538767 - (0, 2) glob_iter/iters_per_epoch : 2/4 
DLL 2021-06-26 16:55:48.012608 - (0, 2) train_loss : 47.671875 
DLL 2021-06-26 16:55:50.673202 - (0, 2) train_items_per_sec : 40602.375280072105 
DLL 2021-06-26 16:55:50.673290 - (0, 2) train_iter_time : 4.134437919999982 
DLL 2021-06-26 16:55:50.690628 - (0, 3) glob_iter/iters_per_epoch : 3/4 
DLL 2021-06-26 16:55:52.133086 - (0, 3) train_loss : 47.17794418334961 
DLL 2021-06-26 16:55:54.808722 - (0, 3) train_items_per_sec : 40740.12990195396 
DLL 2021-06-26 16:55:54.808812 - (0, 3) train_iter_time : 4.118101743999432 
DLL 2021-06-26 16:55:54.845540 - (0,) train_items_per_sec : 31134.050638488403 
DLL 2021-06-26 16:55:54.845591 - (0,) train_loss : 47.17794418334961 
DLL 2021-06-26 16:55:54.845618 - (0,) train_epoch_time : 40.21937921100107 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 16:55:56.541827 - (0, 4, 0) val_items_per_sec : 85729.49279736324 
DLL 2021-06-26 16:55:56.604959 - (0,) val_loss : 45.77946472167969 
DLL 2021-06-26 16:55:56.605030 - (0,) val_items_per_sec : 85729.49279736324 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-26 16:55:59.605974 - (1, 0) glob_iter/iters_per_epoch : 4/4 
DLL 2021-06-26 16:56:00.428492 - (1, 0) train_loss : 46.43714904785156 
DLL 2021-06-26 16:56:03.186815 - (1, 0) train_items_per_sec : 45732.41405709502 
DLL 2021-06-26 16:56:03.186948 - (1, 0) train_iter_time : 3.58089559399923 
DLL 2021-06-26 16:56:03.201630 - (1, 1) glob_iter/iters_per_epoch : 5/4 
DLL 2021-06-26 16:56:04.442860 - (1, 1) train_loss : 46.64971923828125 
DLL 2021-06-26 16:56:07.117095 - (1, 1) train_items_per_sec : 42243.8424303311 
DLL 2021-06-26 16:56:07.117193 - (1, 1) train_iter_time : 3.915481890000592 
DLL 2021-06-26 16:56:07.134661 - (1, 2) glob_iter/iters_per_epoch : 6/4 
DLL 2021-06-26 16:56:07.923943 - (1, 2) train_loss : 48.90605926513672 
DLL 2021-06-26 16:56:10.558507 - (1, 2) train_items_per_sec : 50473.52809618286 
DLL 2021-06-26 16:56:10.558597 - (1, 2) train_iter_time : 3.423854176999157 
DLL 2021-06-26 16:56:10.573497 - (1, 3) glob_iter/iters_per_epoch : 7/4 
DLL 2021-06-26 16:56:11.365083 - (1, 3) train_loss : 47.425636291503906 
DLL 2021-06-26 16:56:14.081345 - (1, 3) train_items_per_sec : 48473.298296192355 
DLL 2021-06-26 16:56:14.081439 - (1, 3) train_iter_time : 3.507848773999285 
DLL 2021-06-26 16:56:14.130178 - (1,) train_items_per_sec : 46730.770719950335 
DLL 2021-06-26 16:56:14.130254 - (1,) train_loss : 47.425636291503906 
DLL 2021-06-26 16:56:14.130300 - (1,) train_epoch_time : 17.12930444599988 
DLL 2021-06-26 16:56:15.774778 - (1, 8, 0) val_items_per_sec : 94220.05617494225 
DLL 2021-06-26 16:56:15.834053 - (1,) val_loss : 45.75929260253906 
DLL 2021-06-26 16:56:15.834148 - (1,) val_items_per_sec : 94220.05617494225 
DLL 2021-06-26 16:56:15.836393 - () run_time : 66.94623601000058 
DLL 2021-06-26 16:56:15.836435 - () val_loss : 45.75929260253906 
DLL 2021-06-26 16:56:15.836459 - () train_items_per_sec : 46730.770719950335 
DONE!
