train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 17:48:51.982326 - PARAMETER output : ./ 
DLL 2021-06-26 17:48:51.982402 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 17:48:51.982425 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 17:48:51.982443 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 17:48:51.982459 - PARAMETER anneal_steps : None 
DLL 2021-06-26 17:48:51.982478 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 17:48:51.982496 - PARAMETER epochs : 2 
DLL 2021-06-26 17:48:51.982512 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 17:48:51.982528 - PARAMETER checkpoint_path :  
DLL 2021-06-26 17:48:51.982546 - PARAMETER resume_from_last : False 
DLL 2021-06-26 17:48:51.982563 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 17:48:51.982580 - PARAMETER amp : False 
DLL 2021-06-26 17:48:51.982597 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 17:48:51.982614 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 17:48:51.982629 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 17:48:51.982644 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 17:48:51.982659 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 17:48:51.982673 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 17:48:51.982689 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 17:48:51.982704 - PARAMETER batch_size : 136 
DLL 2021-06-26 17:48:51.982719 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 17:48:51.982733 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 17:48:51.982748 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-26 17:48:51.982762 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 17:48:51.982777 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 17:48:51.982794 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 17:48:51.982810 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 17:48:51.982825 - PARAMETER filter_length : 1024 
DLL 2021-06-26 17:48:51.982840 - PARAMETER hop_length : 256 
DLL 2021-06-26 17:48:51.982854 - PARAMETER win_length : 1024 
DLL 2021-06-26 17:48:51.982868 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 17:48:51.982883 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 17:48:51.982897 - PARAMETER rank : 0 
DLL 2021-06-26 17:48:51.982912 - PARAMETER world_size : 2 
DLL 2021-06-26 17:48:51.982928 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 17:48:51.982943 - PARAMETER group_name : group_name 
DLL 2021-06-26 17:48:51.982957 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 17:48:51.982972 - PARAMETER bench_class :  
DLL 2021-06-26 17:48:51.982987 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 17:49:08.770875 - (0, 0) glob_iter/iters_per_epoch : 0/2 
DLL 2021-06-26 17:49:30.146152 - (0, 0) train_loss : 45.99176788330078 
DLL 2021-06-26 17:49:34.127851 - (0, 0) train_items_per_sec : 5937.872683729365 
DLL 2021-06-26 17:49:34.127956 - (0, 0) train_iter_time : 25.357061024998984 
DLL 2021-06-26 17:49:34.134074 - (0, 1) glob_iter/iters_per_epoch : 1/2 
DLL 2021-06-26 17:49:36.109694 - (0, 1) train_loss : 47.29485321044922 
DLL 2021-06-26 17:49:38.584278 - (0, 1) train_items_per_sec : 34895.45775374616 
DLL 2021-06-26 17:49:38.584363 - (0, 1) train_iter_time : 4.450206703000731 
DLL 2021-06-26 17:49:38.663144 - (0,) train_items_per_sec : 20416.665218737762 
DLL 2021-06-26 17:49:38.663280 - (0,) train_loss : 47.29485321044922 
DLL 2021-06-26 17:49:38.663312 - (0,) train_epoch_time : 32.338703800000076 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 17:49:40.358700 - (0, 2, 0) val_items_per_sec : 94376.42379145349 
DLL 2021-06-26 17:49:40.490136 - (0,) val_loss : 45.716888427734375 
DLL 2021-06-26 17:49:40.490234 - (0,) val_items_per_sec : 94376.42379145349 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-06-26 17:49:43.660134 - (1, 0) glob_iter/iters_per_epoch : 2/2 
DLL 2021-06-26 17:49:44.511091 - (1, 0) train_loss : 46.395076751708984 
DLL 2021-06-26 17:49:46.991154 - (1, 0) train_items_per_sec : 45640.721851399605 
DLL 2021-06-26 17:49:46.991241 - (1, 0) train_iter_time : 3.3310603740010265 
DLL 2021-06-26 17:49:47.003737 - (1, 1) glob_iter/iters_per_epoch : 3/2 
DLL 2021-06-26 17:49:47.834552 - (1, 1) train_loss : 47.1519660949707 
DLL 2021-06-26 17:49:50.761030 - (1, 1) train_items_per_sec : 41061.7708149354 
DLL 2021-06-26 17:49:50.761158 - (1, 1) train_iter_time : 3.7572904659991764 
DLL 2021-06-26 17:49:50.868568 - (1,) train_items_per_sec : 43351.2463331675 
DLL 2021-06-26 17:49:50.868702 - (1,) train_loss : 47.1519660949707 
DLL 2021-06-26 17:49:50.868737 - (1,) train_epoch_time : 9.786313814000096 
DLL 2021-06-26 17:49:52.616183 - (1, 4, 0) val_items_per_sec : 96324.6366597237 
DLL 2021-06-26 17:49:52.750719 - (1,) val_loss : 45.72929763793945 
DLL 2021-06-26 17:49:52.750810 - (1,) val_items_per_sec : 96324.6366597237 
DLL 2021-06-26 17:49:52.754630 - () run_time : 54.643910591999884 
DLL 2021-06-26 17:49:52.754704 - () val_loss : 45.72929763793945 
DLL 2021-06-26 17:49:52.754746 - () train_items_per_sec : 43351.2463331675 
DONE!
