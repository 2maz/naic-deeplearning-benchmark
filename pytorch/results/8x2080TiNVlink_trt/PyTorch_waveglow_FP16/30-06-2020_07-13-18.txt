:::NVLOGv0.2.2 Tacotron2_PyT 1593501201.088567495 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593501201.113548040 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593501201.132883310 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593501204.392401695 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1593501204.397470951 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 4, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 8, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1593501206.462214947 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1593501262.441943884 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1593501262.443535089 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501262.675257683 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501266.222898722 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002217563334852457
:::NVLOGv0.2.2 Tacotron2_PyT 1593501267.988408327 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501267.988867521 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 48171.00529784152
:::NVLOGv0.2.2 Tacotron2_PyT 1593501267.989225149 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.3144001960754395
Batch: 1/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501267.992359877 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501268.897030830 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002471739426255226
:::NVLOGv0.2.2 Tacotron2_PyT 1593501269.735374689 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501269.735771418 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 146795.5967684626
:::NVLOGv0.2.2 Tacotron2_PyT 1593501269.736149549 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.7439215183258057
Batch: 2/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501269.738814116 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593501269.945602417 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0016843799967318773
:::NVLOGv0.2.2 Tacotron2_PyT 1593501270.698849201 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593501270.699293137 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 266472.94934630184
:::NVLOGv0.2.2 Tacotron2_PyT 1593501270.699645042 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9606978893280029
Batch: 3/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501270.702634573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593501270.954095125 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021750146988779306
:::NVLOGv0.2.2 Tacotron2_PyT 1593501271.709815264 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593501271.710209370 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 253990.5078382245
:::NVLOGv0.2.2 Tacotron2_PyT 1593501271.710561752 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0079116821289062
Batch: 4/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501271.713093996 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593501271.978919268 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021223663352429867
:::NVLOGv0.2.2 Tacotron2_PyT 1593501272.859612703 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593501272.860079527 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 223148.1521737549
:::NVLOGv0.2.2 Tacotron2_PyT 1593501272.860443115 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1472198963165283
Batch: 5/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501272.863487482 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593501273.074226856 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022607336286455393
:::NVLOGv0.2.2 Tacotron2_PyT 1593501273.876741409 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593501273.877201557 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 252473.2156503313
:::NVLOGv0.2.2 Tacotron2_PyT 1593501273.877571344 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0139689445495605
Batch: 6/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501273.880319834 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593501274.166289330 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002429207321256399
:::NVLOGv0.2.2 Tacotron2_PyT 1593501274.968508482 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593501274.968939781 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235083.30583832058
:::NVLOGv0.2.2 Tacotron2_PyT 1593501274.969319820 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0889756679534912
Batch: 7/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501274.971603394 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593501275.234754086 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002167952014133334
:::NVLOGv0.2.2 Tacotron2_PyT 1593501276.051653147 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593501276.052090406 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 236865.85624653383
:::NVLOGv0.2.2 Tacotron2_PyT 1593501276.052493095 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0807805061340332
Batch: 8/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501276.055197716 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593501276.322282314 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023016708437353373
:::NVLOGv0.2.2 Tacotron2_PyT 1593501277.175709963 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593501277.176193476 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 228321.53189976444
:::NVLOGv0.2.2 Tacotron2_PyT 1593501277.176549911 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1212258338928223
Batch: 9/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501277.179312229 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593501277.379894495 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002525511896237731
:::NVLOGv0.2.2 Tacotron2_PyT 1593501278.138115406 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593501278.138552666 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 266801.2317551915
:::NVLOGv0.2.2 Tacotron2_PyT 1593501278.138896465 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9595158100128174
Batch: 10/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501278.141385794 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593501278.363893032 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023864409886300564
:::NVLOGv0.2.2 Tacotron2_PyT 1593501279.119409561 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593501279.119823456 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 261549.3201127417
:::NVLOGv0.2.2 Tacotron2_PyT 1593501279.120198727 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9787828922271729
Batch: 11/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501279.122841120 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593501279.330705881 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023172928486019373
:::NVLOGv0.2.2 Tacotron2_PyT 1593501280.105991364 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593501280.106382370 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 260221.31012460668
:::NVLOGv0.2.2 Tacotron2_PyT 1593501280.106724024 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9837779998779297
Batch: 12/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501280.109009504 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593501280.431594849 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023245755583047867
:::NVLOGv0.2.2 Tacotron2_PyT 1593501281.196145058 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593501281.196536541 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235345.9867696739
:::NVLOGv0.2.2 Tacotron2_PyT 1593501281.196898222 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0877602100372314
Batch: 13/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501281.199432611 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593501281.484628677 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001998970750719309
:::NVLOGv0.2.2 Tacotron2_PyT 1593501282.241140366 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593501282.241604567 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 245580.8993669854
:::NVLOGv0.2.2 Tacotron2_PyT 1593501282.241944790 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.042426347732544
Batch: 14/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501282.244766235 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593501282.460576534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002085187239572406
:::NVLOGv0.2.2 Tacotron2_PyT 1593501283.326288939 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593501283.326712132 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 236542.49106528974
:::NVLOGv0.2.2 Tacotron2_PyT 1593501283.327067375 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0822579860687256
Batch: 15/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501283.330027103 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593501283.619662762 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018764460692182183
:::NVLOGv0.2.2 Tacotron2_PyT 1593501284.385056973 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593501284.385431051 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 242469.8999695372
:::NVLOGv0.2.2 Tacotron2_PyT 1593501284.385785103 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0558011531829834
Batch: 16/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501284.388452053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593501284.782467127 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0027192437555640936
:::NVLOGv0.2.2 Tacotron2_PyT 1593501285.541468382 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593501285.541858912 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 221892.87147577706
:::NVLOGv0.2.2 Tacotron2_PyT 1593501285.542220831 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.153709888458252
Batch: 17/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501285.544572830 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593501285.763142347 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018217224860563874
:::NVLOGv0.2.2 Tacotron2_PyT 1593501286.565257549 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593501286.565747023 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 250683.66807105066
:::NVLOGv0.2.2 Tacotron2_PyT 1593501286.566108704 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.021207332611084
Batch: 18/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501286.568682432 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593501286.779327631 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021598979365080595
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.597996473 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.598400831 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 248603.71606055906
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.598725557 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0297513008117676
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.831748962 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.832211018 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 191578.99296928736
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.832574606 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 229527.02714899732
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.832922935 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0022129430067970566
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.833264589 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 25.389004945755005
:::NVLOGv0.2.2 Tacotron2_PyT 1593501287.833602190 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593501289.672751904 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.002806906122714281
:::NVLOGv0.2.2 Tacotron2_PyT 1593501289.673647881 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501292.528946400 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501292.626330853 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501292.865939617 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001744760200381279
:::NVLOGv0.2.2 Tacotron2_PyT 1593501293.695010662 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593501293.695479393 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 239325.83577453118
:::NVLOGv0.2.2 Tacotron2_PyT 1593501293.695878506 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.069671392440796
Batch: 1/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501293.697900534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501293.897486687 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020821888465434313
:::NVLOGv0.2.2 Tacotron2_PyT 1593501294.665157318 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501294.665551186 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 264493.44568550325
:::NVLOGv0.2.2 Tacotron2_PyT 1593501294.665906668 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9678878784179688
Batch: 2/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501294.667843580 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593501294.840734482 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021603815257549286
:::NVLOGv0.2.2 Tacotron2_PyT 1593501295.610191107 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593501295.610618591 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 271479.89946254785
:::NVLOGv0.2.2 Tacotron2_PyT 1593501295.611027241 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9429795742034912
Batch: 3/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501295.613103390 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593501295.818267584 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002593676559627056
:::NVLOGv0.2.2 Tacotron2_PyT 1593501296.619505644 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593501296.620151043 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 254190.19276463264
:::NVLOGv0.2.2 Tacotron2_PyT 1593501296.620677233 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.00711989402771
Batch: 4/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501296.623731136 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593501296.869367123 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001994132762774825
:::NVLOGv0.2.2 Tacotron2_PyT 1593501297.690919876 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593501297.691331863 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 239699.28677896844
:::NVLOGv0.2.2 Tacotron2_PyT 1593501297.691699028 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.068004846572876
Batch: 5/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501297.694412470 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593501297.927035332 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022128112614154816
:::NVLOGv0.2.2 Tacotron2_PyT 1593501298.697648048 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593501298.698052168 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 255009.03884787997
:::NVLOGv0.2.2 Tacotron2_PyT 1593501298.698434114 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0038859844207764
Batch: 6/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501298.701170444 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593501298.994701385 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.003095510881394148
:::NVLOGv0.2.2 Tacotron2_PyT 1593501299.824474573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593501299.825174570 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 227741.1813913199
:::NVLOGv0.2.2 Tacotron2_PyT 1593501299.825682402 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1240830421447754
Batch: 7/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501299.829028606 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593501300.049252272 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023068911395967007
:::NVLOGv0.2.2 Tacotron2_PyT 1593501300.857296944 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593501300.857743979 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 248740.49456589096
:::NVLOGv0.2.2 Tacotron2_PyT 1593501300.858086824 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0291850566864014
Batch: 8/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501300.860991955 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593501301.087159157 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020858775824308395
:::NVLOGv0.2.2 Tacotron2_PyT 1593501301.851640463 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593501301.852061033 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 258233.80059076168
:::NVLOGv0.2.2 Tacotron2_PyT 1593501301.852456093 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9913496971130371
Batch: 9/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501301.854795218 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593501302.102817774 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024247262626886368
:::NVLOGv0.2.2 Tacotron2_PyT 1593501302.860797167 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593501302.861196995 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 254302.77026935812
:::NVLOGv0.2.2 Tacotron2_PyT 1593501302.861540079 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.00667405128479
Batch: 10/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501302.864284515 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593501303.071747065 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002295228885486722
:::NVLOGv0.2.2 Tacotron2_PyT 1593501303.848942518 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593501303.849374771 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 259802.5422734317
:::NVLOGv0.2.2 Tacotron2_PyT 1593501303.849757195 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9853637218475342
Batch: 11/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501303.852515936 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593501304.129019499 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002311308868229389
:::NVLOGv0.2.2 Tacotron2_PyT 1593501304.884546280 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593501304.884946346 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 247881.49431374567
:::NVLOGv0.2.2 Tacotron2_PyT 1593501304.885294199 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0327515602111816
Batch: 12/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501304.888097286 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593501305.147231817 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020112113561481237
:::NVLOGv0.2.2 Tacotron2_PyT 1593501306.027050018 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593501306.027676582 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 224610.04867512008
:::NVLOGv0.2.2 Tacotron2_PyT 1593501306.028197289 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1397531032562256
Batch: 13/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501306.031378746 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593501306.249484301 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023055439814925194
:::NVLOGv0.2.2 Tacotron2_PyT 1593501307.027667999 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593501307.028094053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 256733.90950559906
:::NVLOGv0.2.2 Tacotron2_PyT 1593501307.028450012 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9971413612365723
Batch: 14/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501307.031199932 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593501307.283242226 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023193866945803165
:::NVLOGv0.2.2 Tacotron2_PyT 1593501308.047470808 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593501308.047875166 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 251738.6980479464
:::NVLOGv0.2.2 Tacotron2_PyT 1593501308.048234940 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0169274806976318
Batch: 15/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501308.050921202 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593501308.338055372 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025177013594657183
:::NVLOGv0.2.2 Tacotron2_PyT 1593501309.141484261 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593501309.141897202 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 234602.2871575709
:::NVLOGv0.2.2 Tacotron2_PyT 1593501309.142215252 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0912084579467773
Batch: 16/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501309.144926786 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593501309.356996298 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0016221413388848305
:::NVLOGv0.2.2 Tacotron2_PyT 1593501310.164626360 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593501310.165045261 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 250898.5271005186
:::NVLOGv0.2.2 Tacotron2_PyT 1593501310.165409565 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0203328132629395
Batch: 17/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501310.168094635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593501310.362055063 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020900496747344732
:::NVLOGv0.2.2 Tacotron2_PyT 1593501311.164424181 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593501311.164855957 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 256769.947918647
:::NVLOGv0.2.2 Tacotron2_PyT 1593501311.165214777 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 0.9970014095306396
Batch: 18/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501311.167179346 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593501311.405161619 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0031709950417280197
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.221475124 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.221910954 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 242713.74546723685
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.222286224 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0547404289245605
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.281231165 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.281629086 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 246243.46962958592
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.281989813 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 249419.32350480053
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.282343388 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.00228129074859776
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.282693386 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 19.752808094024658
:::NVLOGv0.2.2 Tacotron2_PyT 1593501312.283037663 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.208502054 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0018024083692580462
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.209694386 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.217775345 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 106.74875950813293
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.218368053 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 106.74875950813293
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.218800306 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 112.225741147995
:::NVLOGv0.2.2 Tacotron2_PyT 1593501313.219152451 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
