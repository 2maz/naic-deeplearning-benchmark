The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : main.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 4
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_u_qgqa33/none_wtxdqe29
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0, 1, 2, 3]
  role_ranks=[0, 1, 2, 3]
  global_ranks=[0, 1, 2, 3]
  role_world_sizes=[4, 4, 4, 4]
  global_world_sizes=[4, 4, 4, 4]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_u_qgqa33/none_wtxdqe29/attempt_0/0/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker1 reply file to: /tmp/torchelastic_u_qgqa33/none_wtxdqe29/attempt_0/1/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker2 reply file to: /tmp/torchelastic_u_qgqa33/none_wtxdqe29/attempt_0/2/error.json
INFO:torch.distributed.elastic.multiprocessing:Setting worker3 reply file to: /tmp/torchelastic_u_qgqa33/none_wtxdqe29/attempt_0/3/error.json
NOTE! Installing ujson may make loading annotations faster.
NOTE! Installing ujson may make loading annotations faster.
NOTE! Installing ujson may make loading annotations faster.
NOTE! Installing ujson may make loading annotations faster.
DLL 2022-07-01 01:52:41.255359 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 80  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2022-07-01 01:52:41.264968 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 80  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2022-07-01 01:52:41.268122 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 80  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
DLL 2022-07-01 01:52:41.279435 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 80  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
Using seed = 4711
Using seed = 8936
Using seed = 1040Using seed = 1533

loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.45s)
creating index...
Done (t=0.48s)
creating index...
Done (t=0.51s)
creating index...
Done (t=0.52s)
creating index...
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coco_reader` is now deprecated. Use `readers.coco` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder_slice` is now deprecated. Use `decoders.image_slice` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coco_reader` is now deprecated. Use `readers.coco` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder_slice` is now deprecated. Use `decoders.image_slice` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coco_reader` is now deprecated. Use `readers.coco` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder_slice` is now deprecated. Use `decoders.image_slice` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coco_reader` is now deprecated. Use `readers.coco` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder_slice` is now deprecated. Use `decoders.image_slice` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
DLL 2022-07-01 01:54:37.313608 - () avg_img/sec : 119.86395769560497  med_img/sec : 119.84483306930447  min_img/sec : 119.42392241709142  max_img/sec : 120.35465320020387 
Done benchmarking. Total images: 8000	total time: 66.742	Average images/sec: 119.864	Median images/sec: 119.845
DLL 2022-07-01 01:54:37.313662 - () avg_img/sec : 119.88532730564975  med_img/sec : 119.87696641184587  min_img/sec : 119.4416493371597  max_img/sec : 120.38474978706732 
Done benchmarking. Total images: 8000	total time: 66.730	Average images/sec: 119.885	Median images/sec: 119.877
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2022-07-01 01:54:37.314687 - () total time : 107.61095261573792 
DLL 2022-07-01 01:54:37.314710 - () 
DLL 2022-07-01 01:54:37.314666 - () avg_img/sec : 119.96186624611458  med_img/sec : 119.94134964682954  min_img/sec : 119.55821680470758  max_img/sec : 120.46743087859959 
Done benchmarking. Total images: 8000	total time: 66.688	Average images/sec: 119.962	Median images/sec: 119.941
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2022-07-01 01:54:37.316145 - () total time : 107.61219048500061 
DLL 2022-07-01 01:54:37.316172 - () 
DLL 2022-07-01 01:54:37.319779 - () avg_img/sec : 119.90944819789665  med_img/sec : 119.89934790621743  min_img/sec : 119.52295445939838  max_img/sec : 120.35327179568112 
Done benchmarking. Total images: 8000	total time: 66.717	Average images/sec: 119.909	Median images/sec: 119.899
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2022-07-01 01:54:37.321164 - () total time : 107.61733794212341 
DLL 2022-07-01 01:54:37.321188 - () 
Training performance = 479.5625 FPS
DLL 2022-07-01 01:54:37.458752 - (0,) time : 107.75558471679688 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2022-07-01 01:54:37.459120 - () total time : 107.75558471679688 
DLL 2022-07-01 01:54:37.459139 - () 
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0004687309265136719 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "18718", "role": "default", "hostname": "1cd397664366", "state": "SUCCEEDED", "total_run_time": 120, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 1, "group_rank": 0, "worker_id": "18719", "role": "default", "hostname": "1cd397664366", "state": "SUCCEEDED", "total_run_time": 120, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [1], \"role_rank\": [1], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 2, "group_rank": 0, "worker_id": "18720", "role": "default", "hostname": "1cd397664366", "state": "SUCCEEDED", "total_run_time": 120, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [2], \"role_rank\": [2], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 3, "group_rank": 0, "worker_id": "18721", "role": "default", "hostname": "1cd397664366", "state": "SUCCEEDED", "total_run_time": 120, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [3], \"role_rank\": [3], \"role_world_size\": [4]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "1cd397664366", "state": "SUCCEEDED", "total_run_time": 120, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
