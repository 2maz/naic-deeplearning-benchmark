Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  1%|          | 864k/97.8M [00:00<00:11, 8.83MB/s]  1%|          | 1.03M/97.8M [00:00<00:09, 10.8MB/s]  1%|          | 800k/97.8M [00:00<00:12, 8.12MB/s]  0%|          | 440k/97.8M [00:00<00:22, 4.50MB/s]  4%|▍         | 4.05M/97.8M [00:00<00:08, 11.3MB/s]  4%|▍         | 4.24M/97.8M [00:00<00:07, 13.5MB/s]  4%|▍         | 4.18M/97.8M [00:00<00:09, 10.6MB/s]  3%|▎         | 2.82M/97.8M [00:00<00:16, 5.96MB/s]  6%|▋         | 6.30M/97.8M [00:00<00:07, 13.4MB/s]  7%|▋         | 6.43M/97.8M [00:00<00:06, 15.4MB/s]  7%|▋         | 6.74M/97.8M [00:00<00:07, 12.9MB/s]  7%|▋         | 7.31M/97.8M [00:00<00:11, 8.08MB/s]  9%|▉         | 8.80M/97.8M [00:00<00:05, 15.7MB/s]  9%|▉         | 8.95M/97.8M [00:00<00:05, 17.6MB/s] 10%|▉         | 9.38M/97.8M [00:00<00:06, 15.4MB/s] 10%|█         | 10.2M/97.8M [00:00<00:08, 10.3MB/s] 12%|█▏        | 11.9M/97.8M [00:00<00:04, 18.5MB/s] 12%|█▏        | 11.6M/97.8M [00:00<00:04, 19.9MB/s] 12%|█▏        | 11.9M/97.8M [00:00<00:05, 17.5MB/s] 13%|█▎        | 13.2M/97.8M [00:00<00:06, 12.9MB/s] 16%|█▌        | 15.2M/97.8M [00:00<00:04, 21.5MB/s] 15%|█▍        | 14.5M/97.8M [00:00<00:03, 22.1MB/s] 14%|█▍        | 14.0M/97.8M [00:00<00:04, 18.8MB/s] 16%|█▌        | 15.8M/97.8M [00:00<00:05, 15.4MB/s] 18%|█▊        | 18.0M/97.8M [00:00<00:03, 23.3MB/s] 18%|█▊        | 17.3M/97.8M [00:00<00:03, 23.9MB/s] 17%|█▋        | 16.6M/97.8M [00:00<00:04, 20.6MB/s] 20%|██        | 19.6M/97.8M [00:00<00:04, 18.8MB/s] 21%|██        | 20.6M/97.8M [00:00<00:03, 24.1MB/s] 20%|██        | 19.8M/97.8M [00:00<00:03, 23.9MB/s] 19%|█▉        | 18.8M/97.8M [00:00<00:03, 21.1MB/s] 24%|██▍       | 23.4M/97.8M [00:00<00:03, 22.3MB/s] 24%|██▍       | 23.3M/97.8M [00:00<00:03, 25.4MB/s] 23%|██▎       | 22.2M/97.8M [00:00<00:03, 24.0MB/s] 21%|██▏       | 21.0M/97.8M [00:00<00:03, 21.5MB/s] 28%|██▊       | 26.9M/97.8M [00:00<00:02, 25.3MB/s] 27%|██▋       | 26.4M/97.8M [00:01<00:02, 27.0MB/s] 25%|██▌       | 24.9M/97.8M [00:01<00:03, 25.1MB/s] 24%|██▎       | 23.2M/97.8M [00:01<00:03, 21.8MB/s] 31%|███       | 30.2M/97.8M [00:01<00:02, 27.4MB/s] 30%|██▉       | 29.2M/97.8M [00:01<00:02, 27.8MB/s] 28%|██▊       | 27.7M/97.8M [00:01<00:02, 26.3MB/s] 26%|██▌       | 25.4M/97.8M [00:01<00:03, 21.9MB/s] 34%|███▍      | 33.5M/97.8M [00:01<00:02, 29.3MB/s] 33%|███▎      | 32.3M/97.8M [00:01<00:02, 28.9MB/s] 31%|███       | 30.3M/97.8M [00:01<00:02, 26.3MB/s] 28%|██▊       | 27.5M/97.8M [00:01<00:03, 21.4MB/s] 38%|███▊      | 36.9M/97.8M [00:01<00:02, 30.0MB/s] 37%|███▋      | 35.9M/97.8M [00:01<00:02, 31.0MB/s] 34%|███▍      | 33.2M/97.8M [00:01<00:02, 27.5MB/s] 31%|███       | 29.8M/97.8M [00:01<00:03, 22.2MB/s] 41%|████      | 40.1M/97.8M [00:01<00:01, 30.3MB/s] 40%|███▉      | 39.0M/97.8M [00:01<00:01, 31.7MB/s] 37%|███▋      | 35.9M/97.8M [00:01<00:02, 27.8MB/s] 33%|███▎      | 32.0M/97.8M [00:01<00:03, 22.2MB/s] 44%|████▍     | 43.3M/97.8M [00:01<00:01, 30.0MB/s] 43%|████▎     | 42.4M/97.8M [00:01<00:01, 32.6MB/s] 40%|███▉      | 38.8M/97.8M [00:01<00:02, 28.3MB/s] 35%|███▍      | 34.1M/97.8M [00:01<00:03, 21.9MB/s] 47%|████▋     | 46.3M/97.8M [00:01<00:01, 28.8MB/s] 47%|████▋     | 45.9M/97.8M [00:01<00:01, 33.8MB/s] 43%|████▎     | 41.9M/97.8M [00:01<00:01, 29.5MB/s] 37%|███▋      | 36.4M/97.8M [00:01<00:02, 22.4MB/s] 46%|████▋     | 45.4M/97.8M [00:01<00:01, 31.2MB/s] 50%|█████     | 49.2M/97.8M [00:01<00:01, 27.8MB/s] 50%|█████     | 49.2M/97.8M [00:01<00:01, 32.6MB/s] 40%|███▉      | 38.7M/97.8M [00:01<00:02, 22.7MB/s] 50%|████▉     | 48.4M/97.8M [00:01<00:01, 31.5MB/s] 53%|█████▎    | 52.3M/97.8M [00:01<00:01, 29.0MB/s] 54%|█████▎    | 52.4M/97.8M [00:01<00:01, 31.9MB/s] 42%|████▏     | 40.9M/97.8M [00:01<00:02, 22.0MB/s] 53%|█████▎    | 51.6M/97.8M [00:01<00:01, 32.1MB/s] 56%|█████▋    | 55.1M/97.8M [00:01<00:01, 28.4MB/s] 57%|█████▋    | 55.8M/97.8M [00:01<00:01, 33.1MB/s] 44%|████▍     | 43.0M/97.8M [00:01<00:02, 21.1MB/s] 56%|█████▌    | 54.7M/97.8M [00:02<00:01, 31.7MB/s] 61%|██████    | 59.3M/97.8M [00:02<00:01, 34.0MB/s] 59%|█████▉    | 57.9M/97.8M [00:01<00:01, 28.6MB/s] 46%|████▌     | 45.0M/97.8M [00:02<00:02, 20.6MB/s] 59%|█████▉    | 58.0M/97.8M [00:02<00:01, 32.6MB/s] 63%|██████▎   | 61.2M/97.8M [00:02<00:01, 30.0MB/s] 64%|██████▍   | 62.6M/97.8M [00:02<00:01, 31.4MB/s] 48%|████▊     | 47.1M/97.8M [00:02<00:02, 21.1MB/s] 63%|██████▎   | 61.3M/97.8M [00:02<00:01, 33.0MB/s] 66%|██████▌   | 64.3M/97.8M [00:02<00:01, 30.8MB/s] 67%|██████▋   | 65.7M/97.8M [00:02<00:01, 31.7MB/s] 50%|█████     | 49.1M/97.8M [00:02<00:02, 19.9MB/s] 69%|██████▉   | 67.3M/97.8M [00:02<00:01, 30.8MB/s] 66%|██████▌   | 64.5M/97.8M [00:02<00:01, 32.1MB/s] 71%|███████   | 69.0M/97.8M [00:02<00:00, 32.7MB/s] 52%|█████▏    | 51.1M/97.8M [00:02<00:02, 19.4MB/s] 72%|███████▏  | 70.4M/97.8M [00:02<00:00, 31.3MB/s] 69%|██████▉   | 67.5M/97.8M [00:02<00:00, 31.9MB/s] 74%|███████▍  | 72.2M/97.8M [00:02<00:00, 32.6MB/s] 54%|█████▍    | 53.2M/97.8M [00:02<00:02, 20.1MB/s] 76%|███████▌  | 73.8M/97.8M [00:02<00:00, 32.6MB/s] 72%|███████▏  | 70.8M/97.8M [00:02<00:00, 32.5MB/s] 77%|███████▋  | 75.3M/97.8M [00:02<00:00, 30.5MB/s] 56%|█████▋    | 55.1M/97.8M [00:02<00:02, 19.7MB/s] 79%|███████▊  | 77.0M/97.8M [00:02<00:00, 32.3MB/s] 76%|███████▌  | 73.9M/97.8M [00:02<00:00, 32.6MB/s] 81%|████████  | 78.7M/97.8M [00:02<00:00, 31.7MB/s] 58%|█████▊    | 57.0M/97.8M [00:02<00:02, 19.2MB/s] 79%|███████▉  | 77.1M/97.8M [00:02<00:00, 32.6MB/s] 82%|████████▏ | 80.1M/97.8M [00:02<00:00, 31.6MB/s] 84%|████████▎ | 81.9M/97.8M [00:02<00:00, 32.0MB/s] 60%|██████    | 59.0M/97.8M [00:02<00:02, 19.7MB/s] 82%|████████▏ | 80.2M/97.8M [00:02<00:00, 32.5MB/s] 85%|████████▌ | 83.1M/97.8M [00:02<00:00, 31.6MB/s] 87%|████████▋ | 84.9M/97.8M [00:02<00:00, 30.9MB/s] 62%|██████▏   | 61.0M/97.8M [00:02<00:01, 20.1MB/s] 85%|████████▌ | 83.6M/97.8M [00:02<00:00, 33.3MB/s] 88%|████████▊ | 86.2M/97.8M [00:02<00:00, 31.8MB/s] 90%|████████▉ | 87.9M/97.8M [00:03<00:00, 29.8MB/s] 65%|██████▍   | 63.2M/97.8M [00:03<00:01, 20.9MB/s] 89%|████████▉ | 87.1M/97.8M [00:03<00:00, 34.5MB/s] 91%|█████████▏| 89.2M/97.8M [00:03<00:00, 30.2MB/s] 93%|█████████▎| 90.8M/97.8M [00:03<00:00, 28.6MB/s] 67%|██████▋   | 65.6M/97.8M [00:03<00:01, 21.8MB/s] 93%|█████████▎| 91.0M/97.8M [00:03<00:00, 36.2MB/s] 94%|█████████▍| 92.1M/97.8M [00:03<00:00, 28.9MB/s] 96%|█████████▌| 93.6M/97.8M [00:03<00:00, 28.9MB/s] 69%|██████▉   | 67.7M/97.8M [00:03<00:01, 21.9MB/s] 97%|█████████▋| 94.5M/97.8M [00:03<00:00, 35.9MB/s] 97%|█████████▋| 94.9M/97.8M [00:03<00:00, 29.0MB/s] 99%|█████████▉| 96.6M/97.8M [00:03<00:00, 29.4MB/s] 71%|███████▏  | 69.8M/97.8M [00:03<00:01, 21.8MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 30.7MB/s]
100%|██████████| 97.8M/97.8M [00:03<00:00, 30.4MB/s]
100%|██████████| 97.8M/97.8M [00:03<00:00, 30.8MB/s]
 74%|███████▍  | 72.6M/97.8M [00:03<00:01, 23.6MB/s] 77%|███████▋  | 75.3M/97.8M [00:03<00:00, 24.9MB/s] 80%|████████  | 78.3M/97.8M [00:03<00:00, 26.5MB/s] 84%|████████▎ | 81.9M/97.8M [00:03<00:00, 29.1MB/s]DLL 2021-06-26 19:49:53.195839 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 88  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
 88%|████████▊ | 86.2M/97.8M [00:03<00:00, 32.6MB/s] 93%|█████████▎| 91.0M/97.8M [00:03<00:00, 36.5MB/s]DLL 2021-06-26 19:49:53.343848 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 88  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2021-06-26 19:49:53.354706 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 88  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
 99%|█████████▉| 96.8M/97.8M [00:04<00:00, 41.4MB/s]100%|██████████| 97.8M/97.8M [00:04<00:00, 25.4MB/s]
DLL 2021-06-26 19:49:53.934132 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 88  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
Using seed = 7257
Using seed = 1119
Using seed = 7714
Using seed = 6041
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.36s)
creating index...
Done (t=0.37s)
creating index...
Done (t=0.38s)
creating index...
Done (t=0.43s)
creating index...
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0



Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0

DLL 2021-06-26 19:52:43.266538 - () avg_img/sec : 122.54113240148659  med_img/sec : 122.59515049160024  min_img/sec : 121.52051352879184  max_img/sec : 123.08342256439225 
Done benchmarking. Total images: 8800	total time: 71.813	Average images/sec: 122.541	Median images/sec: 122.595
DLL 2021-06-26 19:52:43.266565 - () avg_img/sec : 122.564851154862  med_img/sec : 122.6128253849796  min_img/sec : 121.49691286196146  max_img/sec : 123.08896384153584 
Done benchmarking. Total images: 8800	total time: 71.799	Average images/sec: 122.565	Median images/sec: 122.613
DLL 2021-06-26 19:52:43.266644 - () avg_img/sec : 122.55690468145849  med_img/sec : 122.59793984310933  min_img/sec : 121.53699943199125  max_img/sec : 123.1120373359946 
Done benchmarking. Total images: 8800	total time: 71.803	Average images/sec: 122.557	Median images/sec: 122.598
DLL 2021-06-26 19:52:43.266741 - () avg_img/sec : 122.57954503665923  med_img/sec : 122.6242108873326  min_img/sec : 121.57438938389475  max_img/sec : 123.10160803061441 
Done benchmarking. Total images: 8800	total time: 71.790	Average images/sec: 122.580	Median images/sec: 122.624
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-06-26 19:52:43.267632 - () total time : 146.02808260917664 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-06-26 19:52:43.267659 - () DLL 2021-06-26 19:52:43.267674 - () total time : 146.0280933380127 

DLL 2021-06-26 19:52:43.267706 - () 
Training performance = 490.43011474609375 FPSWARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...

DLL 2021-06-26 19:52:43.267829 - () total time : 146.0285313129425 
DLL 2021-06-26 19:52:43.267859 - () 
DLL 2021-06-26 19:52:43.267939 - (0,) time : 146.02949237823486 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-06-26 19:52:43.268209 - () total time : 146.02949237823486 
DLL 2021-06-26 19:52:43.268234 - () 
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
