train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 20:26:48.167256 - PARAMETER output : ./ 
DLL 2021-06-26 20:26:48.167319 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 20:26:48.167344 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 20:26:48.167363 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 20:26:48.167381 - PARAMETER anneal_steps : None 
DLL 2021-06-26 20:26:48.167403 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 20:26:48.167421 - PARAMETER epochs : 2 
DLL 2021-06-26 20:26:48.167439 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 20:26:48.167455 - PARAMETER checkpoint_path :  
DLL 2021-06-26 20:26:48.167473 - PARAMETER resume_from_last : False 
DLL 2021-06-26 20:26:48.167490 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 20:26:48.167507 - PARAMETER amp : False 
DLL 2021-06-26 20:26:48.167527 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 20:26:48.167544 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 20:26:48.167560 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 20:26:48.167575 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 20:26:48.167591 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 20:26:48.167607 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 20:26:48.167623 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 20:26:48.167639 - PARAMETER batch_size : 52 
DLL 2021-06-26 20:26:48.167654 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 20:26:48.167669 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 20:26:48.167684 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-26 20:26:48.167699 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 20:26:48.167714 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 20:26:48.167732 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 20:26:48.167747 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 20:26:48.167761 - PARAMETER filter_length : 1024 
DLL 2021-06-26 20:26:48.167776 - PARAMETER hop_length : 256 
DLL 2021-06-26 20:26:48.167790 - PARAMETER win_length : 1024 
DLL 2021-06-26 20:26:48.167804 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 20:26:48.167819 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 20:26:48.167833 - PARAMETER rank : 0 
DLL 2021-06-26 20:26:48.167848 - PARAMETER world_size : 4 
DLL 2021-06-26 20:26:48.167865 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 20:26:48.167879 - PARAMETER group_name : group_name 
DLL 2021-06-26 20:26:48.167894 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 20:26:48.167909 - PARAMETER bench_class :  
DLL 2021-06-26 20:26:48.167925 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 20:27:13.103650 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2021-06-26 20:27:54.869013 - (0, 0) train_loss : 46.29345703125 
DLL 2021-06-26 20:27:58.567673 - (0, 0) train_items_per_sec : 2528.2594851232957 
DLL 2021-06-26 20:27:58.567754 - (0, 0) train_iter_time : 45.46408336500099 
DLL 2021-06-26 20:27:58.571950 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2021-06-26 20:28:00.165548 - (0, 1) train_loss : 47.907867431640625 
DLL 2021-06-26 20:28:02.080026 - (0, 1) train_items_per_sec : 33982.310934269684 
DLL 2021-06-26 20:28:02.080112 - (0, 1) train_iter_time : 3.5080898479973257 
DLL 2021-06-26 20:28:02.087339 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2021-06-26 20:28:03.638866 - (0, 2) train_loss : 47.38247299194336 
DLL 2021-06-26 20:28:05.578575 - (0, 2) train_items_per_sec : 33741.558577770855 
DLL 2021-06-26 20:28:05.578654 - (0, 2) train_iter_time : 3.4912435869991896 
DLL 2021-06-26 20:28:05.624755 - (0,) train_items_per_sec : 23417.376332387943 
DLL 2021-06-26 20:28:05.624840 - (0,) train_loss : 47.38247299194336 
DLL 2021-06-26 20:28:05.624868 - (0,) train_epoch_time : 53.503724520000105 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 20:28:06.942354 - (0, 3, 0) val_items_per_sec : 85833.19499453835 
DLL 2021-06-26 20:28:07.020925 - (0,) val_loss : 47.270904541015625 
DLL 2021-06-26 20:28:07.021030 - (0,) val_items_per_sec : 85833.19499453835 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-26 20:28:08.555700 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2021-06-26 20:28:13.924702 - (1, 0) train_loss : 46.58763885498047 
DLL 2021-06-26 20:28:15.895907 - (1, 0) train_items_per_sec : 15770.742421044939 
DLL 2021-06-26 20:28:15.896036 - (1, 0) train_iter_time : 7.340237822001654 
DLL 2021-06-26 20:28:15.905310 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2021-06-26 20:28:17.456118 - (1, 1) train_loss : 47.01559829711914 
DLL 2021-06-26 20:28:21.145536 - (1, 1) train_items_per_sec : 22520.198931582974 
DLL 2021-06-26 20:28:21.145659 - (1, 1) train_iter_time : 5.2402290210011415 
DLL 2021-06-26 20:28:21.154392 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2021-06-26 20:28:22.622294 - (1, 2) train_loss : 47.62334442138672 
DLL 2021-06-26 20:28:24.548200 - (1, 2) train_items_per_sec : 34818.250331762196 
DLL 2021-06-26 20:28:24.548279 - (1, 2) train_iter_time : 3.39382360899981 
DLL 2021-06-26 20:28:24.626230 - (1,) train_items_per_sec : 24369.730561463366 
DLL 2021-06-26 20:28:24.626324 - (1,) train_loss : 47.62334442138672 
DLL 2021-06-26 20:28:24.626381 - (1,) train_epoch_time : 17.118872401999397 
DLL 2021-06-26 20:28:25.934129 - (1, 6, 0) val_items_per_sec : 86397.84592858258 
DLL 2021-06-26 20:28:26.015401 - (1,) val_loss : 47.27293014526367 
DLL 2021-06-26 20:28:26.015504 - (1,) val_items_per_sec : 86397.84592858258 
DLL 2021-06-26 20:28:26.019089 - () run_time : 85.45188660900021 
DLL 2021-06-26 20:28:26.019183 - () val_loss : 47.27293014526367 
DLL 2021-06-26 20:28:26.019239 - () train_items_per_sec : 24369.730561463366 
DONE!
