train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-29 09:55:54.072618 - PARAMETER output : ./ 
DLL 2021-06-29 09:55:54.072693 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-29 09:55:54.072721 - PARAMETER model_name : Tacotron2 
DLL 2021-06-29 09:55:54.072743 - PARAMETER log_file : nvlog.json 
DLL 2021-06-29 09:55:54.072764 - PARAMETER anneal_steps : None 
DLL 2021-06-29 09:55:54.072787 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-29 09:55:54.072808 - PARAMETER epochs : 2 
DLL 2021-06-29 09:55:54.072827 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-29 09:55:54.072845 - PARAMETER checkpoint_path :  
DLL 2021-06-29 09:55:54.072865 - PARAMETER resume_from_last : False 
DLL 2021-06-29 09:55:54.072885 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-29 09:55:54.072903 - PARAMETER amp : False 
DLL 2021-06-29 09:55:54.072924 - PARAMETER cudnn_enabled : True 
DLL 2021-06-29 09:55:54.072942 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-29 09:55:54.072959 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-29 09:55:54.072976 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-29 09:55:54.072992 - PARAMETER learning_rate : 0.0 
DLL 2021-06-29 09:55:54.073011 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-29 09:55:54.073030 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-29 09:55:54.073049 - PARAMETER batch_size : 52 
DLL 2021-06-29 09:55:54.073066 - PARAMETER grad_clip : 5.0 
DLL 2021-06-29 09:55:54.073084 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-29 09:55:54.073101 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-29 09:55:54.073118 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-29 09:55:54.073134 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-29 09:55:54.073154 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-29 09:55:54.073171 - PARAMETER sampling_rate : 22050 
DLL 2021-06-29 09:55:54.073188 - PARAMETER filter_length : 1024 
DLL 2021-06-29 09:55:54.073204 - PARAMETER hop_length : 256 
DLL 2021-06-29 09:55:54.073221 - PARAMETER win_length : 1024 
DLL 2021-06-29 09:55:54.073237 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-29 09:55:54.073253 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-29 09:55:54.073270 - PARAMETER rank : 0 
DLL 2021-06-29 09:55:54.073286 - PARAMETER world_size : 4 
DLL 2021-06-29 09:55:54.073305 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-29 09:55:54.073321 - PARAMETER group_name : group_name 
DLL 2021-06-29 09:55:54.073337 - PARAMETER dist_backend : nccl 
DLL 2021-06-29 09:55:54.073356 - PARAMETER bench_class :  
DLL 2021-06-29 09:55:54.073373 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:56:05.855431 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2021-06-29 09:56:15.402405 - (0, 0) train_loss : 46.16665267944336 
DLL 2021-06-29 09:56:17.589904 - (0, 0) train_items_per_sec : 9795.459882015026 
DLL 2021-06-29 09:56:17.589985 - (0, 0) train_iter_time : 11.734517968987348 
DLL 2021-06-29 09:56:17.594829 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2021-06-29 09:56:18.415588 - (0, 1) train_loss : 47.76948547363281 
DLL 2021-06-29 09:56:20.341628 - (0, 1) train_items_per_sec : 43400.53265411317 
DLL 2021-06-29 09:56:20.341707 - (0, 1) train_iter_time : 2.746809606003808 
DLL 2021-06-29 09:56:20.348093 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2021-06-29 09:56:21.146733 - (0, 2) train_loss : 47.26056671142578 
DLL 2021-06-29 09:56:23.084781 - (0, 2) train_items_per_sec : 43044.795473414735 
DLL 2021-06-29 09:56:23.084871 - (0, 2) train_iter_time : 2.736683929018909 
DLL 2021-06-29 09:56:23.128791 - (0,) train_items_per_sec : 32080.26266984765 
DLL 2021-06-29 09:56:23.128865 - (0,) train_loss : 47.26056671142578 
DLL 2021-06-29 09:56:23.128910 - (0,) train_epoch_time : 18.33565796399489 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:56:24.446561 - (0, 3, 0) val_items_per_sec : 86571.97372380238 
DLL 2021-06-29 09:56:24.531694 - (0,) val_loss : 47.14030456542969 
DLL 2021-06-29 09:56:24.531823 - (0,) val_items_per_sec : 86571.97372380238 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-06-29 09:56:26.360199 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2021-06-29 09:56:27.591617 - (1, 0) train_loss : 46.46063232421875 
DLL 2021-06-29 09:56:29.527168 - (1, 0) train_items_per_sec : 36552.032262771936 
DLL 2021-06-29 09:56:29.527249 - (1, 0) train_iter_time : 3.1670195289771073 
DLL 2021-06-29 09:56:29.535475 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2021-06-29 09:56:30.398668 - (1, 1) train_loss : 46.89059066772461 
DLL 2021-06-29 09:56:32.509865 - (1, 1) train_items_per_sec : 39675.629487741426 
DLL 2021-06-29 09:56:32.509944 - (1, 1) train_iter_time : 2.97439515197766 
DLL 2021-06-29 09:56:32.521854 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2021-06-29 09:56:33.307272 - (1, 2) train_loss : 47.493343353271484 
DLL 2021-06-29 09:56:35.229703 - (1, 2) train_items_per_sec : 43638.581715683824 
DLL 2021-06-29 09:56:35.229783 - (1, 2) train_iter_time : 2.7078561070084106 
DLL 2021-06-29 09:56:35.296924 - (1,) train_items_per_sec : 39955.4144887324 
DLL 2021-06-29 09:56:35.297006 - (1,) train_loss : 47.493343353271484 
DLL 2021-06-29 09:56:35.297035 - (1,) train_epoch_time : 10.03160572500201 
DLL 2021-06-29 09:56:36.678359 - (1, 6, 0) val_items_per_sec : 79315.70675219585 
DLL 2021-06-29 09:56:36.756138 - (1,) val_loss : 47.145877838134766 
DLL 2021-06-29 09:56:36.756244 - (1,) val_items_per_sec : 79315.70675219585 
DLL 2021-06-29 09:56:36.759117 - () run_time : 39.396344179986045 
DLL 2021-06-29 09:56:36.759176 - () val_loss : 47.145877838134766 
DLL 2021-06-29 09:56:36.759210 - () train_items_per_sec : 39955.4144887324 
DONE!
