train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-11-26 08:54:16.271921 - PARAMETER output : ./ 
DLL 2021-11-26 08:54:16.271991 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-11-26 08:54:16.272014 - PARAMETER model_name : Tacotron2 
DLL 2021-11-26 08:54:16.272036 - PARAMETER log_file : nvlog.json 
DLL 2021-11-26 08:54:16.272053 - PARAMETER anneal_steps : None 
DLL 2021-11-26 08:54:16.272070 - PARAMETER anneal_factor : 0.1 
DLL 2021-11-26 08:54:16.272087 - PARAMETER epochs : 2 
DLL 2021-11-26 08:54:16.272104 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-11-26 08:54:16.272120 - PARAMETER checkpoint_path :  
DLL 2021-11-26 08:54:16.272139 - PARAMETER resume_from_last : False 
DLL 2021-11-26 08:54:16.272159 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-11-26 08:54:16.272178 - PARAMETER amp : False 
DLL 2021-11-26 08:54:16.272197 - PARAMETER cudnn_enabled : True 
DLL 2021-11-26 08:54:16.272213 - PARAMETER cudnn_benchmark : False 
DLL 2021-11-26 08:54:16.272229 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-11-26 08:54:16.272243 - PARAMETER use_saved_learning_rate : False 
DLL 2021-11-26 08:54:16.272258 - PARAMETER learning_rate : 0.0 
DLL 2021-11-26 08:54:16.272289 - PARAMETER weight_decay : 1e-06 
DLL 2021-11-26 08:54:16.272316 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-11-26 08:54:16.272345 - PARAMETER batch_size : 256 
DLL 2021-11-26 08:54:16.272371 - PARAMETER grad_clip : 5.0 
DLL 2021-11-26 08:54:16.272393 - PARAMETER load_mel_from_disk : False 
DLL 2021-11-26 08:54:16.272413 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_2500_filelist.txt 
DLL 2021-11-26 08:54:16.272429 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-11-26 08:54:16.272445 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-11-26 08:54:16.272464 - PARAMETER max_wav_value : 32768.0 
DLL 2021-11-26 08:54:16.272480 - PARAMETER sampling_rate : 22050 
DLL 2021-11-26 08:54:16.272495 - PARAMETER filter_length : 1024 
DLL 2021-11-26 08:54:16.272509 - PARAMETER hop_length : 256 
DLL 2021-11-26 08:54:16.272524 - PARAMETER win_length : 1024 
DLL 2021-11-26 08:54:16.272539 - PARAMETER mel_fmin : 0.0 
DLL 2021-11-26 08:54:16.272554 - PARAMETER mel_fmax : 8000.0 
DLL 2021-11-26 08:54:16.272570 - PARAMETER rank : 0 
DLL 2021-11-26 08:54:16.272584 - PARAMETER world_size : 8 
DLL 2021-11-26 08:54:16.272601 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-11-26 08:54:16.272616 - PARAMETER group_name : group_name 
DLL 2021-11-26 08:54:16.272630 - PARAMETER dist_backend : nccl 
DLL 2021-11-26 08:54:16.272646 - PARAMETER bench_class :  
DLL 2021-11-26 08:54:16.272662 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-11-26 08:54:50.100982 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-11-26 08:55:27.024522 - (0, 0) train_loss : 46.486358642578125 
DLL 2021-11-26 08:55:29.599332 - (0, 0) train_items_per_sec : 29387.580905057544 
DLL 2021-11-26 08:55:29.599438 - (0, 0) train_iter_time : 39.498385517000315 
DLL 2021-11-26 08:55:29.645131 - (0,) train_items_per_sec : 29387.580905057544 
DLL 2021-11-26 08:55:29.645234 - (0,) train_loss : 46.486358642578125 
DLL 2021-11-26 08:55:29.645459 - (0,) train_epoch_time : 44.05012845999954 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-11-26 08:55:30.686173 - (0, 1, 0) val_items_per_sec : 100773.71461977709 
DLL 2021-11-26 08:55:30.759288 - (0,) val_loss : 48.03141784667969 
DLL 2021-11-26 08:55:30.759394 - (0,) val_items_per_sec : 100773.71461977709 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-11-26 08:55:36.540753 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-11-26 08:55:39.289164 - (1, 0) train_loss : 46.42502975463867 
DLL 2021-11-26 08:55:41.217339 - (1, 0) train_items_per_sec : 247663.42929403458 
DLL 2021-11-26 08:55:41.217427 - (1, 0) train_iter_time : 4.676616985000692 
DLL 2021-11-26 08:55:41.292017 - (1,) train_items_per_sec : 247663.42929403458 
DLL 2021-11-26 08:55:41.292118 - (1,) train_loss : 46.42502975463867 
DLL 2021-11-26 08:55:41.292153 - (1,) train_epoch_time : 9.151299297999685 
DLL 2021-11-26 08:55:42.364850 - (1, 2, 0) val_items_per_sec : 93087.98518577425 
DLL 2021-11-26 08:55:42.433518 - (1,) val_loss : 48.04098892211914 
DLL 2021-11-26 08:55:42.433636 - (1,) val_items_per_sec : 93087.98518577425 
DLL 2021-11-26 08:55:42.435499 - () run_time : 80.27227942399986 
DLL 2021-11-26 08:55:42.435551 - () val_loss : 48.04098892211914 
DLL 2021-11-26 08:55:42.435579 - () train_items_per_sec : 247663.42929403458 
DONE!
