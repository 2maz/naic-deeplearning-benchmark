DLL 2020-11-04 07:50:52.954490 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 224  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2020-11-04 07:50:52.954881 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 224  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2020-11-04 07:50:52.955062 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 224  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2020-11-04 07:50:52.957931 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 224  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
Using seed = 6045
loading annotations into memory...
Done (t=0.64s)
creating index...
index created!
/workspace/examples/ssd/src/coco_pipeline.py:63: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
  pad_output=pad_output)
Using seed = 8299
loading annotations into memory...
Using seed = 3669
Using seed = 7634
loading annotations into memory...
loading annotations into memory...
Done (t=0.67s)
creating index...
index created!
/workspace/examples/ssd/src/coco_pipeline.py:63: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
  pad_output=pad_output)
Done (t=0.67s)
creating index...
Done (t=0.68s)
creating index...
index created!
/workspace/examples/ssd/src/coco_pipeline.py:63: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
  pad_output=pad_output)
index created!
/workspace/examples/ssd/src/coco_pipeline.py:63: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
  pad_output=pad_output)
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:127: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
DLL 2020-11-04 07:52:46.205613 - () avg_img/sec : 399.1339843084849  med_img/sec : 399.0541437631364  min_img/sec : 391.268826231955  max_img/sec : 405.0835696799167 
Done benchmarking. Total images: 22400	total time: 56.122	Average images/sec: 399.134	Median images/sec: 399.054
DLL 2020-11-04 07:52:46.205811 - () avg_img/sec : 399.0247905854174  med_img/sec : 398.9195381884216  min_img/sec : 391.2743664599636  max_img/sec : 404.1434919941206 
Done benchmarking. Total images: 22400	total time: 56.137	Average images/sec: 399.025	Median images/sec: 398.920
DLL 2020-11-04 07:52:46.205861 - () avg_img/sec : 399.1605581974699  med_img/sec : 399.0746541434113  min_img/sec : 391.4683733333333  max_img/sec : 404.38388927697844 
Done benchmarking. Total images: 22400	total time: 56.118	Average images/sec: 399.161	Median images/sec: 399.075
DLL 2020-11-04 07:52:46.205993 - () avg_img/sec : 399.23133515490616  med_img/sec : 399.2207485732524  min_img/sec : 391.49055779827523  max_img/sec : 404.4335002681805 
Done benchmarking. Total images: 22400	total time: 56.108	Average images/sec: 399.231	Median images/sec: 399.221
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
Training performance = 1596.26904296875 FPS
DLL 2020-11-04 07:52:46.206265 - () total time : 100.52832102775574 
DLL 2020-11-04 07:52:46.206287 - () 
DLL 2020-11-04 07:52:46.206372 - (0,) time : 100.53723812103271 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-11-04 07:52:46.206603 - () total time : 100.5308883190155 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2020-11-04 07:52:46.206616 - () total time : 100.5294897556305 
DLL 2020-11-04 07:52:46.206625 - () 
DLL 2020-11-04 07:52:46.206638 - () 
DLL 2020-11-04 07:52:46.206640 - () total time : 100.53723812103271 
DLL 2020-11-04 07:52:46.206655 - () 
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
