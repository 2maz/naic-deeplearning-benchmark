Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  1%|          | 768k/97.8M [00:00<00:13, 7.75MB/s]  1%|          | 872k/97.8M [00:00<00:11, 8.86MB/s]  1%|          | 640k/97.8M [00:00<00:15, 6.52MB/s]  1%|          | 632k/97.8M [00:00<00:15, 6.47MB/s]  4%|▍         | 3.98M/97.8M [00:00<00:09, 10.1MB/s]  5%|▍         | 4.47M/97.8M [00:00<00:08, 11.5MB/s]  4%|▍         | 3.80M/97.8M [00:00<00:11, 8.59MB/s]  3%|▎         | 2.90M/97.8M [00:00<00:12, 8.28MB/s]  6%|▋         | 6.29M/97.8M [00:00<00:07, 12.2MB/s]  7%|▋         | 6.70M/97.8M [00:00<00:07, 13.6MB/s]  7%|▋         | 7.30M/97.8M [00:00<00:08, 11.1MB/s]  5%|▌         | 4.91M/97.8M [00:00<00:09, 10.1MB/s] 10%|▉         | 9.34M/97.8M [00:00<00:06, 15.0MB/s] 10%|█         | 9.88M/97.8M [00:00<00:05, 16.5MB/s] 10%|█         | 9.99M/97.8M [00:00<00:06, 13.5MB/s]  7%|▋         | 7.30M/97.8M [00:00<00:07, 12.3MB/s] 13%|█▎        | 12.7M/97.8M [00:00<00:04, 18.1MB/s] 13%|█▎        | 12.9M/97.8M [00:00<00:04, 19.2MB/s] 13%|█▎        | 12.8M/97.8M [00:00<00:05, 16.1MB/s]  9%|▉         | 8.96M/97.8M [00:00<00:06, 13.4MB/s] 16%|█▋        | 16.1M/97.8M [00:00<00:04, 21.2MB/s] 17%|█▋        | 16.3M/97.8M [00:00<00:03, 22.2MB/s] 16%|█▌        | 15.6M/97.8M [00:00<00:04, 18.6MB/s] 11%|█         | 10.5M/97.8M [00:00<00:06, 13.3MB/s] 20%|██        | 19.6M/97.8M [00:00<00:03, 24.3MB/s] 21%|██        | 20.4M/97.8M [00:00<00:03, 26.0MB/s] 18%|█▊        | 18.1M/97.8M [00:00<00:04, 20.3MB/s] 13%|█▎        | 12.6M/97.8M [00:00<00:05, 15.0MB/s] 23%|██▎       | 22.5M/97.8M [00:00<00:03, 25.8MB/s] 24%|██▍       | 23.5M/97.8M [00:00<00:02, 26.8MB/s] 21%|██▏       | 21.0M/97.8M [00:00<00:03, 22.5MB/s] 15%|█▌        | 15.0M/97.8M [00:00<00:05, 17.1MB/s] 26%|██▌       | 25.4M/97.8M [00:00<00:02, 26.4MB/s] 27%|██▋       | 26.6M/97.8M [00:00<00:02, 28.2MB/s] 25%|██▍       | 24.0M/97.8M [00:00<00:03, 24.5MB/s] 18%|█▊        | 17.4M/97.8M [00:00<00:04, 18.9MB/s] 29%|██▉       | 28.3M/97.8M [00:01<00:02, 27.5MB/s] 30%|███       | 29.7M/97.8M [00:01<00:02, 29.4MB/s] 27%|██▋       | 26.7M/97.8M [00:01<00:02, 25.4MB/s] 20%|██        | 19.7M/97.8M [00:01<00:04, 20.1MB/s] 32%|███▏      | 31.2M/97.8M [00:01<00:02, 28.1MB/s] 34%|███▍      | 33.0M/97.8M [00:01<00:02, 30.7MB/s] 30%|███       | 29.3M/97.8M [00:01<00:02, 25.8MB/s] 23%|██▎       | 22.0M/97.8M [00:01<00:03, 21.2MB/s] 35%|███▌      | 34.2M/97.8M [00:01<00:02, 29.1MB/s] 37%|███▋      | 36.3M/97.8M [00:01<00:02, 31.7MB/s] 33%|███▎      | 32.0M/97.8M [00:01<00:02, 26.2MB/s] 25%|██▍       | 24.4M/97.8M [00:01<00:03, 22.2MB/s] 38%|███▊      | 37.1M/97.8M [00:01<00:02, 28.8MB/s] 40%|████      | 39.4M/97.8M [00:01<00:01, 31.8MB/s] 35%|███▌      | 34.7M/97.8M [00:01<00:02, 26.9MB/s] 27%|██▋       | 26.9M/97.8M [00:01<00:03, 23.0MB/s] 41%|████      | 40.0M/97.8M [00:01<00:02, 29.0MB/s] 44%|████▍     | 42.9M/97.8M [00:01<00:01, 33.1MB/s] 38%|███▊      | 37.4M/97.8M [00:01<00:02, 27.0MB/s] 30%|██▉       | 29.3M/97.8M [00:01<00:03, 23.7MB/s] 44%|████▍     | 42.8M/97.8M [00:01<00:01, 29.1MB/s] 47%|████▋     | 46.3M/97.8M [00:01<00:01, 33.7MB/s] 41%|████      | 40.0M/97.8M [00:01<00:02, 26.6MB/s] 32%|███▏      | 31.6M/97.8M [00:01<00:02, 23.8MB/s] 47%|████▋     | 45.6M/97.8M [00:01<00:01, 29.0MB/s] 51%|█████     | 49.7M/97.8M [00:01<00:01, 34.3MB/s] 44%|████▎     | 42.6M/97.8M [00:01<00:02, 26.4MB/s] 35%|███▍      | 34.0M/97.8M [00:01<00:02, 24.2MB/s] 50%|████▉     | 48.4M/97.8M [00:01<00:01, 29.1MB/s] 54%|█████▍    | 53.1M/97.8M [00:01<00:01, 34.5MB/s] 46%|████▌     | 45.1M/97.8M [00:01<00:02, 26.1MB/s] 37%|███▋      | 36.5M/97.8M [00:01<00:02, 24.8MB/s] 52%|█████▏    | 51.2M/97.8M [00:01<00:01, 29.1MB/s] 58%|█████▊    | 56.4M/97.8M [00:01<00:01, 34.7MB/s] 49%|████▉     | 47.7M/97.8M [00:01<00:02, 25.7MB/s] 40%|████      | 39.1M/97.8M [00:01<00:02, 25.3MB/s] 55%|█████▌    | 54.0M/97.8M [00:01<00:01, 28.7MB/s] 61%|██████    | 59.9M/97.8M [00:01<00:01, 35.0MB/s] 51%|█████▏    | 50.1M/97.8M [00:01<00:01, 25.6MB/s] 43%|████▎     | 41.6M/97.8M [00:01<00:02, 25.5MB/s] 58%|█████▊    | 56.8M/97.8M [00:02<00:01, 28.5MB/s] 65%|██████▍   | 63.4M/97.8M [00:02<00:01, 35.5MB/s] 54%|█████▍    | 52.6M/97.8M [00:02<00:01, 25.2MB/s] 45%|████▌     | 44.1M/97.8M [00:02<00:02, 25.3MB/s] 61%|██████    | 59.5M/97.8M [00:02<00:01, 28.5MB/s] 68%|██████▊   | 66.8M/97.8M [00:02<00:00, 35.5MB/s] 56%|█████▋    | 55.1M/97.8M [00:02<00:01, 25.3MB/s] 48%|████▊     | 46.7M/97.8M [00:02<00:02, 25.9MB/s] 64%|██████▎   | 62.2M/97.8M [00:02<00:01, 28.5MB/s] 72%|███████▏  | 70.2M/97.8M [00:02<00:00, 35.5MB/s] 59%|█████▉    | 57.7M/97.8M [00:02<00:01, 25.8MB/s] 50%|█████     | 49.3M/97.8M [00:02<00:01, 26.2MB/s] 66%|██████▋   | 65.0M/97.8M [00:02<00:01, 28.4MB/s] 75%|███████▌  | 73.6M/97.8M [00:02<00:00, 35.2MB/s] 62%|██████▏   | 60.2M/97.8M [00:02<00:01, 25.9MB/s] 53%|█████▎    | 51.8M/97.8M [00:02<00:01, 26.2MB/s] 79%|███████▊  | 76.9M/97.8M [00:02<00:00, 35.2MB/s] 69%|██████▉   | 67.7M/97.8M [00:02<00:01, 27.9MB/s] 64%|██████▍   | 62.7M/97.8M [00:02<00:01, 26.0MB/s] 56%|█████▌    | 54.4M/97.8M [00:02<00:01, 26.5MB/s] 82%|████████▏ | 80.3M/97.8M [00:02<00:00, 35.2MB/s] 72%|███████▏  | 70.4M/97.8M [00:02<00:01, 27.8MB/s] 67%|██████▋   | 65.2M/97.8M [00:02<00:01, 25.8MB/s] 58%|█████▊    | 57.0M/97.8M [00:02<00:01, 26.7MB/s] 86%|████████▌ | 83.7M/97.8M [00:02<00:00, 35.4MB/s] 75%|███████▍  | 73.0M/97.8M [00:02<00:00, 27.5MB/s] 69%|██████▉   | 67.6M/97.8M [00:02<00:01, 25.7MB/s] 61%|██████    | 59.7M/97.8M [00:02<00:01, 27.0MB/s] 89%|████████▉ | 87.2M/97.8M [00:02<00:00, 35.7MB/s] 77%|███████▋  | 75.7M/97.8M [00:02<00:00, 27.7MB/s] 64%|██████▎   | 62.3M/97.8M [00:02<00:01, 27.0MB/s] 72%|███████▏  | 70.1M/97.8M [00:02<00:01, 25.0MB/s] 93%|█████████▎| 90.7M/97.8M [00:02<00:00, 36.1MB/s] 80%|████████  | 78.3M/97.8M [00:02<00:00, 27.6MB/s] 66%|██████▋   | 64.8M/97.8M [00:02<00:01, 26.7MB/s] 74%|███████▍  | 72.5M/97.8M [00:02<00:01, 24.7MB/s] 96%|█████████▋| 94.2M/97.8M [00:02<00:00, 36.4MB/s] 83%|████████▎ | 81.0M/97.8M [00:02<00:00, 27.7MB/s] 69%|██████▉   | 67.4M/97.8M [00:02<00:01, 26.7MB/s] 77%|███████▋  | 74.8M/97.8M [00:02<00:00, 24.5MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 33.9MB/s]
 86%|████████▌ | 83.7M/97.8M [00:03<00:00, 27.9MB/s] 72%|███████▏  | 70.4M/97.8M [00:03<00:01, 28.0MB/s] 79%|███████▉  | 77.4M/97.8M [00:03<00:00, 25.2MB/s] 89%|████████▉ | 87.0M/97.8M [00:03<00:00, 29.6MB/s] 75%|███████▍  | 73.3M/97.8M [00:03<00:00, 28.5MB/s] 82%|████████▏ | 80.1M/97.8M [00:03<00:00, 26.1MB/s] 92%|█████████▏| 90.2M/97.8M [00:03<00:00, 30.6MB/s] 78%|███████▊  | 76.2M/97.8M [00:03<00:00, 29.0MB/s] 85%|████████▌ | 83.1M/97.8M [00:03<00:00, 27.5MB/s] 96%|█████████▌| 93.7M/97.8M [00:03<00:00, 32.2MB/s] 81%|████████  | 79.4M/97.8M [00:03<00:00, 30.2MB/s] 89%|████████▊ | 86.5M/97.8M [00:03<00:00, 29.5MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 29.7MB/s]
DLL 2021-11-26 10:02:07.833761 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 448  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
 85%|████████▍ | 82.9M/97.8M [00:03<00:00, 31.9MB/s] 93%|█████████▎| 90.6M/97.8M [00:03<00:00, 32.5MB/s] 89%|████████▊ | 86.6M/97.8M [00:03<00:00, 33.6MB/s] 97%|█████████▋| 95.3M/97.8M [00:03<00:00, 36.2MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 28.2MB/s]
 93%|█████████▎| 90.6M/97.8M [00:03<00:00, 35.8MB/s] 98%|█████████▊| 95.4M/97.8M [00:03<00:00, 39.1MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 26.9MB/s]
DLL 2021-11-26 10:02:09.152532 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 448  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2021-11-26 10:02:09.166110 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 448  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2021-11-26 10:02:09.169821 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 448  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
Using seed = 5908
Using seed = 8553
Using seed = 2588
Using seed = 7413
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.35s)
creating index...
Done (t=0.36s)
creating index...
Done (t=0.36s)
creating index...
Done (t=0.36s)
creating index...
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0

Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0


Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0
DLL 2021-11-26 10:05:57.279582 - () avg_img/sec : 411.42647717043286  med_img/sec : 411.37511598841786  min_img/sec : 407.04214500293307  max_img/sec : 415.2695474451522 
Done benchmarking. Total images: 44800	total time: 108.889	Average images/sec: 411.426	Median images/sec: 411.375
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-11-26 10:05:57.298530 - () total time : 210.18733024597168 
DLL 2021-11-26 10:05:57.298563 - () 
DLL 2021-11-26 10:05:57.298607 - () avg_img/sec : 412.3169732070751  med_img/sec : 412.30430010013094  min_img/sec : 405.7941758475514  max_img/sec : 416.0000708443899 
Done benchmarking. Total images: 44800	total time: 108.654	Average images/sec: 412.317	Median images/sec: 412.304
DLL 2021-11-26 10:05:57.298739 - () avg_img/sec : 411.42864910160563  med_img/sec : 411.54702390859086  min_img/sec : 407.76256544866186  max_img/sec : 414.8597200751188 
Done benchmarking. Total images: 44800	total time: 108.889	Average images/sec: 411.429	Median images/sec: 411.547
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-11-26 10:05:57.299512 - () total time : 210.18781566619873 
DLL 2021-11-26 10:05:57.299561 - () 
DLL 2021-11-26 10:05:57.302757 - () avg_img/sec : 411.6386392121529  med_img/sec : 411.4255120546548  min_img/sec : 407.7991136293646  max_img/sec : 414.9085451524402 
Done benchmarking. Total images: 44800	total time: 108.833	Average images/sec: 411.639	Median images/sec: 411.426
Training performance = 1646.6519775390625 FPS
DLL 2021-11-26 10:05:57.303516 - (0,) time : 210.23992824554443 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-11-26 10:05:57.303697 - () total time : 210.19188690185547 
DLL 2021-11-26 10:05:57.303762 - () 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-11-26 10:05:57.304187 - () total time : 210.23992824554443 
DLL 2021-11-26 10:05:57.304229 - () 
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
