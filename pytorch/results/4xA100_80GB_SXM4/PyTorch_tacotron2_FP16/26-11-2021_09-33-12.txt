train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-11-26 09:33:14.285932 - PARAMETER output : ./ 
DLL 2021-11-26 09:33:14.285997 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-11-26 09:33:14.286019 - PARAMETER model_name : Tacotron2 
DLL 2021-11-26 09:33:14.286038 - PARAMETER log_file : nvlog.json 
DLL 2021-11-26 09:33:14.286054 - PARAMETER anneal_steps : None 
DLL 2021-11-26 09:33:14.286070 - PARAMETER anneal_factor : 0.1 
DLL 2021-11-26 09:33:14.286086 - PARAMETER epochs : 3 
DLL 2021-11-26 09:33:14.286102 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-11-26 09:33:14.286117 - PARAMETER checkpoint_path :  
DLL 2021-11-26 09:33:14.286132 - PARAMETER resume_from_last : False 
DLL 2021-11-26 09:33:14.286149 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-11-26 09:33:14.286165 - PARAMETER amp : False 
DLL 2021-11-26 09:33:14.286180 - PARAMETER cudnn_enabled : True 
DLL 2021-11-26 09:33:14.286195 - PARAMETER cudnn_benchmark : False 
DLL 2021-11-26 09:33:14.286209 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-11-26 09:33:14.286224 - PARAMETER use_saved_learning_rate : False 
DLL 2021-11-26 09:33:14.286238 - PARAMETER learning_rate : 0.0 
DLL 2021-11-26 09:33:14.286252 - PARAMETER weight_decay : 1e-06 
DLL 2021-11-26 09:33:14.286267 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-11-26 09:33:14.286281 - PARAMETER batch_size : 256 
DLL 2021-11-26 09:33:14.286295 - PARAMETER grad_clip : 5.0 
DLL 2021-11-26 09:33:14.286309 - PARAMETER load_mel_from_disk : False 
DLL 2021-11-26 09:33:14.286323 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-11-26 09:33:14.286338 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-11-26 09:33:14.286352 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-11-26 09:33:14.286369 - PARAMETER max_wav_value : 32768.0 
DLL 2021-11-26 09:33:14.286384 - PARAMETER sampling_rate : 22050 
DLL 2021-11-26 09:33:14.286398 - PARAMETER filter_length : 1024 
DLL 2021-11-26 09:33:14.286412 - PARAMETER hop_length : 256 
DLL 2021-11-26 09:33:14.286426 - PARAMETER win_length : 1024 
DLL 2021-11-26 09:33:14.286439 - PARAMETER mel_fmin : 0.0 
DLL 2021-11-26 09:33:14.286453 - PARAMETER mel_fmax : 8000.0 
DLL 2021-11-26 09:33:14.286467 - PARAMETER rank : 0 
DLL 2021-11-26 09:33:14.286481 - PARAMETER world_size : 4 
DLL 2021-11-26 09:33:14.286495 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-11-26 09:33:14.286508 - PARAMETER group_name : group_name 
DLL 2021-11-26 09:33:14.286522 - PARAMETER dist_backend : nccl 
DLL 2021-11-26 09:33:14.286535 - PARAMETER bench_class :  
DLL 2021-11-26 09:33:14.286550 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2021-11-26 09:33:38.028708 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-11-26 09:34:06.033440 - (0, 0) train_loss : 47.00763702392578 
DLL 2021-11-26 09:34:09.788309 - (0, 0) train_items_per_sec : 18246.527925952287 
DLL 2021-11-26 09:34:09.788420 - (0, 0) train_iter_time : 31.7596861359998 
DLL 2021-11-26 09:34:09.822304 - (0,) train_items_per_sec : 18246.527925952287 
DLL 2021-11-26 09:34:09.822365 - (0,) train_loss : 47.00763702392578 
DLL 2021-11-26 09:34:09.822567 - (0,) train_epoch_time : 36.141617039000266 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-11-26 09:34:10.931762 - (0, 1, 0) val_items_per_sec : 97439.29300812194 
DLL 2021-11-26 09:34:10.980313 - (0,) val_loss : 47.2637939453125 
DLL 2021-11-26 09:34:10.980452 - (0,) val_items_per_sec : 97439.29300812194 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-11-26 09:34:15.712267 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-11-26 09:34:20.640755 - (1, 0) train_loss : 47.2879524230957 
DLL 2021-11-26 09:34:22.461191 - (1, 0) train_items_per_sec : 86384.11435187302 
DLL 2021-11-26 09:34:22.461280 - (1, 0) train_iter_time : 6.748983935000069 
DLL 2021-11-26 09:34:22.513806 - (1,) train_items_per_sec : 86384.11435187302 
DLL 2021-11-26 09:34:22.513871 - (1,) train_loss : 47.2879524230957 
DLL 2021-11-26 09:34:22.513896 - (1,) train_epoch_time : 11.14352043100007 
DLL 2021-11-26 09:34:23.726162 - (1, 2, 0) val_items_per_sec : 91840.76068622274 
DLL 2021-11-26 09:34:23.784229 - (1,) val_loss : 47.26365661621094 
DLL 2021-11-26 09:34:23.784365 - (1,) val_items_per_sec : 91840.76068622274 
DLL 2021-11-26 09:34:28.204893 - (2, 0) glob_iter/iters_per_epoch : 2/1 
DLL 2021-11-26 09:34:34.708774 - (2, 0) train_loss : 47.07746887207031 
DLL 2021-11-26 09:34:36.541687 - (2, 0) train_items_per_sec : 69770.51553407882 
DLL 2021-11-26 09:34:36.541773 - (2, 0) train_iter_time : 8.336831046000952 
DLL 2021-11-26 09:34:36.589610 - (2,) train_items_per_sec : 69770.51553407882 
DLL 2021-11-26 09:34:36.589735 - (2,) train_loss : 47.07746887207031 
DLL 2021-11-26 09:34:36.589761 - (2,) train_epoch_time : 12.803624334999768 
DLL 2021-11-26 09:34:37.740954 - (2, 3, 0) val_items_per_sec : 100269.4436218308 
DLL 2021-11-26 09:34:37.788129 - (2,) val_loss : 47.2642822265625 
DLL 2021-11-26 09:34:37.788230 - (2,) val_items_per_sec : 100269.4436218308 
DLL 2021-11-26 09:34:37.791366 - () run_time : 76.6242230150001 
DLL 2021-11-26 09:34:37.791460 - () val_loss : 47.2642822265625 
DLL 2021-11-26 09:34:37.791512 - () train_items_per_sec : 69770.51553407882 
DONE!
