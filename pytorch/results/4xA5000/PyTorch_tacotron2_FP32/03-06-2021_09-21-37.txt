train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-03 09:21:39.227631 - PARAMETER output : ./ 
DLL 2021-06-03 09:21:39.227680 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-03 09:21:39.227698 - PARAMETER model_name : Tacotron2 
DLL 2021-06-03 09:21:39.227714 - PARAMETER log_file : nvlog.json 
DLL 2021-06-03 09:21:39.227728 - PARAMETER anneal_steps : None 
DLL 2021-06-03 09:21:39.227742 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-03 09:21:39.227756 - PARAMETER epochs : 2 
DLL 2021-06-03 09:21:39.227770 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-03 09:21:39.227783 - PARAMETER checkpoint_path :  
DLL 2021-06-03 09:21:39.227795 - PARAMETER resume_from_last : False 
DLL 2021-06-03 09:21:39.227809 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-03 09:21:39.227824 - PARAMETER amp : False 
DLL 2021-06-03 09:21:39.227839 - PARAMETER cudnn_enabled : True 
DLL 2021-06-03 09:21:39.227852 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-03 09:21:39.227865 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-03 09:21:39.227878 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-03 09:21:39.227891 - PARAMETER learning_rate : 0.0 
DLL 2021-06-03 09:21:39.227905 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-03 09:21:39.227919 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-03 09:21:39.227933 - PARAMETER batch_size : 80 
DLL 2021-06-03 09:21:39.227945 - PARAMETER grad_clip : 5.0 
DLL 2021-06-03 09:21:39.227958 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-03 09:21:39.227970 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-06-03 09:21:39.227983 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-03 09:21:39.227996 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-03 09:21:39.228013 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-03 09:21:39.228026 - PARAMETER sampling_rate : 22050 
DLL 2021-06-03 09:21:39.228039 - PARAMETER filter_length : 1024 
DLL 2021-06-03 09:21:39.228051 - PARAMETER hop_length : 256 
DLL 2021-06-03 09:21:39.228064 - PARAMETER win_length : 1024 
DLL 2021-06-03 09:21:39.228076 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-03 09:21:39.228089 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-03 09:21:39.228102 - PARAMETER rank : 0 
DLL 2021-06-03 09:21:39.228114 - PARAMETER world_size : 4 
DLL 2021-06-03 09:21:39.228127 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-03 09:21:39.228139 - PARAMETER group_name : group_name 
DLL 2021-06-03 09:21:39.228151 - PARAMETER dist_backend : nccl 
DLL 2021-06-03 09:21:39.228165 - PARAMETER bench_class :  
DLL 2021-06-03 09:21:39.228178 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-03 09:21:57.986568 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2021-06-03 09:22:14.887401 - (0, 0) train_loss : 47.11397171020508 
DLL 2021-06-03 09:22:18.026707 - (0, 0) train_items_per_sec : 9061.997613509226 
DLL 2021-06-03 09:22:18.026778 - (0, 0) train_iter_time : 20.04017301100066 
DLL 2021-06-03 09:22:18.030310 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2021-06-03 09:22:18.966752 - (0, 1) train_loss : 47.151981353759766 
DLL 2021-06-03 09:22:20.571494 - (0, 1) train_items_per_sec : 72358.31428286213 
DLL 2021-06-03 09:22:20.571572 - (0, 1) train_iter_time : 2.541186895001374 
DLL 2021-06-03 09:22:20.583248 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2021-06-03 09:22:21.232161 - (0, 2) train_loss : 46.09686279296875 
DLL 2021-06-03 09:22:23.588321 - (0, 2) train_items_per_sec : 58975.73283780377 
DLL 2021-06-03 09:22:23.588392 - (0, 2) train_iter_time : 3.0050834720004787 
DLL 2021-06-03 09:22:23.629378 - (0,) train_items_per_sec : 46798.68157805838 
DLL 2021-06-03 09:22:23.629409 - (0,) train_loss : 46.09686279296875 
DLL 2021-06-03 09:22:23.629426 - (0,) train_epoch_time : 27.000072987999374 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-03 09:22:24.688175 - (0, 3, 0) val_items_per_sec : 102225.58744583873 
DLL 2021-06-03 09:22:24.750120 - (0,) val_loss : 47.11481475830078 
DLL 2021-06-03 09:22:24.750227 - (0,) val_items_per_sec : 102225.58744583873 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-06-03 09:22:26.465195 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2021-06-03 09:22:27.159975 - (1, 0) train_loss : 46.23528289794922 
DLL 2021-06-03 09:22:28.816161 - (1, 0) train_items_per_sec : 75355.60762794278 
DLL 2021-06-03 09:22:28.816238 - (1, 0) train_iter_time : 2.350999554999362 
DLL 2021-06-03 09:22:28.829238 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2021-06-03 09:22:29.486867 - (1, 1) train_loss : 47.02499771118164 
DLL 2021-06-03 09:22:31.930195 - (1, 1) train_items_per_sec : 58139.81442840507 
DLL 2021-06-03 09:22:31.930266 - (1, 1) train_iter_time : 3.1009730899986607 
DLL 2021-06-03 09:22:31.943373 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2021-06-03 09:22:32.577258 - (1, 2) train_loss : 48.34281539916992 
DLL 2021-06-03 09:22:34.170719 - (1, 2) train_items_per_sec : 83758.50205087435 
DLL 2021-06-03 09:22:34.170795 - (1, 2) train_iter_time : 2.2273559749992273 
DLL 2021-06-03 09:22:34.240214 - (1,) train_items_per_sec : 72417.9747024074 
DLL 2021-06-03 09:22:34.240291 - (1,) train_loss : 48.34281539916992 
DLL 2021-06-03 09:22:34.240313 - (1,) train_epoch_time : 9.078490459000022 
DLL 2021-06-03 09:22:35.272884 - (1, 6, 0) val_items_per_sec : 111653.16488564217 
DLL 2021-06-03 09:22:35.339031 - (1,) val_loss : 47.11941909790039 
DLL 2021-06-03 09:22:35.339064 - (1,) val_items_per_sec : 111653.16488564217 
DLL 2021-06-03 09:22:35.340527 - () run_time : 46.804707180999685 
DLL 2021-06-03 09:22:35.340557 - () val_loss : 47.11941909790039 
DLL 2021-06-03 09:22:35.340574 - () train_items_per_sec : 72417.9747024074 
DONE!
