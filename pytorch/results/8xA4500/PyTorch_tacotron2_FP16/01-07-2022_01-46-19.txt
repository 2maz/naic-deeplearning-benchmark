train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2022-07-01 01:46:21.170749 - PARAMETER output : ./ 
DLL 2022-07-01 01:46:21.170813 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2022-07-01 01:46:21.170835 - PARAMETER model_name : Tacotron2 
DLL 2022-07-01 01:46:21.170852 - PARAMETER log_file : nvlog.json 
DLL 2022-07-01 01:46:21.170868 - PARAMETER anneal_steps : None 
DLL 2022-07-01 01:46:21.170884 - PARAMETER anneal_factor : 0.1 
DLL 2022-07-01 01:46:21.170901 - PARAMETER epochs : 3 
DLL 2022-07-01 01:46:21.170917 - PARAMETER epochs_per_checkpoint : 50 
DLL 2022-07-01 01:46:21.170933 - PARAMETER checkpoint_path :  
DLL 2022-07-01 01:46:21.170948 - PARAMETER resume_from_last : False 
DLL 2022-07-01 01:46:21.170963 - PARAMETER dynamic_loss_scaling : True 
DLL 2022-07-01 01:46:21.170979 - PARAMETER amp : False 
DLL 2022-07-01 01:46:21.170994 - PARAMETER cudnn_enabled : True 
DLL 2022-07-01 01:46:21.171008 - PARAMETER cudnn_benchmark : False 
DLL 2022-07-01 01:46:21.171023 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2022-07-01 01:46:21.171038 - PARAMETER use_saved_learning_rate : False 
DLL 2022-07-01 01:46:21.171052 - PARAMETER learning_rate : 0.0 
DLL 2022-07-01 01:46:21.171067 - PARAMETER weight_decay : 1e-06 
DLL 2022-07-01 01:46:21.171083 - PARAMETER grad_clip_thresh : 1.0 
DLL 2022-07-01 01:46:21.171098 - PARAMETER batch_size : 48 
DLL 2022-07-01 01:46:21.171112 - PARAMETER grad_clip : 5.0 
DLL 2022-07-01 01:46:21.171127 - PARAMETER load_mel_from_disk : False 
DLL 2022-07-01 01:46:21.171142 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2022-07-01 01:46:21.171157 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2022-07-01 01:46:21.171172 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2022-07-01 01:46:21.171189 - PARAMETER max_wav_value : 32768.0 
DLL 2022-07-01 01:46:21.171205 - PARAMETER sampling_rate : 22050 
DLL 2022-07-01 01:46:21.171220 - PARAMETER filter_length : 1024 
DLL 2022-07-01 01:46:21.171234 - PARAMETER hop_length : 256 
DLL 2022-07-01 01:46:21.171248 - PARAMETER win_length : 1024 
DLL 2022-07-01 01:46:21.171263 - PARAMETER mel_fmin : 0.0 
DLL 2022-07-01 01:46:21.171277 - PARAMETER mel_fmax : 8000.0 
DLL 2022-07-01 01:46:21.171292 - PARAMETER rank : 0 
DLL 2022-07-01 01:46:21.171306 - PARAMETER world_size : 8 
DLL 2022-07-01 01:46:21.171321 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2022-07-01 01:46:21.171335 - PARAMETER group_name : group_name 
DLL 2022-07-01 01:46:21.171349 - PARAMETER dist_backend : nccl 
DLL 2022-07-01 01:46:21.171363 - PARAMETER bench_class :  
DLL 2022-07-01 01:46:21.171378 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2022-07-01 01:46:47.026876 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2022-07-01 01:46:59.630570 - (0, 0) train_loss : 47.726863861083984 
DLL 2022-07-01 01:47:01.411413 - (0, 0) train_items_per_sec : 15263.068313900385 
DLL 2022-07-01 01:47:01.411512 - (0, 0) train_iter_time : 14.384591321002517 
DLL 2022-07-01 01:47:01.418762 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2022-07-01 01:47:02.335777 - (0, 1) train_loss : 46.18873596191406 
DLL 2022-07-01 01:47:03.736591 - (0, 1) train_items_per_sec : 92351.85436899909 
DLL 2022-07-01 01:47:03.736692 - (0, 1) train_iter_time : 2.3178419259966176 
DLL 2022-07-01 01:47:03.746553 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2022-07-01 01:47:04.453037 - (0, 2) train_loss : 47.83369445800781 
DLL 2022-07-01 01:47:05.869178 - (0, 2) train_items_per_sec : 103095.52722795212 
DLL 2022-07-01 01:47:05.869273 - (0, 2) train_iter_time : 2.122633308001241 
DLL 2022-07-01 01:47:05.917180 - (0,) train_items_per_sec : 70236.81663695053 
DLL 2022-07-01 01:47:05.917329 - (0,) train_loss : 47.83369445800781 
DLL 2022-07-01 01:47:05.917375 - (0,) train_epoch_time : 20.091546438001387 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 01:47:06.926628 - (0, 3, 0) val_items_per_sec : 107499.92068765948 
DLL 2022-07-01 01:47:07.001216 - (0,) val_loss : 48.2768440246582 
DLL 2022-07-01 01:47:07.001391 - (0,) val_items_per_sec : 107499.92068765948 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2022-07-01 01:47:08.458002 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2022-07-01 01:47:09.207618 - (1, 0) train_loss : 46.81061553955078 
DLL 2022-07-01 01:47:10.633317 - (1, 0) train_items_per_sec : 97859.37284367062 
DLL 2022-07-01 01:47:10.633421 - (1, 0) train_iter_time : 2.1753562669982784 
DLL 2022-07-01 01:47:10.644992 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2022-07-01 01:47:11.383704 - (1, 1) train_loss : 47.95283508300781 
DLL 2022-07-01 01:47:12.796013 - (1, 1) train_items_per_sec : 102020.46612709259 
DLL 2022-07-01 01:47:12.796146 - (1, 1) train_iter_time : 2.151019381999504 
DLL 2022-07-01 01:47:12.810031 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2022-07-01 01:47:13.520868 - (1, 2) train_loss : 47.48784637451172 
DLL 2022-07-01 01:47:14.938747 - (1, 2) train_items_per_sec : 103472.08551279677 
DLL 2022-07-01 01:47:14.938852 - (1, 2) train_iter_time : 2.128738382998563 
DLL 2022-07-01 01:47:15.020278 - (1,) train_items_per_sec : 101117.30816118665 
DLL 2022-07-01 01:47:15.020365 - (1,) train_loss : 47.48784637451172 
DLL 2022-07-01 01:47:15.020410 - (1,) train_epoch_time : 7.566974867000681 
DLL 2022-07-01 01:47:16.046877 - (1, 6, 0) val_items_per_sec : 110683.76752353708 
DLL 2022-07-01 01:47:16.129386 - (1,) val_loss : 48.27878189086914 
DLL 2022-07-01 01:47:16.129444 - (1,) val_items_per_sec : 110683.76752353708 
DLL 2022-07-01 01:47:17.290114 - (2, 0) glob_iter/iters_per_epoch : 6/3 
DLL 2022-07-01 01:47:18.131563 - (2, 0) train_loss : 48.631065368652344 
DLL 2022-07-01 01:47:19.561481 - (2, 0) train_items_per_sec : 98614.23652904175 
DLL 2022-07-01 01:47:19.561580 - (2, 0) train_iter_time : 2.2713860379990365 
DLL 2022-07-01 01:47:19.574959 - (2, 1) glob_iter/iters_per_epoch : 7/3 
DLL 2022-07-01 01:47:20.288002 - (2, 1) train_loss : 46.60629653930664 
DLL 2022-07-01 01:47:21.719808 - (2, 1) train_items_per_sec : 100464.25852266698 
DLL 2022-07-01 01:47:21.719917 - (2, 1) train_iter_time : 2.1448622940006317 
DLL 2022-07-01 01:47:21.733597 - (2, 2) glob_iter/iters_per_epoch : 8/3 
DLL 2022-07-01 01:47:22.451002 - (2, 2) train_loss : 46.775611877441406 
DLL 2022-07-01 01:47:23.857164 - (2, 2) train_items_per_sec : 101280.91896400241 
DLL 2022-07-01 01:47:23.857271 - (2, 2) train_iter_time : 2.1235786779980117 
DLL 2022-07-01 01:47:23.942735 - (2,) train_items_per_sec : 100119.80467190371 
DLL 2022-07-01 01:47:23.942891 - (2,) train_loss : 46.775611877441406 
DLL 2022-07-01 01:47:23.942938 - (2,) train_epoch_time : 7.811719149001874 
DLL 2022-07-01 01:47:24.962984 - (2, 9, 0) val_items_per_sec : 110871.79192526417 
DLL 2022-07-01 01:47:25.037911 - (2,) val_loss : 48.27676773071289 
DLL 2022-07-01 01:47:25.038000 - (2,) val_items_per_sec : 110871.79192526417 
DLL 2022-07-01 01:47:25.039965 - () run_time : 60.29137258400078 
DLL 2022-07-01 01:47:25.040035 - () val_loss : 48.27676773071289 
DLL 2022-07-01 01:47:25.040077 - () train_items_per_sec : 100119.80467190371 
DONE!
