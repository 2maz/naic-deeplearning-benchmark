The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : train.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_macipgyi/none_fd7bh39n
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_macipgyi/none_fd7bh39n/attempt_0/0/error.json
train.py:41: UserWarning: PyProf is unavailable
  warnings.warn('PyProf is unavailable')
0: thread affinity: {0, 32, 4, 36, 8, 40, 12, 44}
0: Collecting environment information...
0: PyTorch version: 1.10.0a0+ecc3718
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.2 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.0
Libc version: glibc-2.31

Python version: 3.8 (64-bit runtime)
Python platform: Linux-5.4.0-120-generic-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.48
GPU models and configuration: 
GPU 0: NVIDIA RTX A5500
GPU 1: NVIDIA RTX A5500
GPU 2: NVIDIA RTX A5500
GPU 3: NVIDIA RTX A5500
GPU 4: NVIDIA RTX A5500
GPU 5: NVIDIA RTX A5500
GPU 6: NVIDIA RTX A5500
GPU 7: NVIDIA RTX A5500

Nvidia driver version: 510.73.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.2
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.1
[pip3] nvidia-dlprof-pytorch-nvtx==1.3.0
[pip3] pytorch-quantization==2.1.0
[pip3] pytorch-transformers==1.1.0
[pip3] torch==1.10.0a0+ecc3718
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.1           py38h9894fe3_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.3.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] pytorch-transformers      1.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+ecc3718          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
0: Saving results to: gnmt
0: Run arguments: Namespace(affinity='socket_unique_interleaved', batching='bucketing', beam_size=5, bpe_codes='/data/gnmt/wmt16_de_en/bpe.32000', cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data/gnmt/wmt16_de_en', decay_factor=0.5, decay_interval=None, decay_steps=4, dllog_file='train_log.json', dropout=0.2, env=True, epochs=2, eval=True, grad_clip=5.0, hidden_size=1024, init_scale=8192, intra_epoch_eval=0, keep_checkpoints=0, lang={'src': 'en', 'tgt': 'de'}, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, log_all_ranks=True, lr=0.002, math='fp32', num_buckets=5, num_layers=4, optimizer='Adam', optimizer_extra='{}', prealloc_mode='always', print_freq=10, profile=False, rank=0, remain_steps=0.666, resume=None, save_all=False, save_dir='gnmt', save_freq=5000, seed=2, shard_size=80, share_embedding=True, smoothing=0.1, src_lang='en', start_epoch=0, target_bleu=None, target_perf=None, test_batch_size=128, test_loader_workers=0, test_max_length=150, test_min_length=0, test_src='/data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en', test_tgt='/data/gnmt/wmt16_de_en/newstest2014.de', tgt_lang='de', train_batch_size=288, train_global_batch_size=None, train_iter_size=1, train_loader_workers=2, train_max_length=50, train_max_size=None, train_min_length=0, train_src='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en', train_tgt='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de', upscale_interval=128, val_batch_size=64, val_loader_workers=0, val_max_length=125, val_min_length=0, val_src='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en', val_tgt='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de', vocab='/data/gnmt/wmt16_de_en/vocab.bpe.32000', warmup=1, warmup_steps=200)
0: Using master seed from command line: 2
0: Worker 0 is using worker seed: 242886303
0: Building vocabulary from /data/gnmt/wmt16_de_en/vocab.bpe.32000
0: Size of vocabulary: 31794
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 50
0: Pairs before: 160078, after: 148120
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 125
0: Pairs before: 5100, after: 5100
0: Processing data from /data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): LSTM(1024, 1024, bidirectional=True)
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (embedder): Embedding(31794, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(31794, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=31794, bias=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
0: Training optimizer config: {'optimizer': 'Adam', 'lr': 0.002}
0: Training LR schedule config: {'warmup_steps': 200, 'remain_steps': 0.666, 'decay_interval': None, 'decay_steps': 4, 'decay_factor': 0.5}
0: Number of parameters: 159593523
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:557: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)
  return torch.floor_divide(self, other)
0: Saving state of the tokenizer
0: Initializing fp32 optimizer
0: Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 0
)
0: Scheduler warmup steps: 200
0: Scheduler remain steps: 681
0: Scheduler decay interval: 85
0: Scheduler decay factor: 0.5
0: Scheduler max decay steps: 4
0: Starting epoch 0
0: Executing preallocation
0: Sampler for epoch 0 uses seed 364522461
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
0: TRAIN [0][0/512]	Time 0.520 (0.000)	Data 1.70e-01 (0.00e+00)	Tok/s 34971 (0)	Loss/tok 10.6826 (10.6826)	LR 2.047e-05
0: TRAIN [0][10/512]	Time 0.357 (0.302)	Data 1.42e-04 (1.99e-04)	Tok/s 49715 (49762)	Loss/tok 9.6510 (10.0869)	LR 2.576e-05
0: TRAIN [0][20/512]	Time 0.182 (0.292)	Data 1.39e-04 (1.73e-04)	Tok/s 42943 (48166)	Loss/tok 9.0237 (9.7562)	LR 3.244e-05
0: TRAIN [0][30/512]	Time 0.360 (0.278)	Data 2.52e-04 (1.83e-04)	Tok/s 49894 (47813)	Loss/tok 8.9566 (9.5292)	LR 4.083e-05
0: TRAIN [0][40/512]	Time 0.360 (0.281)	Data 1.48e-04 (1.86e-04)	Tok/s 49653 (47766)	Loss/tok 8.7569 (9.3632)	LR 5.141e-05
0: TRAIN [0][50/512]	Time 0.182 (0.273)	Data 1.34e-04 (1.86e-04)	Tok/s 43143 (47449)	Loss/tok 8.3355 (9.2383)	LR 6.472e-05
0: TRAIN [0][60/512]	Time 0.360 (0.274)	Data 1.56e-04 (1.81e-04)	Tok/s 50680 (47505)	Loss/tok 8.4244 (9.1072)	LR 8.148e-05
0: TRAIN [0][70/512]	Time 0.177 (0.279)	Data 1.47e-04 (1.80e-04)	Tok/s 44803 (47583)	Loss/tok 7.9554 (8.9796)	LR 1.026e-04
0: TRAIN [0][80/512]	Time 0.093 (0.282)	Data 2.69e-04 (1.88e-04)	Tok/s 41645 (47662)	Loss/tok 7.7622 (8.8664)	LR 1.291e-04
0: TRAIN [0][90/512]	Time 0.174 (0.284)	Data 2.54e-04 (1.89e-04)	Tok/s 45090 (47625)	Loss/tok 7.6302 (8.7666)	LR 1.626e-04
0: TRAIN [0][100/512]	Time 0.263 (0.286)	Data 2.85e-04 (1.92e-04)	Tok/s 49318 (47682)	Loss/tok 7.7170 (8.6710)	LR 2.047e-04
0: TRAIN [0][110/512]	Time 0.361 (0.287)	Data 1.44e-04 (1.88e-04)	Tok/s 50458 (47680)	Loss/tok 7.8579 (8.5894)	LR 2.576e-04
0: TRAIN [0][120/512]	Time 0.181 (0.288)	Data 1.37e-04 (1.88e-04)	Tok/s 44069 (47687)	Loss/tok 7.4421 (8.5169)	LR 3.244e-04
0: TRAIN [0][130/512]	Time 0.271 (0.289)	Data 1.35e-04 (1.89e-04)	Tok/s 48432 (47683)	Loss/tok 7.7006 (8.4554)	LR 4.083e-04
0: TRAIN [0][140/512]	Time 0.269 (0.289)	Data 1.71e-04 (1.90e-04)	Tok/s 48183 (47717)	Loss/tok 7.5682 (8.4034)	LR 5.141e-04
0: TRAIN [0][150/512]	Time 0.177 (0.287)	Data 2.19e-04 (1.89e-04)	Tok/s 44514 (47637)	Loss/tok 7.3491 (8.3586)	LR 6.472e-04
0: TRAIN [0][160/512]	Time 0.184 (0.286)	Data 2.28e-04 (1.88e-04)	Tok/s 42203 (47552)	Loss/tok 7.3357 (8.3169)	LR 8.148e-04
0: TRAIN [0][170/512]	Time 0.094 (0.285)	Data 2.83e-04 (1.89e-04)	Tok/s 41607 (47533)	Loss/tok 6.9916 (8.2766)	LR 1.026e-03
0: TRAIN [0][180/512]	Time 0.270 (0.285)	Data 1.38e-04 (1.89e-04)	Tok/s 47418 (47531)	Loss/tok 7.6093 (8.2435)	LR 1.291e-03
0: TRAIN [0][190/512]	Time 0.479 (0.286)	Data 2.58e-04 (1.91e-04)	Tok/s 48939 (47540)	Loss/tok 7.7467 (8.2094)	LR 1.626e-03
0: TRAIN [0][200/512]	Time 0.180 (0.286)	Data 2.24e-04 (1.91e-04)	Tok/s 43760 (47521)	Loss/tok 7.2472 (8.1773)	LR 2.000e-03
0: TRAIN [0][210/512]	Time 0.179 (0.284)	Data 2.72e-04 (1.92e-04)	Tok/s 44014 (47432)	Loss/tok 7.1523 (8.1471)	LR 2.000e-03
0: TRAIN [0][220/512]	Time 0.367 (0.282)	Data 1.47e-04 (1.93e-04)	Tok/s 49193 (47406)	Loss/tok 7.3274 (8.1106)	LR 2.000e-03
0: TRAIN [0][230/512]	Time 0.098 (0.282)	Data 1.48e-04 (1.93e-04)	Tok/s 38852 (47394)	Loss/tok 6.6182 (8.0731)	LR 2.000e-03
0: TRAIN [0][240/512]	Time 0.271 (0.281)	Data 1.38e-04 (1.93e-04)	Tok/s 47935 (47363)	Loss/tok 6.9051 (8.0338)	LR 2.000e-03
0: TRAIN [0][250/512]	Time 0.094 (0.281)	Data 2.92e-04 (1.93e-04)	Tok/s 41556 (47352)	Loss/tok 6.3151 (7.9955)	LR 2.000e-03
0: TRAIN [0][260/512]	Time 0.179 (0.281)	Data 1.45e-04 (1.93e-04)	Tok/s 43238 (47325)	Loss/tok 6.6124 (7.9562)	LR 2.000e-03
0: TRAIN [0][270/512]	Time 0.271 (0.280)	Data 1.42e-04 (1.94e-04)	Tok/s 47664 (47345)	Loss/tok 6.7968 (7.9163)	LR 2.000e-03
0: TRAIN [0][280/512]	Time 0.366 (0.281)	Data 1.42e-04 (1.94e-04)	Tok/s 49056 (47381)	Loss/tok 6.9028 (7.8710)	LR 2.000e-03
0: TRAIN [0][290/512]	Time 0.367 (0.283)	Data 1.93e-04 (1.93e-04)	Tok/s 49339 (47402)	Loss/tok 6.7520 (7.8255)	LR 2.000e-03
0: TRAIN [0][300/512]	Time 0.365 (0.284)	Data 1.90e-04 (1.94e-04)	Tok/s 49802 (47395)	Loss/tok 6.5702 (7.7825)	LR 2.000e-03
0: TRAIN [0][310/512]	Time 0.182 (0.283)	Data 1.43e-04 (1.94e-04)	Tok/s 42087 (47349)	Loss/tok 6.2037 (7.7472)	LR 2.000e-03
0: TRAIN [0][320/512]	Time 0.177 (0.283)	Data 2.77e-04 (1.94e-04)	Tok/s 44028 (47345)	Loss/tok 6.0556 (7.7062)	LR 2.000e-03
0: TRAIN [0][330/512]	Time 0.179 (0.285)	Data 1.46e-04 (1.94e-04)	Tok/s 43791 (47358)	Loss/tok 5.9406 (7.6622)	LR 2.000e-03
0: TRAIN [0][340/512]	Time 0.266 (0.287)	Data 1.45e-04 (1.94e-04)	Tok/s 48424 (47391)	Loss/tok 6.1586 (7.6173)	LR 2.000e-03
0: TRAIN [0][350/512]	Time 0.368 (0.287)	Data 1.44e-04 (1.94e-04)	Tok/s 49224 (47407)	Loss/tok 6.3160 (7.5773)	LR 2.000e-03
0: TRAIN [0][360/512]	Time 0.269 (0.288)	Data 1.41e-04 (1.95e-04)	Tok/s 48936 (47411)	Loss/tok 6.0118 (7.5371)	LR 2.000e-03
0: TRAIN [0][370/512]	Time 0.269 (0.288)	Data 1.42e-04 (1.94e-04)	Tok/s 48333 (47415)	Loss/tok 6.0152 (7.4977)	LR 2.000e-03
0: TRAIN [0][380/512]	Time 0.364 (0.290)	Data 2.69e-04 (1.94e-04)	Tok/s 50097 (47442)	Loss/tok 6.0980 (7.4545)	LR 2.000e-03
0: TRAIN [0][390/512]	Time 0.365 (0.291)	Data 1.48e-04 (1.94e-04)	Tok/s 49501 (47457)	Loss/tok 6.0855 (7.4140)	LR 2.000e-03
0: TRAIN [0][400/512]	Time 0.096 (0.291)	Data 1.37e-04 (1.95e-04)	Tok/s 40058 (47439)	Loss/tok 5.2016 (7.3773)	LR 2.000e-03
0: TRAIN [0][410/512]	Time 0.273 (0.292)	Data 1.51e-04 (1.95e-04)	Tok/s 48067 (47441)	Loss/tok 5.8515 (7.3395)	LR 2.000e-03
0: TRAIN [0][420/512]	Time 0.270 (0.291)	Data 1.51e-04 (1.96e-04)	Tok/s 48374 (47426)	Loss/tok 5.8054 (7.3083)	LR 2.000e-03
0: TRAIN [0][430/512]	Time 0.264 (0.290)	Data 2.56e-04 (1.95e-04)	Tok/s 49691 (47420)	Loss/tok 5.7485 (7.2752)	LR 2.000e-03
0: TRAIN [0][440/512]	Time 0.369 (0.291)	Data 1.40e-04 (1.96e-04)	Tok/s 49476 (47412)	Loss/tok 5.8094 (7.2408)	LR 2.000e-03
0: TRAIN [0][450/512]	Time 0.270 (0.290)	Data 1.50e-04 (1.96e-04)	Tok/s 48659 (47445)	Loss/tok 5.6568 (7.2053)	LR 2.000e-03
0: TRAIN [0][460/512]	Time 0.367 (0.291)	Data 1.47e-04 (1.96e-04)	Tok/s 48971 (47447)	Loss/tok 5.7677 (7.1700)	LR 2.000e-03
0: TRAIN [0][470/512]	Time 0.274 (0.291)	Data 1.67e-04 (1.95e-04)	Tok/s 47659 (47445)	Loss/tok 5.4221 (7.1358)	LR 2.000e-03
0: TRAIN [0][480/512]	Time 0.266 (0.291)	Data 2.79e-04 (1.96e-04)	Tok/s 48717 (47439)	Loss/tok 5.3730 (7.1034)	LR 2.000e-03
0: TRAIN [0][490/512]	Time 0.179 (0.291)	Data 1.43e-04 (1.96e-04)	Tok/s 43706 (47437)	Loss/tok 4.9613 (7.0703)	LR 2.000e-03
0: TRAIN [0][500/512]	Time 0.183 (0.291)	Data 1.46e-04 (1.95e-04)	Tok/s 42531 (47433)	Loss/tok 4.8709 (7.0364)	LR 2.000e-03
0: TRAIN [0][510/512]	Time 0.179 (0.290)	Data 4.41e-05 (2.03e-04)	Tok/s 43171 (47402)	Loss/tok 4.8307 (7.0089)	LR 2.000e-03
0: Running validation on dev set
0: Executing preallocation
0: VALIDATION [0][0/80]	Time 0.123 (0.000)	Data 2.35e-03 (0.00e+00)	Tok/s 85430 (0)	Loss/tok 6.7592 (6.7592)
0: VALIDATION [0][10/80]	Time 0.045 (0.057)	Data 1.77e-03 (1.84e-03)	Tok/s 129059 (121629)	Loss/tok 6.5034 (6.5878)
0: VALIDATION [0][20/80]	Time 0.037 (0.049)	Data 1.68e-03 (1.79e-03)	Tok/s 126807 (123213)	Loss/tok 6.1855 (6.4983)
0: VALIDATION [0][30/80]	Time 0.032 (0.044)	Data 1.72e-03 (1.76e-03)	Tok/s 123007 (123820)	Loss/tok 6.0206 (6.4226)
0: VALIDATION [0][40/80]	Time 0.026 (0.040)	Data 1.67e-03 (1.75e-03)	Tok/s 124162 (123555)	Loss/tok 6.0883 (6.3748)
0: VALIDATION [0][50/80]	Time 0.021 (0.037)	Data 1.66e-03 (1.73e-03)	Tok/s 124001 (123096)	Loss/tok 5.8339 (6.3352)
0: VALIDATION [0][60/80]	Time 0.018 (0.034)	Data 1.67e-03 (1.72e-03)	Tok/s 117219 (122413)	Loss/tok 6.0010 (6.3016)
0: VALIDATION [0][70/80]	Time 0.015 (0.032)	Data 1.66e-03 (1.72e-03)	Tok/s 109242 (120970)	Loss/tok 5.6654 (6.2687)
0: Saving model to gnmt/model_best.pth
0: Running evaluation on test set
0: TEST [0][9/24]	Time 0.6905 (1.1441)	Decoder iters 149.0 (149.0)	Tok/s 12104 (12698)
0: TEST [0][19/24]	Time 0.4145 (0.8330)	Decoder iters 149.0 (149.0)	Tok/s 10686 (12422)
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
0: Summary: Epoch: 0	Training Loss: 7.0057	Validation Loss: 6.2387	Test BLEU: 1.25
0: Performance: Epoch: 0	Training: 47404 Tok/s	Validation: 118251 Tok/s
0: Finished epoch 0
0: Starting epoch 1
0: Executing preallocation
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: Sampler for epoch 1 uses seed 3588440356
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: TRAIN [1][0/512]	Time 0.596 (0.000)	Data 1.33e-01 (0.00e+00)	Tok/s 39437 (0)	Loss/tok 5.5188 (5.5188)	LR 2.000e-03
0: TRAIN [1][10/512]	Time 0.325 (0.212)	Data 1.57e-04 (2.20e-04)	Tok/s 39827 (44373)	Loss/tok 5.0383 (5.0506)	LR 2.000e-03
0: TRAIN [1][20/512]	Time 0.095 (0.256)	Data 3.13e-04 (2.24e-04)	Tok/s 40603 (44583)	Loss/tok 4.2846 (5.0391)	LR 2.000e-03
Traceback (most recent call last):
  File "train.py", line 667, in <module>
    main()
  File "train.py", line 592, in main
    train_loss, train_perf = trainer.optimize(train_loader)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 352, in optimize
    output = self.feed_data(data_loader, training=True)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 236, in feed_data
    stats = self.iterate(src, tgt, update, training=training)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 191, in iterate
    self.fp_optimizer.step(loss, self.optimizer, self.scheduler,
  File "/workspace/examples/gnmt/seq2seq/train/fp_optimizers.py", line 181, in step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 256, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.67 GiB (GPU 0; 23.69 GiB total capacity; 15.61 GiB already allocated; 1.40 GiB free; 20.70 GiB reserved in total by PyTorch)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 4876) of binary: /opt/conda/bin/python3
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=1
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_macipgyi/none_fd7bh39n/attempt_1/0/error.json
train.py:41: UserWarning: PyProf is unavailable
  warnings.warn('PyProf is unavailable')
0: thread affinity: {0, 32, 4, 36, 8, 40, 12, 44}
0: Collecting environment information...
0: PyTorch version: 1.10.0a0+ecc3718
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.2 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.0
Libc version: glibc-2.31

Python version: 3.8 (64-bit runtime)
Python platform: Linux-5.4.0-120-generic-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.48
GPU models and configuration: 
GPU 0: NVIDIA RTX A5500
GPU 1: NVIDIA RTX A5500
GPU 2: NVIDIA RTX A5500
GPU 3: NVIDIA RTX A5500
GPU 4: NVIDIA RTX A5500
GPU 5: NVIDIA RTX A5500
GPU 6: NVIDIA RTX A5500
GPU 7: NVIDIA RTX A5500

Nvidia driver version: 510.73.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.2
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.1
[pip3] nvidia-dlprof-pytorch-nvtx==1.3.0
[pip3] pytorch-quantization==2.1.0
[pip3] pytorch-transformers==1.1.0
[pip3] torch==1.10.0a0+ecc3718
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.1           py38h9894fe3_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.3.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] pytorch-transformers      1.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+ecc3718          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
0: Saving results to: gnmt
0: Run arguments: Namespace(affinity='socket_unique_interleaved', batching='bucketing', beam_size=5, bpe_codes='/data/gnmt/wmt16_de_en/bpe.32000', cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data/gnmt/wmt16_de_en', decay_factor=0.5, decay_interval=None, decay_steps=4, dllog_file='train_log.json', dropout=0.2, env=True, epochs=2, eval=True, grad_clip=5.0, hidden_size=1024, init_scale=8192, intra_epoch_eval=0, keep_checkpoints=0, lang={'src': 'en', 'tgt': 'de'}, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, log_all_ranks=True, lr=0.002, math='fp32', num_buckets=5, num_layers=4, optimizer='Adam', optimizer_extra='{}', prealloc_mode='always', print_freq=10, profile=False, rank=0, remain_steps=0.666, resume=None, save_all=False, save_dir='gnmt', save_freq=5000, seed=2, shard_size=80, share_embedding=True, smoothing=0.1, src_lang='en', start_epoch=0, target_bleu=None, target_perf=None, test_batch_size=128, test_loader_workers=0, test_max_length=150, test_min_length=0, test_src='/data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en', test_tgt='/data/gnmt/wmt16_de_en/newstest2014.de', tgt_lang='de', train_batch_size=288, train_global_batch_size=None, train_iter_size=1, train_loader_workers=2, train_max_length=50, train_max_size=None, train_min_length=0, train_src='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en', train_tgt='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de', upscale_interval=128, val_batch_size=64, val_loader_workers=0, val_max_length=125, val_min_length=0, val_src='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en', val_tgt='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de', vocab='/data/gnmt/wmt16_de_en/vocab.bpe.32000', warmup=1, warmup_steps=200)
0: Using master seed from command line: 2
0: Worker 0 is using worker seed: 242886303
0: Building vocabulary from /data/gnmt/wmt16_de_en/vocab.bpe.32000
0: Size of vocabulary: 31794
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 50
0: Pairs before: 160078, after: 148120
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 125
0: Pairs before: 5100, after: 5100
0: Processing data from /data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): LSTM(1024, 1024, bidirectional=True)
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (embedder): Embedding(31794, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(31794, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=31794, bias=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
0: Training optimizer config: {'optimizer': 'Adam', 'lr': 0.002}
0: Training LR schedule config: {'warmup_steps': 200, 'remain_steps': 0.666, 'decay_interval': None, 'decay_steps': 4, 'decay_factor': 0.5}
0: Number of parameters: 159593523
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:557: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)
  return torch.floor_divide(self, other)
0: Saving state of the tokenizer
0: Initializing fp32 optimizer
0: Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 0
)
0: Scheduler warmup steps: 200
0: Scheduler remain steps: 681
0: Scheduler decay interval: 85
0: Scheduler decay factor: 0.5
0: Scheduler max decay steps: 4
0: Starting epoch 0
0: Executing preallocation
0: Sampler for epoch 0 uses seed 364522461
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
0: TRAIN [0][0/512]	Time 0.529 (0.000)	Data 1.77e-01 (0.00e+00)	Tok/s 34371 (0)	Loss/tok 10.6826 (10.6826)	LR 2.047e-05
0: TRAIN [0][10/512]	Time 0.359 (0.302)	Data 3.46e-04 (2.73e-04)	Tok/s 49383 (49700)	Loss/tok 9.6510 (10.0869)	LR 2.576e-05
0: TRAIN [0][20/512]	Time 0.178 (0.293)	Data 1.31e-04 (2.50e-04)	Tok/s 43857 (48115)	Loss/tok 9.0237 (9.7562)	LR 3.244e-05
0: TRAIN [0][30/512]	Time 0.361 (0.278)	Data 1.35e-04 (2.29e-04)	Tok/s 49695 (47681)	Loss/tok 8.9566 (9.5292)	LR 4.083e-05
0: TRAIN [0][40/512]	Time 0.358 (0.281)	Data 2.89e-04 (2.26e-04)	Tok/s 49957 (47593)	Loss/tok 8.7569 (9.3632)	LR 5.141e-05
0: TRAIN [0][50/512]	Time 0.177 (0.274)	Data 1.47e-04 (2.22e-04)	Tok/s 44178 (47291)	Loss/tok 8.3355 (9.2383)	LR 6.472e-05
0: TRAIN [0][60/512]	Time 0.358 (0.275)	Data 1.39e-04 (2.18e-04)	Tok/s 50949 (47364)	Loss/tok 8.4244 (9.1072)	LR 8.148e-05
0: TRAIN [0][70/512]	Time 0.180 (0.280)	Data 1.47e-04 (2.08e-04)	Tok/s 44211 (47447)	Loss/tok 7.9554 (8.9796)	LR 1.026e-04
0: TRAIN [0][80/512]	Time 0.094 (0.282)	Data 2.60e-04 (2.05e-04)	Tok/s 41256 (47530)	Loss/tok 7.7622 (8.8664)	LR 1.291e-04
0: TRAIN [0][90/512]	Time 0.184 (0.285)	Data 1.44e-04 (1.99e-04)	Tok/s 42723 (47483)	Loss/tok 7.6302 (8.7666)	LR 1.626e-04
0: TRAIN [0][100/512]	Time 0.268 (0.287)	Data 2.52e-04 (1.96e-04)	Tok/s 48419 (47545)	Loss/tok 7.7170 (8.6710)	LR 2.047e-04
0: TRAIN [0][110/512]	Time 0.364 (0.287)	Data 1.46e-04 (1.97e-04)	Tok/s 50079 (47548)	Loss/tok 7.8579 (8.5894)	LR 2.576e-04
0: TRAIN [0][120/512]	Time 0.180 (0.289)	Data 2.01e-04 (1.96e-04)	Tok/s 44247 (47556)	Loss/tok 7.4421 (8.5169)	LR 3.244e-04
0: TRAIN [0][130/512]	Time 0.265 (0.290)	Data 2.54e-04 (1.94e-04)	Tok/s 49676 (47558)	Loss/tok 7.7006 (8.4554)	LR 4.083e-04
0: TRAIN [0][140/512]	Time 0.266 (0.290)	Data 1.68e-04 (1.94e-04)	Tok/s 48714 (47596)	Loss/tok 7.5682 (8.4034)	LR 5.141e-04
0: TRAIN [0][150/512]	Time 0.183 (0.287)	Data 1.38e-04 (1.90e-04)	Tok/s 43140 (47511)	Loss/tok 7.3491 (8.3586)	LR 6.472e-04
0: TRAIN [0][160/512]	Time 0.180 (0.286)	Data 1.38e-04 (1.88e-04)	Tok/s 43323 (47462)	Loss/tok 7.3357 (8.3169)	LR 8.148e-04
0: TRAIN [0][170/512]	Time 0.098 (0.286)	Data 1.83e-04 (1.88e-04)	Tok/s 39593 (47428)	Loss/tok 6.9916 (8.2766)	LR 1.026e-03
0: TRAIN [0][180/512]	Time 0.268 (0.285)	Data 1.43e-04 (1.85e-04)	Tok/s 47873 (47440)	Loss/tok 7.6093 (8.2435)	LR 1.291e-03
0: TRAIN [0][190/512]	Time 0.477 (0.286)	Data 2.74e-04 (1.85e-04)	Tok/s 49129 (47446)	Loss/tok 7.7467 (8.2094)	LR 1.626e-03
0: TRAIN [0][200/512]	Time 0.176 (0.286)	Data 2.74e-04 (1.88e-04)	Tok/s 44735 (47438)	Loss/tok 7.2472 (8.1773)	LR 2.000e-03
0: TRAIN [0][210/512]	Time 0.178 (0.284)	Data 2.67e-04 (1.88e-04)	Tok/s 44328 (47340)	Loss/tok 7.1523 (8.1471)	LR 2.000e-03
0: TRAIN [0][220/512]	Time 0.367 (0.282)	Data 1.41e-04 (1.86e-04)	Tok/s 49279 (47312)	Loss/tok 7.3274 (8.1106)	LR 2.000e-03
0: TRAIN [0][230/512]	Time 0.099 (0.282)	Data 1.40e-04 (1.85e-04)	Tok/s 38399 (47299)	Loss/tok 6.6182 (8.0731)	LR 2.000e-03
0: TRAIN [0][240/512]	Time 0.267 (0.281)	Data 1.35e-04 (1.83e-04)	Tok/s 48634 (47273)	Loss/tok 6.9051 (8.0338)	LR 2.000e-03
0: TRAIN [0][250/512]	Time 0.100 (0.281)	Data 1.42e-04 (1.84e-04)	Tok/s 39095 (47257)	Loss/tok 6.3151 (7.9955)	LR 2.000e-03
0: TRAIN [0][260/512]	Time 0.183 (0.281)	Data 1.47e-04 (1.84e-04)	Tok/s 42450 (47229)	Loss/tok 6.6124 (7.9562)	LR 2.000e-03
0: TRAIN [0][270/512]	Time 0.268 (0.281)	Data 1.81e-04 (1.83e-04)	Tok/s 48275 (47250)	Loss/tok 6.7968 (7.9163)	LR 2.000e-03
0: TRAIN [0][280/512]	Time 0.360 (0.282)	Data 1.37e-04 (1.85e-04)	Tok/s 49836 (47294)	Loss/tok 6.9028 (7.8710)	LR 2.000e-03
0: TRAIN [0][290/512]	Time 0.365 (0.284)	Data 2.91e-04 (1.86e-04)	Tok/s 49590 (47316)	Loss/tok 6.7520 (7.8255)	LR 2.000e-03
0: TRAIN [0][300/512]	Time 0.362 (0.284)	Data 1.39e-04 (1.85e-04)	Tok/s 50188 (47313)	Loss/tok 6.5702 (7.7825)	LR 2.000e-03
0: TRAIN [0][310/512]	Time 0.183 (0.283)	Data 1.33e-04 (1.84e-04)	Tok/s 41945 (47264)	Loss/tok 6.2037 (7.7472)	LR 2.000e-03
0: TRAIN [0][320/512]	Time 0.176 (0.283)	Data 2.53e-04 (1.84e-04)	Tok/s 44131 (47263)	Loss/tok 6.0556 (7.7062)	LR 2.000e-03
0: TRAIN [0][330/512]	Time 0.179 (0.285)	Data 1.46e-04 (1.83e-04)	Tok/s 43860 (47282)	Loss/tok 5.9406 (7.6622)	LR 2.000e-03
0: TRAIN [0][340/512]	Time 0.265 (0.287)	Data 3.14e-04 (1.84e-04)	Tok/s 48522 (47317)	Loss/tok 6.1586 (7.6173)	LR 2.000e-03
0: TRAIN [0][350/512]	Time 0.365 (0.288)	Data 1.92e-04 (1.84e-04)	Tok/s 49617 (47338)	Loss/tok 6.3160 (7.5773)	LR 2.000e-03
0: TRAIN [0][360/512]	Time 0.269 (0.288)	Data 1.92e-04 (1.84e-04)	Tok/s 48869 (47346)	Loss/tok 6.0118 (7.5371)	LR 2.000e-03
0: TRAIN [0][370/512]	Time 0.266 (0.288)	Data 2.62e-04 (1.85e-04)	Tok/s 48840 (47352)	Loss/tok 6.0152 (7.4977)	LR 2.000e-03
0: TRAIN [0][380/512]	Time 0.364 (0.290)	Data 1.43e-04 (1.85e-04)	Tok/s 50184 (47379)	Loss/tok 6.0980 (7.4545)	LR 2.000e-03
0: TRAIN [0][390/512]	Time 0.366 (0.291)	Data 1.85e-04 (1.85e-04)	Tok/s 49408 (47396)	Loss/tok 6.0855 (7.4140)	LR 2.000e-03
0: TRAIN [0][400/512]	Time 0.095 (0.291)	Data 2.51e-04 (1.87e-04)	Tok/s 40727 (47381)	Loss/tok 5.2016 (7.3773)	LR 2.000e-03
0: TRAIN [0][410/512]	Time 0.269 (0.292)	Data 2.62e-04 (1.87e-04)	Tok/s 48709 (47382)	Loss/tok 5.8515 (7.3395)	LR 2.000e-03
0: TRAIN [0][420/512]	Time 0.262 (0.291)	Data 2.54e-04 (1.86e-04)	Tok/s 49841 (47369)	Loss/tok 5.8054 (7.3083)	LR 2.000e-03
0: TRAIN [0][430/512]	Time 0.266 (0.291)	Data 2.46e-04 (1.85e-04)	Tok/s 49343 (47367)	Loss/tok 5.7485 (7.2752)	LR 2.000e-03
0: TRAIN [0][440/512]	Time 0.367 (0.291)	Data 2.81e-04 (1.85e-04)	Tok/s 49663 (47359)	Loss/tok 5.8094 (7.2408)	LR 2.000e-03
0: TRAIN [0][450/512]	Time 0.268 (0.291)	Data 2.71e-04 (1.85e-04)	Tok/s 48889 (47392)	Loss/tok 5.6568 (7.2053)	LR 2.000e-03
0: TRAIN [0][460/512]	Time 0.365 (0.291)	Data 1.35e-04 (1.85e-04)	Tok/s 49120 (47395)	Loss/tok 5.7677 (7.1700)	LR 2.000e-03
0: TRAIN [0][470/512]	Time 0.273 (0.291)	Data 1.40e-04 (1.85e-04)	Tok/s 47863 (47392)	Loss/tok 5.4221 (7.1358)	LR 2.000e-03
0: TRAIN [0][480/512]	Time 0.268 (0.291)	Data 1.35e-04 (1.85e-04)	Tok/s 48476 (47380)	Loss/tok 5.3730 (7.1034)	LR 2.000e-03
0: TRAIN [0][490/512]	Time 0.179 (0.291)	Data 2.78e-04 (1.85e-04)	Tok/s 43599 (47375)	Loss/tok 4.9613 (7.0703)	LR 2.000e-03
0: TRAIN [0][500/512]	Time 0.178 (0.291)	Data 2.55e-04 (1.85e-04)	Tok/s 43746 (47376)	Loss/tok 4.8709 (7.0364)	LR 2.000e-03
0: TRAIN [0][510/512]	Time 0.181 (0.290)	Data 4.10e-05 (1.89e-04)	Tok/s 42650 (47345)	Loss/tok 4.8307 (7.0089)	LR 2.000e-03
0: Running validation on dev set
0: Executing preallocation
0: VALIDATION [0][0/80]	Time 0.122 (0.000)	Data 2.30e-03 (0.00e+00)	Tok/s 85504 (0)	Loss/tok 6.7592 (6.7592)
0: VALIDATION [0][10/80]	Time 0.045 (0.057)	Data 1.71e-03 (1.78e-03)	Tok/s 129135 (121837)	Loss/tok 6.5034 (6.5878)
0: VALIDATION [0][20/80]	Time 0.037 (0.049)	Data 1.67e-03 (1.74e-03)	Tok/s 126738 (123140)	Loss/tok 6.1855 (6.4983)
0: VALIDATION [0][30/80]	Time 0.032 (0.044)	Data 1.64e-03 (1.71e-03)	Tok/s 122401 (123778)	Loss/tok 6.0206 (6.4226)
0: VALIDATION [0][40/80]	Time 0.026 (0.040)	Data 1.62e-03 (1.69e-03)	Tok/s 124711 (123548)	Loss/tok 6.0883 (6.3748)
0: VALIDATION [0][50/80]	Time 0.021 (0.037)	Data 1.61e-03 (1.68e-03)	Tok/s 124212 (123153)	Loss/tok 5.8339 (6.3352)
0: VALIDATION [0][60/80]	Time 0.018 (0.034)	Data 1.61e-03 (1.66e-03)	Tok/s 117181 (122492)	Loss/tok 6.0010 (6.3016)
0: VALIDATION [0][70/80]	Time 0.015 (0.031)	Data 1.61e-03 (1.66e-03)	Tok/s 109415 (121124)	Loss/tok 5.6654 (6.2687)
0: Saving model to gnmt/model_best.pth
0: Running evaluation on test set
0: TEST [0][9/24]	Time 0.6889 (1.1443)	Decoder iters 149.0 (149.0)	Tok/s 12132 (12696)
0: TEST [0][19/24]	Time 0.4150 (0.8325)	Decoder iters 149.0 (149.0)	Tok/s 10673 (12437)
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
0: Summary: Epoch: 0	Training Loss: 7.0057	Validation Loss: 6.2387	Test BLEU: 1.25
0: Performance: Epoch: 0	Training: 47347 Tok/s	Validation: 118433 Tok/s
0: Finished epoch 0
0: Starting epoch 1
0: Executing preallocation
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: Sampler for epoch 1 uses seed 3588440356
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: TRAIN [1][0/512]	Time 0.600 (0.000)	Data 1.27e-01 (0.00e+00)	Tok/s 39162 (0)	Loss/tok 5.5188 (5.5188)	LR 2.000e-03
0: TRAIN [1][10/512]	Time 0.321 (0.212)	Data 1.38e-04 (2.27e-04)	Tok/s 40334 (44357)	Loss/tok 5.0383 (5.0506)	LR 2.000e-03
0: TRAIN [1][20/512]	Time 0.096 (0.257)	Data 1.84e-04 (2.61e-04)	Tok/s 39822 (44272)	Loss/tok 4.2846 (5.0391)	LR 2.000e-03
Traceback (most recent call last):
  File "train.py", line 667, in <module>
    main()
  File "train.py", line 592, in main
    train_loss, train_perf = trainer.optimize(train_loader)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 352, in optimize
    output = self.feed_data(data_loader, training=True)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 236, in feed_data
    stats = self.iterate(src, tgt, update, training=training)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 191, in iterate
    self.fp_optimizer.step(loss, self.optimizer, self.scheduler,
  File "/workspace/examples/gnmt/seq2seq/train/fp_optimizers.py", line 181, in step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 256, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.67 GiB (GPU 0; 23.69 GiB total capacity; 15.61 GiB already allocated; 1.40 GiB free; 20.70 GiB reserved in total by PyTorch)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 5647) of binary: /opt/conda/bin/python3
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 2/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=2
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_macipgyi/none_fd7bh39n/attempt_2/0/error.json
train.py:41: UserWarning: PyProf is unavailable
  warnings.warn('PyProf is unavailable')
0: thread affinity: {0, 32, 4, 36, 8, 40, 12, 44}
0: Collecting environment information...
0: PyTorch version: 1.10.0a0+ecc3718
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.2 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.0
Libc version: glibc-2.31

Python version: 3.8 (64-bit runtime)
Python platform: Linux-5.4.0-120-generic-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.48
GPU models and configuration: 
GPU 0: NVIDIA RTX A5500
GPU 1: NVIDIA RTX A5500
GPU 2: NVIDIA RTX A5500
GPU 3: NVIDIA RTX A5500
GPU 4: NVIDIA RTX A5500
GPU 5: NVIDIA RTX A5500
GPU 6: NVIDIA RTX A5500
GPU 7: NVIDIA RTX A5500

Nvidia driver version: 510.73.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.2
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.1
[pip3] nvidia-dlprof-pytorch-nvtx==1.3.0
[pip3] pytorch-quantization==2.1.0
[pip3] pytorch-transformers==1.1.0
[pip3] torch==1.10.0a0+ecc3718
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.1           py38h9894fe3_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.3.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] pytorch-transformers      1.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+ecc3718          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
0: Saving results to: gnmt
0: Run arguments: Namespace(affinity='socket_unique_interleaved', batching='bucketing', beam_size=5, bpe_codes='/data/gnmt/wmt16_de_en/bpe.32000', cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data/gnmt/wmt16_de_en', decay_factor=0.5, decay_interval=None, decay_steps=4, dllog_file='train_log.json', dropout=0.2, env=True, epochs=2, eval=True, grad_clip=5.0, hidden_size=1024, init_scale=8192, intra_epoch_eval=0, keep_checkpoints=0, lang={'src': 'en', 'tgt': 'de'}, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, log_all_ranks=True, lr=0.002, math='fp32', num_buckets=5, num_layers=4, optimizer='Adam', optimizer_extra='{}', prealloc_mode='always', print_freq=10, profile=False, rank=0, remain_steps=0.666, resume=None, save_all=False, save_dir='gnmt', save_freq=5000, seed=2, shard_size=80, share_embedding=True, smoothing=0.1, src_lang='en', start_epoch=0, target_bleu=None, target_perf=None, test_batch_size=128, test_loader_workers=0, test_max_length=150, test_min_length=0, test_src='/data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en', test_tgt='/data/gnmt/wmt16_de_en/newstest2014.de', tgt_lang='de', train_batch_size=288, train_global_batch_size=None, train_iter_size=1, train_loader_workers=2, train_max_length=50, train_max_size=None, train_min_length=0, train_src='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en', train_tgt='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de', upscale_interval=128, val_batch_size=64, val_loader_workers=0, val_max_length=125, val_min_length=0, val_src='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en', val_tgt='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de', vocab='/data/gnmt/wmt16_de_en/vocab.bpe.32000', warmup=1, warmup_steps=200)
0: Using master seed from command line: 2
0: Worker 0 is using worker seed: 242886303
0: Building vocabulary from /data/gnmt/wmt16_de_en/vocab.bpe.32000
0: Size of vocabulary: 31794
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 50
0: Pairs before: 160078, after: 148120
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 125
0: Pairs before: 5100, after: 5100
0: Processing data from /data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): LSTM(1024, 1024, bidirectional=True)
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (embedder): Embedding(31794, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(31794, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=31794, bias=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
0: Training optimizer config: {'optimizer': 'Adam', 'lr': 0.002}
0: Training LR schedule config: {'warmup_steps': 200, 'remain_steps': 0.666, 'decay_interval': None, 'decay_steps': 4, 'decay_factor': 0.5}
0: Number of parameters: 159593523
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:557: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)
  return torch.floor_divide(self, other)
0: Saving state of the tokenizer
0: Initializing fp32 optimizer
0: Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 0
)
0: Scheduler warmup steps: 200
0: Scheduler remain steps: 681
0: Scheduler decay interval: 85
0: Scheduler decay factor: 0.5
0: Scheduler max decay steps: 4
0: Starting epoch 0
0: Executing preallocation
0: Sampler for epoch 0 uses seed 364522461
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
0: TRAIN [0][0/512]	Time 0.519 (0.000)	Data 1.70e-01 (0.00e+00)	Tok/s 35074 (0)	Loss/tok 10.6826 (10.6826)	LR 2.047e-05
0: TRAIN [0][10/512]	Time 0.357 (0.302)	Data 2.57e-04 (1.74e-04)	Tok/s 49770 (49769)	Loss/tok 9.6510 (10.0869)	LR 2.576e-05
0: TRAIN [0][20/512]	Time 0.177 (0.294)	Data 1.28e-04 (1.96e-04)	Tok/s 44175 (48038)	Loss/tok 9.0237 (9.7562)	LR 3.244e-05
0: TRAIN [0][30/512]	Time 0.366 (0.279)	Data 1.34e-04 (1.82e-04)	Tok/s 49054 (47580)	Loss/tok 8.9566 (9.5292)	LR 4.083e-05
0: TRAIN [0][40/512]	Time 0.363 (0.283)	Data 1.43e-04 (1.81e-04)	Tok/s 49268 (47470)	Loss/tok 8.7569 (9.3632)	LR 5.141e-05
0: TRAIN [0][50/512]	Time 0.181 (0.275)	Data 1.39e-04 (1.74e-04)	Tok/s 43326 (47161)	Loss/tok 8.3355 (9.2383)	LR 6.472e-05
0: TRAIN [0][60/512]	Time 0.365 (0.276)	Data 1.44e-04 (1.72e-04)	Tok/s 50094 (47207)	Loss/tok 8.4244 (9.1072)	LR 8.148e-05
0: TRAIN [0][70/512]	Time 0.182 (0.281)	Data 1.34e-04 (1.74e-04)	Tok/s 43763 (47278)	Loss/tok 7.9554 (8.9796)	LR 1.026e-04
0: TRAIN [0][80/512]	Time 0.098 (0.283)	Data 1.40e-04 (1.72e-04)	Tok/s 39822 (47369)	Loss/tok 7.7622 (8.8664)	LR 1.291e-04
0: TRAIN [0][90/512]	Time 0.182 (0.286)	Data 1.32e-04 (1.69e-04)	Tok/s 43243 (47327)	Loss/tok 7.6302 (8.7666)	LR 1.626e-04
0: TRAIN [0][100/512]	Time 0.268 (0.288)	Data 1.37e-04 (1.72e-04)	Tok/s 48388 (47399)	Loss/tok 7.7170 (8.6710)	LR 2.047e-04
0: TRAIN [0][110/512]	Time 0.365 (0.288)	Data 2.49e-04 (1.74e-04)	Tok/s 50020 (47399)	Loss/tok 7.8579 (8.5894)	LR 2.576e-04
0: TRAIN [0][120/512]	Time 0.183 (0.290)	Data 1.32e-04 (1.74e-04)	Tok/s 43520 (47405)	Loss/tok 7.4421 (8.5169)	LR 3.244e-04
0: TRAIN [0][130/512]	Time 0.273 (0.291)	Data 1.45e-04 (1.76e-04)	Tok/s 48207 (47396)	Loss/tok 7.7006 (8.4554)	LR 4.083e-04
0: TRAIN [0][140/512]	Time 0.270 (0.290)	Data 1.75e-04 (1.77e-04)	Tok/s 48029 (47434)	Loss/tok 7.5682 (8.4034)	LR 5.141e-04
0: TRAIN [0][150/512]	Time 0.180 (0.288)	Data 1.76e-04 (1.77e-04)	Tok/s 43776 (47355)	Loss/tok 7.3491 (8.3586)	LR 6.472e-04
0: TRAIN [0][160/512]	Time 0.179 (0.287)	Data 2.68e-04 (1.77e-04)	Tok/s 43383 (47286)	Loss/tok 7.3357 (8.3169)	LR 8.148e-04
0: TRAIN [0][170/512]	Time 0.094 (0.286)	Data 2.67e-04 (1.79e-04)	Tok/s 41376 (47269)	Loss/tok 6.9916 (8.2766)	LR 1.026e-03
0: TRAIN [0][180/512]	Time 0.268 (0.286)	Data 1.37e-04 (1.78e-04)	Tok/s 47838 (47276)	Loss/tok 7.6093 (8.2435)	LR 1.291e-03
0: TRAIN [0][190/512]	Time 0.479 (0.287)	Data 2.45e-04 (1.79e-04)	Tok/s 49012 (47288)	Loss/tok 7.7467 (8.2094)	LR 1.626e-03
0: TRAIN [0][200/512]	Time 0.175 (0.287)	Data 2.74e-04 (1.81e-04)	Tok/s 44788 (47284)	Loss/tok 7.2472 (8.1773)	LR 2.000e-03
0: TRAIN [0][210/512]	Time 0.182 (0.285)	Data 2.56e-04 (1.81e-04)	Tok/s 43430 (47186)	Loss/tok 7.1523 (8.1471)	LR 2.000e-03
0: TRAIN [0][220/512]	Time 0.368 (0.283)	Data 1.35e-04 (1.80e-04)	Tok/s 49165 (47166)	Loss/tok 7.3274 (8.1106)	LR 2.000e-03
0: TRAIN [0][230/512]	Time 0.098 (0.283)	Data 1.46e-04 (1.81e-04)	Tok/s 38561 (47160)	Loss/tok 6.6182 (8.0731)	LR 2.000e-03
0: TRAIN [0][240/512]	Time 0.271 (0.282)	Data 1.34e-04 (1.81e-04)	Tok/s 47842 (47128)	Loss/tok 6.9051 (8.0338)	LR 2.000e-03
0: TRAIN [0][250/512]	Time 0.098 (0.282)	Data 1.38e-04 (1.82e-04)	Tok/s 39787 (47116)	Loss/tok 6.3151 (7.9955)	LR 2.000e-03
0: TRAIN [0][260/512]	Time 0.183 (0.282)	Data 1.40e-04 (1.82e-04)	Tok/s 42414 (47094)	Loss/tok 6.6124 (7.9562)	LR 2.000e-03
0: TRAIN [0][270/512]	Time 0.268 (0.281)	Data 2.52e-04 (1.82e-04)	Tok/s 48246 (47111)	Loss/tok 6.7968 (7.9163)	LR 2.000e-03
0: TRAIN [0][280/512]	Time 0.363 (0.283)	Data 1.36e-04 (1.83e-04)	Tok/s 49487 (47156)	Loss/tok 6.9028 (7.8710)	LR 2.000e-03
0: TRAIN [0][290/512]	Time 0.364 (0.284)	Data 2.57e-04 (1.83e-04)	Tok/s 49759 (47182)	Loss/tok 6.7520 (7.8255)	LR 2.000e-03
0: TRAIN [0][300/512]	Time 0.368 (0.285)	Data 1.38e-04 (1.83e-04)	Tok/s 49403 (47179)	Loss/tok 6.5702 (7.7825)	LR 2.000e-03
0: TRAIN [0][310/512]	Time 0.181 (0.284)	Data 2.44e-04 (1.84e-04)	Tok/s 42297 (47135)	Loss/tok 6.2037 (7.7472)	LR 2.000e-03
0: TRAIN [0][320/512]	Time 0.180 (0.284)	Data 2.52e-04 (1.85e-04)	Tok/s 43276 (47139)	Loss/tok 6.0556 (7.7062)	LR 2.000e-03
0: TRAIN [0][330/512]	Time 0.179 (0.286)	Data 1.95e-04 (1.86e-04)	Tok/s 43790 (47161)	Loss/tok 5.9406 (7.6622)	LR 2.000e-03
0: TRAIN [0][340/512]	Time 0.270 (0.288)	Data 1.75e-04 (1.87e-04)	Tok/s 47577 (47198)	Loss/tok 6.1586 (7.6173)	LR 2.000e-03
0: TRAIN [0][350/512]	Time 0.362 (0.288)	Data 2.62e-04 (1.87e-04)	Tok/s 49913 (47219)	Loss/tok 6.3160 (7.5773)	LR 2.000e-03
0: TRAIN [0][360/512]	Time 0.264 (0.289)	Data 2.69e-04 (1.87e-04)	Tok/s 49881 (47235)	Loss/tok 6.0118 (7.5371)	LR 2.000e-03
0: TRAIN [0][370/512]	Time 0.267 (0.289)	Data 2.69e-04 (1.87e-04)	Tok/s 48586 (47244)	Loss/tok 6.0152 (7.4977)	LR 2.000e-03
0: TRAIN [0][380/512]	Time 0.365 (0.290)	Data 1.44e-04 (1.87e-04)	Tok/s 49967 (47277)	Loss/tok 6.0980 (7.4545)	LR 2.000e-03
0: TRAIN [0][390/512]	Time 0.361 (0.291)	Data 2.66e-04 (1.88e-04)	Tok/s 50152 (47298)	Loss/tok 6.0855 (7.4140)	LR 2.000e-03
0: TRAIN [0][400/512]	Time 0.097 (0.292)	Data 1.37e-04 (1.87e-04)	Tok/s 39631 (47284)	Loss/tok 5.2016 (7.3773)	LR 2.000e-03
0: TRAIN [0][410/512]	Time 0.267 (0.293)	Data 2.75e-04 (1.87e-04)	Tok/s 49172 (47293)	Loss/tok 5.8515 (7.3395)	LR 2.000e-03
0: TRAIN [0][420/512]	Time 0.262 (0.292)	Data 2.63e-04 (1.87e-04)	Tok/s 49786 (47282)	Loss/tok 5.8054 (7.3083)	LR 2.000e-03
0: TRAIN [0][430/512]	Time 0.263 (0.291)	Data 1.39e-04 (1.87e-04)	Tok/s 49771 (47281)	Loss/tok 5.7485 (7.2752)	LR 2.000e-03
0: TRAIN [0][440/512]	Time 0.367 (0.291)	Data 2.64e-04 (1.87e-04)	Tok/s 49784 (47272)	Loss/tok 5.8094 (7.2408)	LR 2.000e-03
0: TRAIN [0][450/512]	Time 0.269 (0.291)	Data 1.38e-04 (1.87e-04)	Tok/s 48724 (47307)	Loss/tok 5.6568 (7.2053)	LR 2.000e-03
0: TRAIN [0][460/512]	Time 0.367 (0.291)	Data 1.41e-04 (1.86e-04)	Tok/s 48850 (47309)	Loss/tok 5.7677 (7.1700)	LR 2.000e-03
0: TRAIN [0][470/512]	Time 0.270 (0.292)	Data 1.41e-04 (1.85e-04)	Tok/s 48314 (47312)	Loss/tok 5.4221 (7.1358)	LR 2.000e-03
0: TRAIN [0][480/512]	Time 0.266 (0.292)	Data 2.58e-04 (1.86e-04)	Tok/s 48838 (47306)	Loss/tok 5.3730 (7.1034)	LR 2.000e-03
0: TRAIN [0][490/512]	Time 0.174 (0.292)	Data 2.58e-04 (1.87e-04)	Tok/s 44825 (47308)	Loss/tok 4.9613 (7.0703)	LR 2.000e-03
0: TRAIN [0][500/512]	Time 0.178 (0.292)	Data 2.67e-04 (1.87e-04)	Tok/s 43541 (47307)	Loss/tok 4.8709 (7.0364)	LR 2.000e-03
0: TRAIN [0][510/512]	Time 0.181 (0.290)	Data 4.27e-05 (1.91e-04)	Tok/s 42658 (47276)	Loss/tok 4.8307 (7.0089)	LR 2.000e-03
0: Running validation on dev set
0: Executing preallocation
0: VALIDATION [0][0/80]	Time 0.123 (0.000)	Data 2.31e-03 (0.00e+00)	Tok/s 85306 (0)	Loss/tok 6.7592 (6.7592)
0: VALIDATION [0][10/80]	Time 0.046 (0.057)	Data 1.76e-03 (1.81e-03)	Tok/s 128022 (121231)	Loss/tok 6.5034 (6.5878)
0: VALIDATION [0][20/80]	Time 0.036 (0.049)	Data 1.69e-03 (1.77e-03)	Tok/s 127162 (122938)	Loss/tok 6.1855 (6.4983)
0: VALIDATION [0][30/80]	Time 0.032 (0.044)	Data 1.66e-03 (1.74e-03)	Tok/s 122791 (123630)	Loss/tok 6.0206 (6.4226)
0: VALIDATION [0][40/80]	Time 0.026 (0.040)	Data 1.69e-03 (1.72e-03)	Tok/s 123755 (123399)	Loss/tok 6.0883 (6.3748)
0: VALIDATION [0][50/80]	Time 0.021 (0.037)	Data 1.66e-03 (1.71e-03)	Tok/s 124093 (122969)	Loss/tok 5.8339 (6.3352)
0: VALIDATION [0][60/80]	Time 0.018 (0.034)	Data 1.64e-03 (1.70e-03)	Tok/s 117747 (122319)	Loss/tok 6.0010 (6.3016)
0: VALIDATION [0][70/80]	Time 0.015 (0.032)	Data 1.65e-03 (1.69e-03)	Tok/s 109421 (120956)	Loss/tok 5.6654 (6.2687)
0: Saving model to gnmt/model_best.pth
0: Running evaluation on test set
0: TEST [0][9/24]	Time 0.6885 (1.1443)	Decoder iters 149.0 (149.0)	Tok/s 12139 (12698)
0: TEST [0][19/24]	Time 0.4142 (0.8317)	Decoder iters 149.0 (149.0)	Tok/s 10692 (12455)
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
0: Summary: Epoch: 0	Training Loss: 7.0057	Validation Loss: 6.2387	Test BLEU: 1.25
0: Performance: Epoch: 0	Training: 47278 Tok/s	Validation: 118262 Tok/s
0: Finished epoch 0
0: Starting epoch 1
0: Executing preallocation
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: Sampler for epoch 1 uses seed 3588440356
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: TRAIN [1][0/512]	Time 0.605 (0.000)	Data 1.40e-01 (0.00e+00)	Tok/s 38814 (0)	Loss/tok 5.5188 (5.5188)	LR 2.000e-03
0: TRAIN [1][10/512]	Time 0.326 (0.214)	Data 1.36e-04 (1.40e-04)	Tok/s 39664 (43858)	Loss/tok 5.0383 (5.0506)	LR 2.000e-03
0: TRAIN [1][20/512]	Time 0.093 (0.258)	Data 2.56e-04 (1.61e-04)	Tok/s 41415 (44150)	Loss/tok 4.2846 (5.0391)	LR 2.000e-03
Traceback (most recent call last):
  File "train.py", line 667, in <module>
    main()
  File "train.py", line 592, in main
    train_loss, train_perf = trainer.optimize(train_loader)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 352, in optimize
    output = self.feed_data(data_loader, training=True)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 236, in feed_data
    stats = self.iterate(src, tgt, update, training=training)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 191, in iterate
    self.fp_optimizer.step(loss, self.optimizer, self.scheduler,
  File "/workspace/examples/gnmt/seq2seq/train/fp_optimizers.py", line 181, in step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 256, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.67 GiB (GPU 0; 23.69 GiB total capacity; 15.61 GiB already allocated; 1.40 GiB free; 20.70 GiB reserved in total by PyTorch)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 6418) of binary: /opt/conda/bin/python3
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 1/3 attempts left; will restart worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=3
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_macipgyi/none_fd7bh39n/attempt_3/0/error.json
train.py:41: UserWarning: PyProf is unavailable
  warnings.warn('PyProf is unavailable')
0: thread affinity: {0, 32, 4, 36, 8, 40, 12, 44}
0: Collecting environment information...
0: PyTorch version: 1.10.0a0+ecc3718
Is debug build: False
CUDA used to build PyTorch: 11.4
ROCM used to build PyTorch: N/A

OS: Ubuntu 20.04.2 LTS (x86_64)
GCC version: (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0
Clang version: Could not collect
CMake version: version 3.21.0
Libc version: glibc-2.31

Python version: 3.8 (64-bit runtime)
Python platform: Linux-5.4.0-120-generic-x86_64-with-glibc2.10
Is CUDA available: True
CUDA runtime version: 11.4.48
GPU models and configuration: 
GPU 0: NVIDIA RTX A5500
GPU 1: NVIDIA RTX A5500
GPU 2: NVIDIA RTX A5500
GPU 3: NVIDIA RTX A5500
GPU 4: NVIDIA RTX A5500
GPU 5: NVIDIA RTX A5500
GPU 6: NVIDIA RTX A5500
GPU 7: NVIDIA RTX A5500

Nvidia driver version: 510.73.05
cuDNN version: Probably one of the following:
/usr/lib/x86_64-linux-gnu/libcudnn.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_adv_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_cnn_train.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_infer.so.8.2.2
/usr/lib/x86_64-linux-gnu/libcudnn_ops_train.so.8.2.2
HIP runtime version: N/A
MIOpen runtime version: N/A

Versions of relevant libraries:
[pip3] numpy==1.21.1
[pip3] nvidia-dlprof-pytorch-nvtx==1.3.0
[pip3] pytorch-quantization==2.1.0
[pip3] pytorch-transformers==1.1.0
[pip3] torch==1.10.0a0+ecc3718
[pip3] torchtext==0.11.0a0
[pip3] torchvision==0.11.0a0
[conda] magma-cuda110             2.5.2                         5    local
[conda] mkl                       2019.5                      281    conda-forge
[conda] mkl-include               2019.5                      281    conda-forge
[conda] numpy                     1.21.1           py38h9894fe3_0    conda-forge
[conda] nvidia-dlprof-pytorch-nvtx 1.3.0                    pypi_0    pypi
[conda] pytorch-quantization      2.1.0                    pypi_0    pypi
[conda] pytorch-transformers      1.1.0                    pypi_0    pypi
[conda] torch                     1.10.0a0+ecc3718          pypi_0    pypi
[conda] torchtext                 0.11.0a0                 pypi_0    pypi
[conda] torchvision               0.11.0a0                 pypi_0    pypi
0: Saving results to: gnmt
0: Run arguments: Namespace(affinity='socket_unique_interleaved', batching='bucketing', beam_size=5, bpe_codes='/data/gnmt/wmt16_de_en/bpe.32000', cov_penalty_factor=0.1, cuda=True, cudnn=True, dataset_dir='/data/gnmt/wmt16_de_en', decay_factor=0.5, decay_interval=None, decay_steps=4, dllog_file='train_log.json', dropout=0.2, env=True, epochs=2, eval=True, grad_clip=5.0, hidden_size=1024, init_scale=8192, intra_epoch_eval=0, keep_checkpoints=0, lang={'src': 'en', 'tgt': 'de'}, len_norm_const=5.0, len_norm_factor=0.6, local_rank=0, log_all_ranks=True, lr=0.002, math='fp32', num_buckets=5, num_layers=4, optimizer='Adam', optimizer_extra='{}', prealloc_mode='always', print_freq=10, profile=False, rank=0, remain_steps=0.666, resume=None, save_all=False, save_dir='gnmt', save_freq=5000, seed=2, shard_size=80, share_embedding=True, smoothing=0.1, src_lang='en', start_epoch=0, target_bleu=None, target_perf=None, test_batch_size=128, test_loader_workers=0, test_max_length=150, test_min_length=0, test_src='/data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en', test_tgt='/data/gnmt/wmt16_de_en/newstest2014.de', tgt_lang='de', train_batch_size=288, train_global_batch_size=None, train_iter_size=1, train_loader_workers=2, train_max_length=50, train_max_size=None, train_min_length=0, train_src='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en', train_tgt='/data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de', upscale_interval=128, val_batch_size=64, val_loader_workers=0, val_max_length=125, val_min_length=0, val_src='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en', val_tgt='/data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de', vocab='/data/gnmt/wmt16_de_en/vocab.bpe.32000', warmup=1, warmup_steps=200)
0: Using master seed from command line: 2
0: Worker 0 is using worker seed: 242886303
0: Building vocabulary from /data/gnmt/wmt16_de_en/vocab.bpe.32000
0: Size of vocabulary: 31794
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/train.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 50
0: Pairs before: 160078, after: 148120
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.en
0: Processing data from /data/gnmt/wmt16_de_en/newstest_dev.tok.clean.bpe.32000.de
0: Filtering data, min len: 0, max len: 125
0: Pairs before: 5100, after: 5100
0: Processing data from /data/gnmt/wmt16_de_en/newstest2014.tok.bpe.32000.en
0: Filtering data, min len: 0, max len: 150
0: Pairs before: 3003, after: 3003
0: GNMT(
  (encoder): ResidualRecurrentEncoder(
    (rnn_layers): ModuleList(
      (0): LSTM(1024, 1024, bidirectional=True)
      (1): LSTM(2048, 1024)
      (2): LSTM(1024, 1024)
      (3): LSTM(1024, 1024)
    )
    (dropout): Dropout(p=0.2, inplace=False)
    (embedder): Embedding(31794, 1024, padding_idx=0)
  )
  (decoder): ResidualRecurrentDecoder(
    (att_rnn): RecurrentAttention(
      (rnn): LSTM(1024, 1024)
      (attn): BahdanauAttention(
        (linear_q): Linear(in_features=1024, out_features=1024, bias=False)
        (linear_k): Linear(in_features=1024, out_features=1024, bias=False)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (rnn_layers): ModuleList(
      (0): LSTM(2048, 1024)
      (1): LSTM(2048, 1024)
      (2): LSTM(2048, 1024)
    )
    (embedder): Embedding(31794, 1024, padding_idx=0)
    (classifier): Classifier(
      (classifier): Linear(in_features=1024, out_features=31794, bias=True)
    )
    (dropout): Dropout(p=0.2, inplace=False)
  )
)
0: Building LabelSmoothingLoss (smoothing: 0.1)
0: Training optimizer config: {'optimizer': 'Adam', 'lr': 0.002}
0: Training LR schedule config: {'warmup_steps': 200, 'remain_steps': 0.666, 'decay_interval': None, 'decay_steps': 4, 'decay_factor': 0.5}
0: Number of parameters: 159593523
/opt/conda/lib/python3.8/site-packages/torch/_tensor.py:557: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.
To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /opt/pytorch/pytorch/aten/src/ATen/native/BinaryOps.cpp:461.)
  return torch.floor_divide(self, other)
0: Saving state of the tokenizer
0: Initializing fp32 optimizer
0: Using optimizer: Adam (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    eps: 1e-08
    lr: 0.002
    weight_decay: 0
)
0: Scheduler warmup steps: 200
0: Scheduler remain steps: 681
0: Scheduler decay interval: 85
0: Scheduler decay factor: 0.5
0: Scheduler max decay steps: 4
0: Starting epoch 0
0: Executing preallocation
0: Sampler for epoch 0 uses seed 364522461
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
0: TRAIN [0][0/512]	Time 0.529 (0.000)	Data 1.76e-01 (0.00e+00)	Tok/s 34407 (0)	Loss/tok 10.6826 (10.6826)	LR 2.047e-05
0: TRAIN [0][10/512]	Time 0.360 (0.304)	Data 1.51e-04 (1.68e-04)	Tok/s 49281 (49351)	Loss/tok 9.6510 (10.0869)	LR 2.576e-05
0: TRAIN [0][20/512]	Time 0.178 (0.295)	Data 2.35e-04 (1.69e-04)	Tok/s 43907 (47749)	Loss/tok 9.0237 (9.7562)	LR 3.244e-05
0: TRAIN [0][30/512]	Time 0.364 (0.280)	Data 1.61e-04 (1.61e-04)	Tok/s 49300 (47379)	Loss/tok 8.9566 (9.5292)	LR 4.083e-05
0: TRAIN [0][40/512]	Time 0.364 (0.283)	Data 1.45e-04 (1.66e-04)	Tok/s 49153 (47300)	Loss/tok 8.7569 (9.3632)	LR 5.141e-05
0: TRAIN [0][50/512]	Time 0.177 (0.276)	Data 2.80e-04 (1.66e-04)	Tok/s 44238 (46988)	Loss/tok 8.3355 (9.2383)	LR 6.472e-05
0: TRAIN [0][60/512]	Time 0.359 (0.277)	Data 3.72e-04 (1.83e-04)	Tok/s 50863 (47012)	Loss/tok 8.4244 (9.1072)	LR 8.148e-05
0: TRAIN [0][70/512]	Time 0.178 (0.282)	Data 1.43e-04 (1.92e-04)	Tok/s 44538 (47103)	Loss/tok 7.9554 (8.9796)	LR 1.026e-04
0: TRAIN [0][80/512]	Time 0.098 (0.285)	Data 1.45e-04 (2.00e-04)	Tok/s 39655 (47161)	Loss/tok 7.7622 (8.8664)	LR 1.291e-04
0: TRAIN [0][90/512]	Time 0.177 (0.287)	Data 4.27e-04 (2.08e-04)	Tok/s 44443 (47126)	Loss/tok 7.6302 (8.7666)	LR 1.626e-04
0: TRAIN [0][100/512]	Time 0.266 (0.289)	Data 1.53e-04 (2.11e-04)	Tok/s 48801 (47229)	Loss/tok 7.7170 (8.6710)	LR 2.047e-04
0: TRAIN [0][110/512]	Time 0.362 (0.289)	Data 1.57e-04 (2.09e-04)	Tok/s 50327 (47262)	Loss/tok 7.8579 (8.5894)	LR 2.576e-04
0: TRAIN [0][120/512]	Time 0.182 (0.290)	Data 3.67e-04 (2.09e-04)	Tok/s 43771 (47295)	Loss/tok 7.4421 (8.5169)	LR 3.244e-04
0: TRAIN [0][130/512]	Time 0.272 (0.291)	Data 1.31e-04 (2.11e-04)	Tok/s 48400 (47315)	Loss/tok 7.7006 (8.4554)	LR 4.083e-04
0: TRAIN [0][140/512]	Time 0.265 (0.291)	Data 2.02e-04 (2.12e-04)	Tok/s 48888 (47371)	Loss/tok 7.5682 (8.4034)	LR 5.141e-04
0: TRAIN [0][150/512]	Time 0.180 (0.289)	Data 3.72e-04 (2.14e-04)	Tok/s 43740 (47301)	Loss/tok 7.3491 (8.3586)	LR 6.472e-04
0: TRAIN [0][160/512]	Time 0.179 (0.288)	Data 1.50e-04 (2.11e-04)	Tok/s 43585 (47256)	Loss/tok 7.3357 (8.3169)	LR 8.148e-04
0: TRAIN [0][170/512]	Time 0.098 (0.287)	Data 1.49e-04 (2.07e-04)	Tok/s 39713 (47239)	Loss/tok 6.9916 (8.2766)	LR 1.026e-03
0: TRAIN [0][180/512]	Time 0.271 (0.287)	Data 1.43e-04 (2.07e-04)	Tok/s 47243 (47252)	Loss/tok 7.6093 (8.2435)	LR 1.291e-03
0: TRAIN [0][190/512]	Time 0.476 (0.287)	Data 2.83e-04 (2.07e-04)	Tok/s 49288 (47270)	Loss/tok 7.7467 (8.2094)	LR 1.626e-03
0: TRAIN [0][200/512]	Time 0.179 (0.287)	Data 1.40e-04 (2.05e-04)	Tok/s 43771 (47267)	Loss/tok 7.2472 (8.1773)	LR 2.000e-03
0: TRAIN [0][210/512]	Time 0.176 (0.285)	Data 1.45e-04 (2.03e-04)	Tok/s 44873 (47186)	Loss/tok 7.1523 (8.1471)	LR 2.000e-03
0: TRAIN [0][220/512]	Time 0.368 (0.283)	Data 1.45e-04 (2.01e-04)	Tok/s 49088 (47164)	Loss/tok 7.3274 (8.1106)	LR 2.000e-03
0: TRAIN [0][230/512]	Time 0.100 (0.283)	Data 1.48e-04 (1.99e-04)	Tok/s 38079 (47154)	Loss/tok 6.6182 (8.0731)	LR 2.000e-03
0: TRAIN [0][240/512]	Time 0.271 (0.282)	Data 1.42e-04 (1.97e-04)	Tok/s 47974 (47134)	Loss/tok 6.9051 (8.0338)	LR 2.000e-03
0: TRAIN [0][250/512]	Time 0.098 (0.282)	Data 1.97e-04 (1.97e-04)	Tok/s 40107 (47129)	Loss/tok 6.3151 (7.9955)	LR 2.000e-03
0: TRAIN [0][260/512]	Time 0.180 (0.282)	Data 1.43e-04 (1.96e-04)	Tok/s 43040 (47116)	Loss/tok 6.6124 (7.9562)	LR 2.000e-03
0: TRAIN [0][270/512]	Time 0.267 (0.281)	Data 1.45e-04 (1.95e-04)	Tok/s 48391 (47142)	Loss/tok 6.7968 (7.9163)	LR 2.000e-03
0: TRAIN [0][280/512]	Time 0.361 (0.283)	Data 1.35e-04 (1.95e-04)	Tok/s 49717 (47185)	Loss/tok 6.9028 (7.8710)	LR 2.000e-03
0: TRAIN [0][290/512]	Time 0.366 (0.284)	Data 1.42e-04 (1.94e-04)	Tok/s 49491 (47211)	Loss/tok 6.7520 (7.8255)	LR 2.000e-03
0: TRAIN [0][300/512]	Time 0.361 (0.285)	Data 1.88e-04 (1.93e-04)	Tok/s 50338 (47207)	Loss/tok 6.5702 (7.7825)	LR 2.000e-03
0: TRAIN [0][310/512]	Time 0.181 (0.284)	Data 2.95e-04 (1.93e-04)	Tok/s 42476 (47158)	Loss/tok 6.2037 (7.7472)	LR 2.000e-03
0: TRAIN [0][320/512]	Time 0.180 (0.284)	Data 1.42e-04 (1.92e-04)	Tok/s 43255 (47157)	Loss/tok 6.0556 (7.7062)	LR 2.000e-03
0: TRAIN [0][330/512]	Time 0.177 (0.286)	Data 2.58e-04 (1.91e-04)	Tok/s 44335 (47177)	Loss/tok 5.9406 (7.6622)	LR 2.000e-03
0: TRAIN [0][340/512]	Time 0.265 (0.288)	Data 2.89e-04 (1.92e-04)	Tok/s 48549 (47213)	Loss/tok 6.1586 (7.6173)	LR 2.000e-03
0: TRAIN [0][350/512]	Time 0.362 (0.288)	Data 1.83e-04 (1.90e-04)	Tok/s 50006 (47235)	Loss/tok 6.3160 (7.5773)	LR 2.000e-03
0: TRAIN [0][360/512]	Time 0.272 (0.289)	Data 1.55e-04 (1.89e-04)	Tok/s 48332 (47243)	Loss/tok 6.0118 (7.5371)	LR 2.000e-03
0: TRAIN [0][370/512]	Time 0.267 (0.289)	Data 1.80e-04 (1.89e-04)	Tok/s 48523 (47251)	Loss/tok 6.0152 (7.4977)	LR 2.000e-03
0: TRAIN [0][380/512]	Time 0.366 (0.290)	Data 1.85e-04 (1.88e-04)	Tok/s 49872 (47283)	Loss/tok 6.0980 (7.4545)	LR 2.000e-03
0: TRAIN [0][390/512]	Time 0.365 (0.291)	Data 1.84e-04 (1.88e-04)	Tok/s 49619 (47302)	Loss/tok 6.0855 (7.4140)	LR 2.000e-03
0: TRAIN [0][400/512]	Time 0.096 (0.292)	Data 1.50e-04 (1.87e-04)	Tok/s 40143 (47286)	Loss/tok 5.2016 (7.3773)	LR 2.000e-03
0: TRAIN [0][410/512]	Time 0.268 (0.293)	Data 1.43e-04 (1.87e-04)	Tok/s 49016 (47289)	Loss/tok 5.8515 (7.3395)	LR 2.000e-03
0: TRAIN [0][420/512]	Time 0.263 (0.292)	Data 2.63e-04 (1.86e-04)	Tok/s 49613 (47270)	Loss/tok 5.8054 (7.3083)	LR 2.000e-03
0: TRAIN [0][430/512]	Time 0.267 (0.291)	Data 1.44e-04 (1.85e-04)	Tok/s 49041 (47271)	Loss/tok 5.7485 (7.2752)	LR 2.000e-03
0: TRAIN [0][440/512]	Time 0.362 (0.291)	Data 2.84e-04 (1.85e-04)	Tok/s 50405 (47266)	Loss/tok 5.8094 (7.2408)	LR 2.000e-03
0: TRAIN [0][450/512]	Time 0.269 (0.291)	Data 1.47e-04 (1.85e-04)	Tok/s 48868 (47298)	Loss/tok 5.6568 (7.2053)	LR 2.000e-03
0: TRAIN [0][460/512]	Time 0.371 (0.292)	Data 1.46e-04 (1.85e-04)	Tok/s 48366 (47299)	Loss/tok 5.7677 (7.1700)	LR 2.000e-03
0: TRAIN [0][470/512]	Time 0.266 (0.292)	Data 2.68e-04 (1.85e-04)	Tok/s 48984 (47304)	Loss/tok 5.4221 (7.1358)	LR 2.000e-03
0: TRAIN [0][480/512]	Time 0.266 (0.292)	Data 1.49e-04 (1.84e-04)	Tok/s 48892 (47300)	Loss/tok 5.3730 (7.1034)	LR 2.000e-03
0: TRAIN [0][490/512]	Time 0.178 (0.292)	Data 1.83e-04 (1.84e-04)	Tok/s 43979 (47299)	Loss/tok 4.9613 (7.0703)	LR 2.000e-03
0: TRAIN [0][500/512]	Time 0.180 (0.292)	Data 1.84e-04 (1.84e-04)	Tok/s 43221 (47298)	Loss/tok 4.8709 (7.0364)	LR 2.000e-03
0: TRAIN [0][510/512]	Time 0.179 (0.290)	Data 7.75e-05 (1.89e-04)	Tok/s 43316 (47267)	Loss/tok 4.8307 (7.0089)	LR 2.000e-03
0: Running validation on dev set
0: Executing preallocation
0: VALIDATION [0][0/80]	Time 0.122 (0.000)	Data 2.36e-03 (0.00e+00)	Tok/s 85643 (0)	Loss/tok 6.7592 (6.7592)
0: VALIDATION [0][10/80]	Time 0.046 (0.057)	Data 1.81e-03 (1.84e-03)	Tok/s 128116 (121238)	Loss/tok 6.5034 (6.5878)
0: VALIDATION [0][20/80]	Time 0.036 (0.049)	Data 1.71e-03 (1.80e-03)	Tok/s 127408 (122922)	Loss/tok 6.1855 (6.4983)
0: VALIDATION [0][30/80]	Time 0.032 (0.044)	Data 1.70e-03 (1.77e-03)	Tok/s 122957 (123615)	Loss/tok 6.0206 (6.4226)
0: VALIDATION [0][40/80]	Time 0.026 (0.040)	Data 1.70e-03 (1.75e-03)	Tok/s 123512 (123401)	Loss/tok 6.0883 (6.3748)
0: VALIDATION [0][50/80]	Time 0.021 (0.037)	Data 1.68e-03 (1.73e-03)	Tok/s 123998 (122973)	Loss/tok 5.8339 (6.3352)
0: VALIDATION [0][60/80]	Time 0.018 (0.034)	Data 1.68e-03 (1.72e-03)	Tok/s 117173 (122338)	Loss/tok 6.0010 (6.3016)
0: VALIDATION [0][70/80]	Time 0.015 (0.032)	Data 1.66e-03 (1.71e-03)	Tok/s 109368 (120920)	Loss/tok 5.6654 (6.2687)
0: Saving model to gnmt/model_best.pth
0: Running evaluation on test set
0: TEST [0][9/24]	Time 0.6896 (1.1441)	Decoder iters 149.0 (149.0)	Tok/s 12119 (12698)
0: TEST [0][19/24]	Time 0.4155 (0.8325)	Decoder iters 149.0 (149.0)	Tok/s 10659 (12434)
0: Running sacrebleu (parameters: --score-only -lc --tokenize intl)
0: Finished evaluation on test set
0: Summary: Epoch: 0	Training Loss: 7.0057	Validation Loss: 6.2387	Test BLEU: 1.25
0: Performance: Epoch: 0	Training: 47267 Tok/s	Validation: 118211 Tok/s
0: Finished epoch 0
0: Starting epoch 1
0: Executing preallocation
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: Sampler for epoch 1 uses seed 3588440356
[W pthreadpool-cpp.cc:99] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)
0: TRAIN [1][0/512]	Time 0.596 (0.000)	Data 1.29e-01 (0.00e+00)	Tok/s 39406 (0)	Loss/tok 5.5188 (5.5188)	LR 2.000e-03
0: TRAIN [1][10/512]	Time 0.323 (0.214)	Data 1.35e-04 (1.45e-04)	Tok/s 40041 (44052)	Loss/tok 5.0383 (5.0506)	LR 2.000e-03
0: TRAIN [1][20/512]	Time 0.099 (0.258)	Data 1.38e-04 (1.54e-04)	Tok/s 38668 (44119)	Loss/tok 4.2846 (5.0391)	LR 2.000e-03
Traceback (most recent call last):
  File "train.py", line 667, in <module>
    main()
  File "train.py", line 592, in main
    train_loss, train_perf = trainer.optimize(train_loader)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 352, in optimize
    output = self.feed_data(data_loader, training=True)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 236, in feed_data
    stats = self.iterate(src, tgt, update, training=training)
  File "/workspace/examples/gnmt/seq2seq/train/trainer.py", line 191, in iterate
    self.fp_optimizer.step(loss, self.optimizer, self.scheduler,
  File "/workspace/examples/gnmt/seq2seq/train/fp_optimizers.py", line 181, in step
    loss.backward()
  File "/opt/conda/lib/python3.8/site-packages/torch/_tensor.py", line 256, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py", line 147, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 1.67 GiB (GPU 0; 23.69 GiB total capacity; 15.61 GiB already allocated; 1.40 GiB free; 20.70 GiB reserved in total by PyTorch)
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 7189) of binary: /opt/conda/bin/python3
ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (FAILED). Waiting 300 seconds for other agents to finish
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0004127025604248047 seconds
{"name": "torchelastic.worker.status.FAILED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "7189", "role": "default", "hostname": "0a54804b5a78", "state": "FAILED", "total_run_time": 800, "rdzv_backend": "static", "raw_error": "{\"message\": \"<NONE>\"}", "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [1]}", "agent_restarts": 3}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "0a54804b5a78", "state": "SUCCEEDED", "total_run_time": 800, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python3\"}", "agent_restarts": 3}}
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py:357: UserWarning: 

**********************************************************************
               CHILD PROCESS FAILED WITH NO ERROR_FILE                
**********************************************************************
CHILD PROCESS FAILED WITH NO ERROR_FILE
Child process 7189 (local_rank 0) FAILED (exitcode 1)
Error msg: Process failed with exitcode 1
Without writing an error file to <N/A>.
While this DOES NOT affect the correctness of your application,
no trace information about the error will be available for inspection.
Consider decorating your top level entrypoint function with
torch.distributed.elastic.multiprocessing.errors.record. Example:

  from torch.distributed.elastic.multiprocessing.errors import record

  @record
  def trainer_main(args):
     # do train
**********************************************************************
  warnings.warn(_no_error_file_warning_msg(rank, failure))
Traceback (most recent call last):
  File "/opt/conda/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/opt/conda/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 173, in <module>
    main()
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launch.py", line 169, in main
    run(args)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/run.py", line 622, in run
    elastic_launch(
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 116, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 351, in wrapper
    return f(*args, **kwargs)
  File "/opt/conda/lib/python3.8/site-packages/torch/distributed/launcher/api.py", line 245, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
**********************************************************************************************************************************************************************************************************************************************************
                                                                                                                     train.py FAILED                                                                                                                      
==========================================================================================================================================================================================================================================================
Root Cause:
[0]:
  time: 2022-06-30_20:07:30
  rank: 0 (local_rank: 0)
  exitcode: 1 (pid: 7189)
  error_file: <N/A>
  msg: "Process failed with exitcode 1"
==========================================================================================================================================================================================================================================================
Other Failures:
  <NO_OTHER_FAILURES>
**********************************************************************************************************************************************************************************************************************************************************

DONE!
