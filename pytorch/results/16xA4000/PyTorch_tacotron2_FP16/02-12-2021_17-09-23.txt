train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-12-02 17:09:25.456900 - PARAMETER output : ./ 
DLL 2021-12-02 17:09:25.456971 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-12-02 17:09:25.456993 - PARAMETER model_name : Tacotron2 
DLL 2021-12-02 17:09:25.457011 - PARAMETER log_file : nvlog.json 
DLL 2021-12-02 17:09:25.457027 - PARAMETER anneal_steps : None 
DLL 2021-12-02 17:09:25.457045 - PARAMETER anneal_factor : 0.1 
DLL 2021-12-02 17:09:25.457061 - PARAMETER epochs : 3 
DLL 2021-12-02 17:09:25.457078 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-12-02 17:09:25.457094 - PARAMETER checkpoint_path :  
DLL 2021-12-02 17:09:25.457112 - PARAMETER resume_from_last : False 
DLL 2021-12-02 17:09:25.457129 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-12-02 17:09:25.457147 - PARAMETER amp : False 
DLL 2021-12-02 17:09:25.457165 - PARAMETER cudnn_enabled : True 
DLL 2021-12-02 17:09:25.457181 - PARAMETER cudnn_benchmark : False 
DLL 2021-12-02 17:09:25.457203 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-12-02 17:09:25.457219 - PARAMETER use_saved_learning_rate : False 
DLL 2021-12-02 17:09:25.457234 - PARAMETER learning_rate : 0.0 
DLL 2021-12-02 17:09:25.457251 - PARAMETER weight_decay : 1e-06 
DLL 2021-12-02 17:09:25.457268 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-12-02 17:09:25.457285 - PARAMETER batch_size : 48 
DLL 2021-12-02 17:09:25.457303 - PARAMETER grad_clip : 5.0 
DLL 2021-12-02 17:09:25.457320 - PARAMETER load_mel_from_disk : False 
DLL 2021-12-02 17:09:25.457336 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-12-02 17:09:25.457352 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-12-02 17:09:25.457367 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-12-02 17:09:25.457386 - PARAMETER max_wav_value : 32768.0 
DLL 2021-12-02 17:09:25.457402 - PARAMETER sampling_rate : 22050 
DLL 2021-12-02 17:09:25.457418 - PARAMETER filter_length : 1024 
DLL 2021-12-02 17:09:25.457434 - PARAMETER hop_length : 256 
DLL 2021-12-02 17:09:25.457449 - PARAMETER win_length : 1024 
DLL 2021-12-02 17:09:25.457465 - PARAMETER mel_fmin : 0.0 
DLL 2021-12-02 17:09:25.457480 - PARAMETER mel_fmax : 8000.0 
DLL 2021-12-02 17:09:25.457496 - PARAMETER rank : 0 
DLL 2021-12-02 17:09:25.457511 - PARAMETER world_size : 16 
DLL 2021-12-02 17:09:25.457529 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-12-02 17:09:25.457545 - PARAMETER group_name : group_name 
DLL 2021-12-02 17:09:25.457560 - PARAMETER dist_backend : nccl 
DLL 2021-12-02 17:09:25.457575 - PARAMETER bench_class :  
DLL 2021-12-02 17:09:25.457593 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-12-02 17:10:04.711838 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-12-02 17:11:07.970385 - (0, 0) train_loss : 47.13754653930664 
DLL 2021-12-02 17:11:12.362193 - (0, 0) train_items_per_sec : 6409.570453760887 
DLL 2021-12-02 17:11:12.362283 - (0, 0) train_iter_time : 67.65039921599964 
DLL 2021-12-02 17:11:12.399672 - (0,) train_items_per_sec : 6409.570453760887 
DLL 2021-12-02 17:11:12.399717 - (0,) train_loss : 47.13754653930664 
DLL 2021-12-02 17:11:12.399900 - (0,) train_epoch_time : 70.39523930199357 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-12-02 17:11:13.344619 - (0, 1, 0) val_items_per_sec : 101396.5358097365 
DLL 2021-12-02 17:11:13.390563 - (0,) val_loss : 49.69483184814453 
DLL 2021-12-02 17:11:13.390661 - (0,) val_items_per_sec : 101396.5358097365 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-12-02 17:11:14.906453 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-12-02 17:11:16.883364 - (1, 0) train_loss : 47.57679748535156 
DLL 2021-12-02 17:11:18.802745 - (1, 0) train_items_per_sec : 110957.36751681574 
DLL 2021-12-02 17:11:18.802844 - (1, 0) train_iter_time : 3.896334327997465 
DLL 2021-12-02 17:11:18.860823 - (1,) train_items_per_sec : 110957.36751681574 
DLL 2021-12-02 17:11:18.860955 - (1,) train_loss : 47.57679748535156 
DLL 2021-12-02 17:11:18.860993 - (1,) train_epoch_time : 4.998598382000637 
DLL 2021-12-02 17:11:19.868504 - (1, 2, 0) val_items_per_sec : 101452.18019782433 
DLL 2021-12-02 17:11:19.926099 - (1,) val_loss : 49.69902038574219 
DLL 2021-12-02 17:11:19.926207 - (1,) val_items_per_sec : 101452.18019782433 
DLL 2021-12-02 17:11:21.106478 - (2, 0) glob_iter/iters_per_epoch : 2/1 
DLL 2021-12-02 17:11:22.913831 - (2, 0) train_loss : 48.03981018066406 
DLL 2021-12-02 17:11:24.830940 - (2, 0) train_items_per_sec : 117995.0190604205 
DLL 2021-12-02 17:11:24.831038 - (2, 0) train_iter_time : 3.7245046740063117 
DLL 2021-12-02 17:11:24.885164 - (2,) train_items_per_sec : 117995.0190604205 
DLL 2021-12-02 17:11:24.885302 - (2,) train_loss : 48.03981018066406 
DLL 2021-12-02 17:11:24.885346 - (2,) train_epoch_time : 4.9577018809941364 
DLL 2021-12-02 17:11:25.910153 - (2, 3, 0) val_items_per_sec : 100751.32533681038 
DLL 2021-12-02 17:11:25.969177 - (2,) val_loss : 49.70542526245117 
DLL 2021-12-02 17:11:25.969268 - (2,) val_items_per_sec : 100751.32533681038 
DLL 2021-12-02 17:11:25.970921 - () run_time : 105.88213012999768 
DLL 2021-12-02 17:11:25.971010 - () val_loss : 49.70542526245117 
DLL 2021-12-02 17:11:25.971057 - () train_items_per_sec : 117995.0190604205 
DONE!
