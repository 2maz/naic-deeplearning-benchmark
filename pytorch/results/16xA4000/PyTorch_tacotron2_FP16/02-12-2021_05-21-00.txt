train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-12-02 05:21:02.017900 - PARAMETER output : ./ 
DLL 2021-12-02 05:21:02.017963 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-12-02 05:21:02.017986 - PARAMETER model_name : Tacotron2 
DLL 2021-12-02 05:21:02.018004 - PARAMETER log_file : nvlog.json 
DLL 2021-12-02 05:21:02.018021 - PARAMETER anneal_steps : None 
DLL 2021-12-02 05:21:02.018040 - PARAMETER anneal_factor : 0.1 
DLL 2021-12-02 05:21:02.018057 - PARAMETER epochs : 3 
DLL 2021-12-02 05:21:02.018074 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-12-02 05:21:02.018091 - PARAMETER checkpoint_path :  
DLL 2021-12-02 05:21:02.018110 - PARAMETER resume_from_last : False 
DLL 2021-12-02 05:21:02.018128 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-12-02 05:21:02.018145 - PARAMETER amp : False 
DLL 2021-12-02 05:21:02.018164 - PARAMETER cudnn_enabled : True 
DLL 2021-12-02 05:21:02.018180 - PARAMETER cudnn_benchmark : False 
DLL 2021-12-02 05:21:02.018200 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-12-02 05:21:02.018217 - PARAMETER use_saved_learning_rate : False 
DLL 2021-12-02 05:21:02.018233 - PARAMETER learning_rate : 0.0 
DLL 2021-12-02 05:21:02.018249 - PARAMETER weight_decay : 1e-06 
DLL 2021-12-02 05:21:02.018267 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-12-02 05:21:02.018283 - PARAMETER batch_size : 48 
DLL 2021-12-02 05:21:02.018299 - PARAMETER grad_clip : 5.0 
DLL 2021-12-02 05:21:02.018314 - PARAMETER load_mel_from_disk : False 
DLL 2021-12-02 05:21:02.018330 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-12-02 05:21:02.018346 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-12-02 05:21:02.018362 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-12-02 05:21:02.018381 - PARAMETER max_wav_value : 32768.0 
DLL 2021-12-02 05:21:02.018398 - PARAMETER sampling_rate : 22050 
DLL 2021-12-02 05:21:02.018414 - PARAMETER filter_length : 1024 
DLL 2021-12-02 05:21:02.018430 - PARAMETER hop_length : 256 
DLL 2021-12-02 05:21:02.018446 - PARAMETER win_length : 1024 
DLL 2021-12-02 05:21:02.018462 - PARAMETER mel_fmin : 0.0 
DLL 2021-12-02 05:21:02.018478 - PARAMETER mel_fmax : 8000.0 
DLL 2021-12-02 05:21:02.018493 - PARAMETER rank : 0 
DLL 2021-12-02 05:21:02.018509 - PARAMETER world_size : 16 
DLL 2021-12-02 05:21:02.018528 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-12-02 05:21:02.018544 - PARAMETER group_name : group_name 
DLL 2021-12-02 05:21:02.018559 - PARAMETER dist_backend : nccl 
DLL 2021-12-02 05:21:02.018575 - PARAMETER bench_class :  
DLL 2021-12-02 05:21:02.018591 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-12-02 05:21:40.660787 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-12-02 05:22:43.590315 - (0, 0) train_loss : 46.8767204284668 
DLL 2021-12-02 05:22:48.027764 - (0, 0) train_items_per_sec : 6436.533683796277 
DLL 2021-12-02 05:22:48.027884 - (0, 0) train_iter_time : 67.3670054879999 
DLL 2021-12-02 05:22:48.064845 - (0,) train_items_per_sec : 6436.533683796277 
DLL 2021-12-02 05:22:48.064986 - (0,) train_loss : 46.8767204284668 
DLL 2021-12-02 05:22:48.065347 - (0,) train_epoch_time : 70.98124958899962 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-12-02 05:22:49.042064 - (0, 1, 0) val_items_per_sec : 95658.20691364574 
DLL 2021-12-02 05:22:49.101814 - (0,) val_loss : 49.573028564453125 
DLL 2021-12-02 05:22:49.101966 - (0,) val_items_per_sec : 95658.20691364574 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-12-02 05:22:50.601911 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-12-02 05:22:52.657432 - (1, 0) train_loss : 47.31401824951172 
DLL 2021-12-02 05:22:54.568872 - (1, 0) train_items_per_sec : 108980.7632392573 
DLL 2021-12-02 05:22:54.569000 - (1, 0) train_iter_time : 3.967002864999813 
DLL 2021-12-02 05:22:54.627069 - (1,) train_items_per_sec : 108980.7632392573 
DLL 2021-12-02 05:22:54.627172 - (1,) train_loss : 47.31401824951172 
DLL 2021-12-02 05:22:54.627194 - (1,) train_epoch_time : 5.049482637999972 
DLL 2021-12-02 05:22:55.636694 - (1, 2, 0) val_items_per_sec : 99269.1174342478 
DLL 2021-12-02 05:22:55.691474 - (1,) val_loss : 49.56886291503906 
DLL 2021-12-02 05:22:55.691634 - (1,) val_items_per_sec : 99269.1174342478 
DLL 2021-12-02 05:22:56.863106 - (2, 0) glob_iter/iters_per_epoch : 2/1 
DLL 2021-12-02 05:22:58.648883 - (2, 0) train_loss : 47.78031921386719 
DLL 2021-12-02 05:23:00.565507 - (2, 0) train_items_per_sec : 118698.208065927 
DLL 2021-12-02 05:23:00.565632 - (2, 0) train_iter_time : 3.7024400549998973 
DLL 2021-12-02 05:23:00.637544 - (2,) train_items_per_sec : 118698.208065927 
DLL 2021-12-02 05:23:00.637690 - (2,) train_loss : 47.78031921386719 
DLL 2021-12-02 05:23:00.637739 - (2,) train_epoch_time : 4.944547002000036 
DLL 2021-12-02 05:23:01.631804 - (2, 3, 0) val_items_per_sec : 104044.4438316053 
DLL 2021-12-02 05:23:01.708653 - (2,) val_loss : 49.56371307373047 
DLL 2021-12-02 05:23:01.708818 - (2,) val_items_per_sec : 104044.4438316053 
DLL 2021-12-02 05:23:01.711033 - () run_time : 105.08194713600005 
DLL 2021-12-02 05:23:01.711120 - () val_loss : 49.56371307373047 
DLL 2021-12-02 05:23:01.711166 - () train_items_per_sec : 118698.208065927 
DONE!
