train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-03 07:03:07.182341 - PARAMETER output : ./ 
DLL 2021-06-03 07:03:07.182391 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-03 07:03:07.182409 - PARAMETER model_name : Tacotron2 
DLL 2021-06-03 07:03:07.182423 - PARAMETER log_file : nvlog.json 
DLL 2021-06-03 07:03:07.182436 - PARAMETER anneal_steps : None 
DLL 2021-06-03 07:03:07.182450 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-03 07:03:07.182463 - PARAMETER epochs : 2 
DLL 2021-06-03 07:03:07.182476 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-03 07:03:07.182489 - PARAMETER checkpoint_path :  
DLL 2021-06-03 07:03:07.182501 - PARAMETER resume_from_last : False 
DLL 2021-06-03 07:03:07.182515 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-03 07:03:07.182528 - PARAMETER amp : False 
DLL 2021-06-03 07:03:07.182540 - PARAMETER cudnn_enabled : True 
DLL 2021-06-03 07:03:07.182552 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-03 07:03:07.182565 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-03 07:03:07.182577 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-03 07:03:07.182589 - PARAMETER learning_rate : 0.0 
DLL 2021-06-03 07:03:07.182601 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-03 07:03:07.182615 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-03 07:03:07.182628 - PARAMETER batch_size : 80 
DLL 2021-06-03 07:03:07.182640 - PARAMETER grad_clip : 5.0 
DLL 2021-06-03 07:03:07.182652 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-03 07:03:07.182665 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-03 07:03:07.182677 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-03 07:03:07.182689 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-03 07:03:07.182704 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-03 07:03:07.182716 - PARAMETER sampling_rate : 22050 
DLL 2021-06-03 07:03:07.182729 - PARAMETER filter_length : 1024 
DLL 2021-06-03 07:03:07.182741 - PARAMETER hop_length : 256 
DLL 2021-06-03 07:03:07.182753 - PARAMETER win_length : 1024 
DLL 2021-06-03 07:03:07.182765 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-03 07:03:07.182777 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-03 07:03:07.182790 - PARAMETER rank : 0 
DLL 2021-06-03 07:03:07.182802 - PARAMETER world_size : 2 
DLL 2021-06-03 07:03:07.182814 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-03 07:03:07.182826 - PARAMETER group_name : group_name 
DLL 2021-06-03 07:03:07.182838 - PARAMETER dist_backend : nccl 
DLL 2021-06-03 07:03:07.182849 - PARAMETER bench_class :  
DLL 2021-06-03 07:03:07.182862 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2021-06-03 07:03:19.882446 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2021-06-03 07:03:33.026683 - (0, 0) train_loss : 45.482810974121094 
DLL 2021-06-03 07:03:35.994694 - (0, 0) train_items_per_sec : 5399.109353916596 
DLL 2021-06-03 07:03:35.994753 - (0, 0) train_iter_time : 16.11228710100022 
DLL 2021-06-03 07:03:35.998834 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2021-06-03 07:03:36.908804 - (0, 1) train_loss : 47.63774871826172 
DLL 2021-06-03 07:03:38.560271 - (0, 1) train_items_per_sec : 35995.77555192601 
DLL 2021-06-03 07:03:38.560339 - (0, 1) train_iter_time : 2.56143946300017 
DLL 2021-06-03 07:03:38.568387 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2021-06-03 07:03:39.182138 - (0, 2) train_loss : 47.25071716308594 
DLL 2021-06-03 07:03:41.078799 - (0, 2) train_items_per_sec : 36316.229669427434 
DLL 2021-06-03 07:03:41.078864 - (0, 2) train_iter_time : 2.510420294999676 
DLL 2021-06-03 07:03:41.105970 - (0,) train_items_per_sec : 25903.704858423345 
DLL 2021-06-03 07:03:41.106037 - (0,) train_loss : 47.25071716308594 
DLL 2021-06-03 07:03:41.106055 - (0,) train_epoch_time : 22.49761975399997 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-03 07:03:42.465086 - (0, 3, 0) val_items_per_sec : 113404.64070688935 
DLL 2021-06-03 07:03:42.508108 - (0,) val_loss : 45.809967041015625 
DLL 2021-06-03 07:03:42.508217 - (0,) val_items_per_sec : 113404.64070688935 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-03 07:03:44.091115 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2021-06-03 07:03:45.126711 - (1, 0) train_loss : 45.7866325378418 
DLL 2021-06-03 07:03:46.820349 - (1, 0) train_items_per_sec : 32425.304838486914 
DLL 2021-06-03 07:03:46.820418 - (1, 0) train_iter_time : 2.729257301999496 
DLL 2021-06-03 07:03:46.831482 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2021-06-03 07:03:48.225875 - (1, 1) train_loss : 46.8297119140625 
DLL 2021-06-03 07:03:49.823887 - (1, 1) train_items_per_sec : 30428.283419268188 
DLL 2021-06-03 07:03:49.823956 - (1, 1) train_iter_time : 2.9924133000004076 
DLL 2021-06-03 07:03:49.835722 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2021-06-03 07:03:50.456729 - (1, 2) train_loss : 46.9932861328125 
DLL 2021-06-03 07:03:52.040786 - (1, 2) train_items_per_sec : 41221.724086319 
DLL 2021-06-03 07:03:52.040854 - (1, 2) train_iter_time : 2.205075163999936 
DLL 2021-06-03 07:03:52.088593 - (1,) train_items_per_sec : 34691.770781358035 
DLL 2021-06-03 07:03:52.088666 - (1,) train_loss : 46.9932861328125 
DLL 2021-06-03 07:03:52.088683 - (1,) train_epoch_time : 9.265388904999782 
DLL 2021-06-03 07:03:53.426039 - (1, 6, 0) val_items_per_sec : 115487.42652347256 
DLL 2021-06-03 07:03:53.471873 - (1,) val_loss : 45.803245544433594 
DLL 2021-06-03 07:03:53.471946 - (1,) val_items_per_sec : 115487.42652347256 
DLL 2021-06-03 07:03:53.473647 - () run_time : 40.4964884230003 
DLL 2021-06-03 07:03:53.473677 - () val_loss : 45.803245544433594 
DLL 2021-06-03 07:03:53.473694 - () train_items_per_sec : 34691.770781358035 
DONE!
