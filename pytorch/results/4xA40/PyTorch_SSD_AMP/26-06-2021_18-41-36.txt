Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  1%|          | 624k/97.8M [00:00<00:16, 6.36MB/s]  1%|          | 1.02M/97.8M [00:00<00:09, 10.6MB/s]  1%|          | 616k/97.8M [00:00<00:16, 6.23MB/s]  0%|          | 416k/97.8M [00:00<00:24, 4.25MB/s]  5%|▍         | 4.66M/97.8M [00:00<00:11, 8.54MB/s]  5%|▌         | 5.12M/97.8M [00:00<00:07, 13.7MB/s]  2%|▏         | 1.98M/97.8M [00:00<00:13, 7.51MB/s]  1%|          | 1.14M/97.8M [00:00<00:20, 4.90MB/s]  9%|▉         | 8.77M/97.8M [00:00<00:08, 11.2MB/s] 10%|▉         | 9.29M/97.8M [00:00<00:05, 17.3MB/s]  5%|▌         | 4.91M/97.8M [00:00<00:10, 9.71MB/s]  3%|▎         | 3.22M/97.8M [00:00<00:15, 6.39MB/s] 12%|█▏        | 11.4M/97.8M [00:00<00:06, 13.7MB/s] 12%|█▏        | 11.9M/97.8M [00:00<00:04, 19.5MB/s]  8%|▊         | 8.22M/97.8M [00:00<00:07, 12.4MB/s]  5%|▌         | 4.95M/97.8M [00:00<00:12, 7.85MB/s] 15%|█▍        | 14.2M/97.8M [00:00<00:05, 16.3MB/s] 15%|█▌        | 15.0M/97.8M [00:00<00:03, 21.8MB/s] 12%|█▏        | 11.7M/97.8M [00:00<00:05, 15.4MB/s]  7%|▋         | 6.52M/97.8M [00:00<00:10, 9.32MB/s] 18%|█▊        | 17.9M/97.8M [00:00<00:04, 19.6MB/s] 19%|█▉        | 18.7M/97.8M [00:00<00:03, 25.1MB/s] 14%|█▍        | 14.1M/97.8M [00:00<00:05, 17.4MB/s]  8%|▊         | 7.93M/97.8M [00:00<00:09, 10.4MB/s] 22%|██▏       | 21.3M/97.8M [00:00<00:03, 22.7MB/s] 22%|██▏       | 21.9M/97.8M [00:00<00:02, 27.2MB/s] 18%|█▊        | 17.1M/97.8M [00:00<00:04, 20.2MB/s] 10%|▉         | 9.77M/97.8M [00:00<00:07, 12.1MB/s] 25%|██▍       | 24.3M/97.8M [00:00<00:03, 24.2MB/s] 26%|██▌       | 25.0M/97.8M [00:00<00:02, 28.4MB/s] 21%|██▏       | 20.9M/97.8M [00:00<00:03, 23.6MB/s] 12%|█▏        | 11.8M/97.8M [00:00<00:06, 13.8MB/s] 29%|██▊       | 28.0M/97.8M [00:00<00:02, 28.6MB/s] 28%|██▊       | 27.2M/97.8M [00:00<00:03, 24.5MB/s] 25%|██▌       | 24.6M/97.8M [00:00<00:02, 26.7MB/s] 14%|█▍        | 13.6M/97.8M [00:00<00:05, 15.2MB/s] 32%|███▏      | 31.1M/97.8M [00:01<00:02, 29.7MB/s] 31%|███       | 30.0M/97.8M [00:01<00:02, 25.7MB/s] 29%|██▊       | 28.1M/97.8M [00:01<00:02, 29.0MB/s] 16%|█▌        | 15.4M/97.8M [00:01<00:05, 16.0MB/s] 34%|███▎      | 32.9M/97.8M [00:01<00:02, 27.0MB/s] 35%|███▍      | 34.1M/97.8M [00:01<00:02, 29.7MB/s] 32%|███▏      | 31.6M/97.8M [00:01<00:02, 31.1MB/s] 18%|█▊        | 17.2M/97.8M [00:01<00:05, 16.8MB/s] 37%|███▋      | 35.8M/97.8M [00:01<00:02, 27.9MB/s] 38%|███▊      | 37.0M/97.8M [00:01<00:02, 29.8MB/s] 36%|███▌      | 35.1M/97.8M [00:01<00:02, 32.5MB/s] 19%|█▉        | 19.1M/97.8M [00:01<00:04, 17.5MB/s] 40%|███▉      | 38.6M/97.8M [00:01<00:02, 28.4MB/s] 41%|████      | 39.9M/97.8M [00:01<00:02, 29.3MB/s] 40%|███▉      | 38.7M/97.8M [00:01<00:01, 33.8MB/s] 21%|██▏       | 21.0M/97.8M [00:01<00:04, 18.2MB/s] 42%|████▏     | 41.5M/97.8M [00:01<00:02, 28.3MB/s] 43%|████▎     | 42.2M/97.8M [00:01<00:01, 34.6MB/s] 44%|████▍     | 42.8M/97.8M [00:01<00:01, 29.0MB/s] 23%|██▎       | 22.8M/97.8M [00:01<00:04, 18.3MB/s] 45%|████▌     | 44.3M/97.8M [00:01<00:01, 28.6MB/s] 47%|████▋     | 45.8M/97.8M [00:01<00:01, 35.6MB/s] 47%|████▋     | 45.8M/97.8M [00:01<00:01, 29.6MB/s] 25%|██▌       | 24.7M/97.8M [00:01<00:04, 18.7MB/s] 48%|████▊     | 47.2M/97.8M [00:01<00:01, 29.2MB/s] 51%|█████     | 49.6M/97.8M [00:01<00:01, 36.6MB/s] 50%|████▉     | 48.7M/97.8M [00:01<00:01, 29.0MB/s] 27%|██▋       | 26.5M/97.8M [00:01<00:04, 18.6MB/s] 51%|█████▏    | 50.2M/97.8M [00:01<00:01, 29.6MB/s] 55%|█████▍    | 53.5M/97.8M [00:01<00:01, 37.8MB/s] 53%|█████▎    | 51.5M/97.8M [00:01<00:01, 27.9MB/s] 29%|██▉       | 28.4M/97.8M [00:01<00:03, 18.4MB/s] 54%|█████▍    | 53.0M/97.8M [00:01<00:01, 29.6MB/s] 59%|█████▉    | 57.5M/97.8M [00:01<00:01, 39.0MB/s] 55%|█████▌    | 54.1M/97.8M [00:01<00:01, 27.3MB/s] 31%|███       | 30.1M/97.8M [00:01<00:03, 18.1MB/s] 57%|█████▋    | 56.0M/97.8M [00:01<00:01, 30.1MB/s] 63%|██████▎   | 61.5M/97.8M [00:01<00:00, 39.8MB/s] 58%|█████▊    | 56.8M/97.8M [00:01<00:01, 26.3MB/s] 33%|███▎      | 31.9M/97.8M [00:01<00:03, 17.9MB/s] 60%|██████    | 58.9M/97.8M [00:02<00:01, 29.7MB/s] 67%|██████▋   | 65.5M/97.8M [00:02<00:00, 40.4MB/s] 61%|██████    | 59.3M/97.8M [00:02<00:01, 25.7MB/s] 34%|███▍      | 33.6M/97.8M [00:02<00:03, 17.7MB/s] 63%|██████▎   | 61.8M/97.8M [00:02<00:01, 29.4MB/s] 71%|███████▏  | 69.8M/97.8M [00:02<00:00, 41.7MB/s] 63%|██████▎   | 61.8M/97.8M [00:02<00:01, 24.9MB/s] 36%|███▌      | 35.3M/97.8M [00:02<00:03, 17.3MB/s] 76%|███████▌  | 73.8M/97.8M [00:02<00:00, 41.8MB/s] 66%|██████▌   | 64.6M/97.8M [00:02<00:01, 29.1MB/s] 38%|███▊      | 37.1M/97.8M [00:02<00:03, 17.7MB/s] 66%|██████▌   | 64.2M/97.8M [00:02<00:01, 24.7MB/s] 80%|███████▉  | 78.0M/97.8M [00:02<00:00, 42.3MB/s] 69%|██████▉   | 67.4M/97.8M [00:02<00:01, 28.8MB/s] 40%|███▉      | 38.8M/97.8M [00:02<00:03, 17.6MB/s] 68%|██████▊   | 66.6M/97.8M [00:02<00:01, 24.5MB/s] 84%|████████▍ | 82.3M/97.8M [00:02<00:00, 43.0MB/s] 72%|███████▏  | 70.2M/97.8M [00:02<00:01, 28.4MB/s] 41%|████▏     | 40.5M/97.8M [00:02<00:03, 17.8MB/s] 71%|███████   | 69.0M/97.8M [00:02<00:01, 24.7MB/s] 88%|████████▊ | 86.4M/97.8M [00:02<00:00, 42.3MB/s] 75%|███████▍  | 72.9M/97.8M [00:02<00:00, 28.3MB/s] 44%|████▎     | 42.6M/97.8M [00:02<00:03, 18.9MB/s] 74%|███████▎  | 72.0M/97.8M [00:02<00:01, 26.4MB/s] 77%|███████▋  | 75.7M/97.8M [00:02<00:00, 28.8MB/s] 46%|████▌     | 45.1M/97.8M [00:02<00:02, 20.5MB/s] 77%|███████▋  | 74.8M/97.8M [00:02<00:00, 27.2MB/s] 81%|████████  | 78.9M/97.8M [00:02<00:00, 30.0MB/s] 93%|█████████▎| 90.5M/97.8M [00:02<00:00, 32.0MB/s] 49%|████▊     | 47.5M/97.8M [00:02<00:02, 21.8MB/s] 79%|███████▉  | 77.6M/97.8M [00:02<00:00, 27.9MB/s] 85%|████████▍ | 82.8M/97.8M [00:02<00:00, 32.5MB/s] 51%|█████▏    | 50.2M/97.8M [00:02<00:02, 23.3MB/s] 83%|████████▎ | 80.7M/97.8M [00:02<00:00, 29.1MB/s] 89%|████████▊ | 86.5M/97.8M [00:02<00:00, 34.2MB/s] 96%|█████████▌| 93.9M/97.8M [00:02<00:00, 25.3MB/s] 54%|█████▍    | 52.6M/97.8M [00:02<00:01, 23.8MB/s] 86%|████████▌ | 83.6M/97.8M [00:03<00:00, 29.4MB/s] 92%|█████████▏| 90.1M/97.8M [00:03<00:00, 35.2MB/s] 99%|█████████▉| 96.8M/97.8M [00:03<00:00, 25.5MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 33.2MB/s]
 56%|█████▌    | 54.9M/97.8M [00:03<00:01, 23.7MB/s] 88%|████████▊ | 86.5M/97.8M [00:03<00:00, 29.3MB/s] 96%|█████████▌| 93.9M/97.8M [00:03<00:00, 36.5MB/s] 59%|█████▉    | 57.9M/97.8M [00:03<00:01, 25.6MB/s] 92%|█████████▏| 90.1M/97.8M [00:03<00:00, 31.5MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 31.4MB/s]
 63%|██████▎   | 61.6M/97.8M [00:03<00:01, 28.4MB/s] 96%|█████████▋| 94.2M/97.8M [00:03<00:00, 34.3MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 30.1MB/s]
 67%|██████▋   | 65.6M/97.8M [00:03<00:01, 31.6MB/s] 72%|███████▏  | 70.6M/97.8M [00:03<00:00, 35.7MB/s] 78%|███████▊  | 76.5M/97.8M [00:03<00:00, 40.9MB/s] 85%|████████▍ | 82.7M/97.8M [00:03<00:00, 46.0MB/s]DLL 2021-06-26 18:41:42.032374 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 256  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2021-06-26 18:41:42.076945 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 256  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
 93%|█████████▎| 90.6M/97.8M [00:03<00:00, 53.1MB/s]100%|██████████| 97.8M/97.8M [00:03<00:00, 26.7MB/s]
DLL 2021-06-26 18:41:42.199460 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 256  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
DLL 2021-06-26 18:41:42.668615 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 256  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
Using seed = 302
Using seed = 7905
Using seed = 2690
Using seed = 6422
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
loading annotations into memory...
Done (t=0.36s)
creating index...
Done (t=0.36s)
creating index...
Done (t=0.36s)
creating index...
Done (t=0.37s)
creating index...
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `Uniform` is now deprecated. Use `random.Uniform` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:532: DeprecationWarning: WARNING: `CoinFlip` is now deprecated. Use `random.CoinFlip` instead
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:163: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
DLL 2021-06-26 18:43:18.005495 - () avg_img/sec : 174.89316759877224  med_img/sec : 174.9185246557255  min_img/sec : 174.6928350255822  max_img/sec : 175.06053170547673 
Done benchmarking. Total images: 5120	total time: 29.275	Average images/sec: 174.893	Median images/sec: 174.919
DLL 2021-06-26 18:43:18.005764 - () avg_img/sec : 174.98449882208257  med_img/sec : 175.0095001341129  min_img/sec : 174.76673431689574  max_img/sec : 175.11731914096208 
Done benchmarking. Total images: 5120	total time: 29.260	Average images/sec: 174.984	Median images/sec: 175.010
DLL 2021-06-26 18:43:18.005949 - () avg_img/sec : 174.99436473110887  med_img/sec : 175.01392174571453  min_img/sec : 174.79046130870745  max_img/sec : 175.1770584909028 WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...

Done benchmarking. Total images: 5120	total time: 29.258	Average images/sec: 174.994	Median images/sec: 175.014
DLL 2021-06-26 18:43:18.006079 - () total time : 77.61657047271729 
DLL 2021-06-26 18:43:18.006104 - () 
DLL 2021-06-26 18:43:18.006017 - () avg_img/sec : 175.02082380610378  med_img/sec : 175.0238350475745  min_img/sec : 174.7974611482722  max_img/sec : 175.15125500602002 
Done benchmarking. Total images: 5120	total time: 29.254	Average images/sec: 175.021	Median images/sec: 175.024
Training performance = 699.9658203125 FPS
DLL 2021-06-26 18:43:18.006479 - (0,) time : 77.61781907081604 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-06-26 18:43:18.006720 - () total time : 77.61714935302734 
DLL 2021-06-26 18:43:18.006739 - () total time : 77.61781907081604 
DLL 2021-06-26 18:43:18.006752 - () 
DLL 2021-06-26 18:43:18.006761 - () 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2021-06-26 18:43:18.006805 - () total time : 77.61724138259888 
DLL 2021-06-26 18:43:18.006840 - () 
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
