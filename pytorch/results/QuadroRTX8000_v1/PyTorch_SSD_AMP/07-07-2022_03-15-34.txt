The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run
WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.
 Please read local_rank from `os.environ('LOCAL_RANK')` instead.
INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:
  entrypoint       : main.py
  min_nodes        : 1
  max_nodes        : 1
  nproc_per_node   : 1
  run_id           : none
  rdzv_backend     : static
  rdzv_endpoint    : 127.0.0.1:29500
  rdzv_configs     : {'rank': 0, 'timeout': 900}
  max_restarts     : 3
  monitor_interval : 5
  log_dir          : None
  metrics_cfg      : {}

INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_9kop8ul7/none_4eanq5he
INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:52: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:
  restart_count=0
  master_addr=127.0.0.1
  master_port=29500
  group_rank=0
  group_world_size=1
  local_ranks=[0]
  role_ranks=[0]
  global_ranks=[0]
  role_world_sizes=[1]
  global_world_sizes=[1]

INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group
INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_9kop8ul7/none_4eanq5he/attempt_0/0/error.json
Downloading: "https://download.pytorch.org/models/resnet50-0676ba61.pth" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 240k/97.8M [00:00<00:42, 2.42MB/s]  2%|▏         | 1.98M/97.8M [00:00<00:30, 3.27MB/s]  4%|▎         | 3.56M/97.8M [00:00<00:23, 4.18MB/s]  5%|▌         | 4.94M/97.8M [00:00<00:18, 5.28MB/s]  6%|▌         | 5.85M/97.8M [00:00<00:16, 5.92MB/s]  7%|▋         | 6.73M/97.8M [00:00<00:16, 5.73MB/s]  8%|▊         | 7.49M/97.8M [00:00<00:20, 4.72MB/s]  9%|▊         | 8.50M/97.8M [00:01<00:16, 5.53MB/s] 10%|▉         | 9.31M/97.8M [00:01<00:15, 6.15MB/s] 10%|█         | 10.1M/97.8M [00:01<00:14, 6.19MB/s] 12%|█▏        | 11.6M/97.8M [00:01<00:11, 7.55MB/s] 14%|█▎        | 13.4M/97.8M [00:01<00:09, 8.93MB/s] 15%|█▌        | 15.1M/97.8M [00:01<00:08, 10.5MB/s] 17%|█▋        | 16.5M/97.8M [00:01<00:07, 11.2MB/s] 18%|█▊        | 17.8M/97.8M [00:01<00:09, 9.24MB/s] 19%|█▉        | 18.9M/97.8M [00:02<00:11, 7.47MB/s] 20%|██        | 20.0M/97.8M [00:02<00:09, 8.33MB/s] 22%|██▏       | 21.2M/97.8M [00:02<00:10, 7.66MB/s] 23%|██▎       | 22.1M/97.8M [00:02<00:12, 6.11MB/s] 23%|██▎       | 22.8M/97.8M [00:02<00:16, 4.76MB/s] 24%|██▍       | 23.6M/97.8M [00:03<00:14, 5.32MB/s] 25%|██▌       | 24.8M/97.8M [00:03<00:12, 6.37MB/s] 26%|██▋       | 25.7M/97.8M [00:03<00:10, 7.05MB/s] 27%|██▋       | 26.9M/97.8M [00:03<00:09, 7.91MB/s] 29%|██▊       | 27.9M/97.8M [00:03<00:08, 8.64MB/s] 30%|██▉       | 28.9M/97.8M [00:03<00:09, 7.70MB/s] 31%|███       | 29.9M/97.8M [00:03<00:08, 8.34MB/s] 32%|███▏      | 30.8M/97.8M [00:03<00:08, 8.36MB/s] 32%|███▏      | 31.7M/97.8M [00:03<00:08, 7.95MB/s] 33%|███▎      | 32.6M/97.8M [00:04<00:08, 8.50MB/s] 34%|███▍      | 33.6M/97.8M [00:04<00:08, 8.32MB/s] 35%|███▌      | 34.6M/97.8M [00:04<00:07, 8.80MB/s] 36%|███▋      | 35.5M/97.8M [00:04<00:07, 8.77MB/s] 37%|███▋      | 36.6M/97.8M [00:04<00:07, 8.82MB/s] 38%|███▊      | 37.4M/97.8M [00:04<00:07, 8.21MB/s] 39%|███▉      | 38.2M/97.8M [00:04<00:07, 8.21MB/s] 40%|████      | 39.1M/97.8M [00:04<00:07, 8.43MB/s] 41%|████      | 39.9M/97.8M [00:04<00:07, 8.45MB/s] 42%|████▏     | 40.8M/97.8M [00:05<00:07, 7.74MB/s] 43%|████▎     | 41.8M/97.8M [00:05<00:07, 7.42MB/s] 44%|████▎     | 42.7M/97.8M [00:05<00:07, 7.65MB/s] 44%|████▍     | 43.4M/97.8M [00:05<00:07, 7.41MB/s] 46%|████▌     | 44.5M/97.8M [00:05<00:07, 7.50MB/s] 46%|████▋     | 45.3M/97.8M [00:05<00:07, 7.09MB/s] 47%|████▋     | 46.4M/97.8M [00:05<00:06, 8.04MB/s] 48%|████▊     | 47.4M/97.8M [00:05<00:06, 8.41MB/s] 50%|████▉     | 48.5M/97.8M [00:06<00:05, 9.20MB/s] 51%|█████     | 49.4M/97.8M [00:06<00:08, 6.00MB/s] 52%|█████▏    | 50.5M/97.8M [00:06<00:07, 6.98MB/s] 53%|█████▎    | 51.3M/97.8M [00:06<00:07, 6.25MB/s] 54%|█████▍    | 52.7M/97.8M [00:06<00:06, 7.44MB/s] 55%|█████▍    | 53.6M/97.8M [00:06<00:05, 7.88MB/s] 56%|█████▌    | 54.5M/97.8M [00:06<00:05, 8.28MB/s] 57%|█████▋    | 55.4M/97.8M [00:07<00:06, 6.77MB/s] 58%|█████▊    | 56.3M/97.8M [00:07<00:05, 7.30MB/s] 59%|█████▊    | 57.4M/97.8M [00:07<00:05, 8.10MB/s] 60%|█████▉    | 58.2M/97.8M [00:07<00:04, 8.36MB/s] 61%|██████    | 59.3M/97.8M [00:07<00:04, 8.71MB/s] 62%|██████▏   | 60.3M/97.8M [00:07<00:04, 9.24MB/s] 63%|██████▎   | 61.3M/97.8M [00:07<00:04, 9.53MB/s] 64%|██████▍   | 62.9M/97.8M [00:07<00:03, 10.8MB/s] 66%|██████▌   | 64.3M/97.8M [00:08<00:03, 11.1MB/s] 67%|██████▋   | 65.4M/97.8M [00:08<00:03, 8.76MB/s] 68%|██████▊   | 66.4M/97.8M [00:08<00:03, 8.96MB/s] 69%|██████▉   | 67.6M/97.8M [00:08<00:03, 9.51MB/s] 70%|███████   | 68.8M/97.8M [00:08<00:02, 10.3MB/s] 71%|███████▏  | 69.9M/97.8M [00:08<00:03, 8.74MB/s] 72%|███████▏  | 70.8M/97.8M [00:09<00:05, 4.72MB/s] 73%|███████▎  | 71.5M/97.8M [00:09<00:05, 4.91MB/s] 74%|███████▍  | 72.1M/97.8M [00:09<00:05, 5.15MB/s] 74%|███████▍  | 72.8M/97.8M [00:09<00:04, 5.34MB/s] 75%|███████▌  | 73.4M/97.8M [00:09<00:07, 3.55MB/s] 76%|███████▌  | 74.2M/97.8M [00:09<00:06, 3.91MB/s] 76%|███████▋  | 74.7M/97.8M [00:10<00:05, 4.26MB/s] 77%|███████▋  | 75.2M/97.8M [00:10<00:07, 3.18MB/s] 79%|███████▊  | 76.9M/97.8M [00:10<00:05, 3.76MB/s] 80%|███████▉  | 78.0M/97.8M [00:10<00:04, 4.74MB/s] 81%|████████  | 79.1M/97.8M [00:10<00:03, 5.72MB/s] 82%|████████▏ | 80.6M/97.8M [00:10<00:02, 7.07MB/s] 83%|████████▎ | 81.6M/97.8M [00:11<00:02, 7.30MB/s] 85%|████████▍ | 82.7M/97.8M [00:11<00:01, 8.05MB/s] 86%|████████▌ | 83.6M/97.8M [00:11<00:01, 8.50MB/s] 87%|████████▋ | 84.7M/97.8M [00:11<00:01, 8.49MB/s] 88%|████████▊ | 85.7M/97.8M [00:11<00:01, 8.97MB/s] 89%|████████▉ | 86.9M/97.8M [00:11<00:01, 9.09MB/s] 90%|█████████ | 88.1M/97.8M [00:11<00:01, 9.98MB/s] 91%|█████████ | 89.1M/97.8M [00:11<00:01, 8.68MB/s] 92%|█████████▏| 90.2M/97.8M [00:11<00:00, 9.27MB/s] 93%|█████████▎| 91.2M/97.8M [00:12<00:00, 8.76MB/s] 94%|█████████▍| 92.1M/97.8M [00:12<00:00, 8.80MB/s] 95%|█████████▌| 93.0M/97.8M [00:12<00:00, 8.60MB/s] 96%|█████████▋| 94.2M/97.8M [00:12<00:00, 9.42MB/s] 97%|█████████▋| 95.1M/97.8M [00:12<00:00, 9.02MB/s] 99%|█████████▊| 96.4M/97.8M [00:12<00:00, 8.57MB/s]100%|█████████▉| 97.6M/97.8M [00:12<00:00, 9.53MB/s]100%|██████████| 97.8M/97.8M [00:12<00:00, 7.95MB/s]
NOTE! Installing ujson may make loading annotations faster.
DLL 2022-07-07 03:15:49.704076 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 256  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : True  precision : amp 
Using seed = 9497
loading annotations into memory...
Done (t=0.62s)
creating index...
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `uniform` is now deprecated. Use `random.uniform` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coin_flip` is now deprecated. Use `random.coin_flip` instead.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `coco_reader` is now deprecated. Use `readers.coco` instead.
In DALI 1.0 all readers were moved into a dedicated :mod:`~nvidia.dali.fn.readers`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/ops.py:627: DeprecationWarning: WARNING: `image_decoder_slice` is now deprecated. Use `decoders.image_slice` instead.
In DALI 1.0 all decoders were moved into a dedicated :mod:`~nvidia.dali.fn.decoders`
submodule and renamed to follow a common pattern. This is a placeholder operator with identical
functionality to allow for backward compatibility.
  op_instances.append(_OperatorInstance(input_set, self, **kwargs))
/opt/conda/lib/python3.8/site-packages/nvidia/dali/pipeline.py:199: Warning: batch_size is deprecated, please use max_batch_size instead
  _show_deprecation_warning("batch_size", "max_batch_size")
/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
/opt/conda/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Seems like `optimizer.step()` has been overridden after learning rate scheduler initialization. Please, make sure to call `optimizer.step()` before `lr_scheduler.step()`. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Seems like `optimizer.step()` has been overridden after learning rate scheduler "
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
DLL 2022-07-07 03:17:52.694561 - () avg_img/sec : 156.25979072365257  med_img/sec : 156.0628540304898  min_img/sec : 155.17222390984088  max_img/sec : 157.81474032498252 
Done benchmarking. Total images: 10240	total time: 65.532	Average images/sec: 156.260	Median images/sec: 156.063
Training performance = 156.06285095214844 FPS
DLL 2022-07-07 03:17:52.694974 - (0,) time : 112.86440110206604 
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
DLL 2022-07-07 03:17:52.695196 - () total time : 112.86440110206604 
DLL 2022-07-07 03:17:52.695218 - () 
INFO:torch.distributed.elastic.agent.server.api:[default] worker group successfully finished. Waiting 300 seconds for other agents to finish.
INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (SUCCEEDED). Waiting 300 seconds for other agents to finish
/opt/conda/lib/python3.8/site-packages/torch/distributed/elastic/utils/store.py:70: FutureWarning: This is an experimental API and will be changed in future.
  warnings.warn(
INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.0005068778991699219 seconds
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "WORKER", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": 0, "group_rank": 0, "worker_id": "775", "role": "default", "hostname": "70188eb6454c", "state": "SUCCEEDED", "total_run_time": 140, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\", \"local_rank\": [0], \"role_rank\": [0], \"role_world_size\": [1]}", "agent_restarts": 0}}
{"name": "torchelastic.worker.status.SUCCEEDED", "source": "AGENT", "timestamp": 0, "metadata": {"run_id": "none", "global_rank": null, "group_rank": 0, "worker_id": null, "role": "default", "hostname": "70188eb6454c", "state": "SUCCEEDED", "total_run_time": 140, "rdzv_backend": "static", "raw_error": null, "metadata": "{\"group_world_size\": 1, \"entry_point\": \"python\"}", "agent_restarts": 0}}
DONE!
