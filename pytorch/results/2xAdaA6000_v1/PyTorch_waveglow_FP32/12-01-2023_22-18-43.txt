OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
DLL 2023-01-12 22:18:53.876024 - PARAMETER output : ./ 
DLL 2023-01-12 22:18:53.876073 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2023-01-12 22:18:53.876091 - PARAMETER model_name : WaveGlow 
DLL 2023-01-12 22:18:53.876106 - PARAMETER log_file : nvlog.json 
DLL 2023-01-12 22:18:53.876119 - PARAMETER anneal_steps : None 
DLL 2023-01-12 22:18:53.876133 - PARAMETER anneal_factor : 0.1 
DLL 2023-01-12 22:18:53.876146 - PARAMETER config_file : None 
DLL 2023-01-12 22:18:53.876159 - PARAMETER seed : None 
DLL 2023-01-12 22:18:53.876171 - PARAMETER epochs : 1 
DLL 2023-01-12 22:18:53.876183 - PARAMETER epochs_per_checkpoint : 50 
DLL 2023-01-12 22:18:53.876194 - PARAMETER checkpoint_path :  
DLL 2023-01-12 22:18:53.876206 - PARAMETER resume_from_last : False 
DLL 2023-01-12 22:18:53.876219 - PARAMETER dynamic_loss_scaling : True 
DLL 2023-01-12 22:18:53.876231 - PARAMETER amp : False 
DLL 2023-01-12 22:18:53.876243 - PARAMETER cudnn_enabled : True 
DLL 2023-01-12 22:18:53.876253 - PARAMETER cudnn_benchmark : True 
DLL 2023-01-12 22:18:53.876264 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2023-01-12 22:18:53.876275 - PARAMETER use_saved_learning_rate : False 
DLL 2023-01-12 22:18:53.876287 - PARAMETER learning_rate : 0.0 
DLL 2023-01-12 22:18:53.876299 - PARAMETER weight_decay : 0.0 
DLL 2023-01-12 22:18:53.876311 - PARAMETER grad_clip_thresh : 65504.0 
DLL 2023-01-12 22:18:53.876323 - PARAMETER batch_size : 32 
DLL 2023-01-12 22:18:53.876334 - PARAMETER grad_clip : 5.0 
DLL 2023-01-12 22:18:53.876346 - PARAMETER load_mel_from_disk : False 
DLL 2023-01-12 22:18:53.876357 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2023-01-12 22:18:53.876368 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2023-01-12 22:18:53.876379 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2023-01-12 22:18:53.876393 - PARAMETER max_wav_value : 32768.0 
DLL 2023-01-12 22:18:53.876404 - PARAMETER sampling_rate : 22050 
DLL 2023-01-12 22:18:53.876416 - PARAMETER filter_length : 1024 
DLL 2023-01-12 22:18:53.876427 - PARAMETER hop_length : 256 
DLL 2023-01-12 22:18:53.876438 - PARAMETER win_length : 1024 
DLL 2023-01-12 22:18:53.876449 - PARAMETER mel_fmin : 0.0 
DLL 2023-01-12 22:18:53.876460 - PARAMETER mel_fmax : 8000.0 
DLL 2023-01-12 22:18:53.876471 - PARAMETER rank : 0 
DLL 2023-01-12 22:18:53.876481 - PARAMETER world_size : 2 
DLL 2023-01-12 22:18:53.876492 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2023-01-12 22:18:53.876503 - PARAMETER group_name : group_name 
DLL 2023-01-12 22:18:53.876515 - PARAMETER dist_backend : nccl 
DLL 2023-01-12 22:18:53.876526 - PARAMETER bench_class :  
DLL 2023-01-12 22:18:53.876537 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
DLL 2023-01-12 22:19:00.592971 - (0, 0) glob_iter/iters_per_epoch : 0/9 
DLL 2023-01-12 22:19:03.562410 - (0, 0) train_loss : 0.0021692144218832254 
DLL 2023-01-12 22:19:06.214536 - (0, 0) train_items_per_sec : 91077.10687362756 items/s
DLL 2023-01-12 22:19:06.214596 - (0, 0) train_iter_time : 5.6216102769976715 
DLL 2023-01-12 22:19:06.215845 - (0, 1) glob_iter/iters_per_epoch : 1/9 
DLL 2023-01-12 22:19:06.686691 - (0, 1) train_loss : 0.002299873623996973 
DLL 2023-01-12 22:19:07.885740 - (0, 1) train_items_per_sec : 306604.5688393051 items/s
DLL 2023-01-12 22:19:07.885781 - (0, 1) train_iter_time : 1.6699033609911567 
DLL 2023-01-12 22:19:07.886847 - (0, 2) glob_iter/iters_per_epoch : 2/9 
DLL 2023-01-12 22:19:08.362526 - (0, 2) train_loss : 0.0021567121148109436 
DLL 2023-01-12 22:19:09.563611 - (0, 2) train_items_per_sec : 305349.0282359509 items/s
DLL 2023-01-12 22:19:09.563651 - (0, 2) train_iter_time : 1.6767697050090646 
DLL 2023-01-12 22:19:09.564699 - (0, 3) glob_iter/iters_per_epoch : 3/9 
DLL 2023-01-12 22:19:10.043314 - (0, 3) train_loss : 0.0025904434733092785 
DLL 2023-01-12 22:19:11.244555 - (0, 3) train_items_per_sec : 304787.3682941099 items/s
DLL 2023-01-12 22:19:11.244594 - (0, 3) train_iter_time : 1.6798596440057736 
DLL 2023-01-12 22:19:11.245621 - (0, 4) glob_iter/iters_per_epoch : 4/9 
DLL 2023-01-12 22:19:11.726817 - (0, 4) train_loss : 0.00232609617523849 
DLL 2023-01-12 22:19:12.930546 - (0, 4) train_items_per_sec : 303870.6418592721 items/s
DLL 2023-01-12 22:19:12.930587 - (0, 4) train_iter_time : 1.6849274970008992 
DLL 2023-01-12 22:19:12.931630 - (0, 5) glob_iter/iters_per_epoch : 5/9 
DLL 2023-01-12 22:19:13.414170 - (0, 5) train_loss : 0.0019212919287383556 
DLL 2023-01-12 22:19:14.617699 - (0, 5) train_items_per_sec : 303663.9021830518 items/s
DLL 2023-01-12 22:19:14.617743 - (0, 5) train_iter_time : 1.6860746250022203 
DLL 2023-01-12 22:19:14.618780 - (0, 6) glob_iter/iters_per_epoch : 6/9 
DLL 2023-01-12 22:19:15.103320 - (0, 6) train_loss : 0.002304542576894164 
DLL 2023-01-12 22:19:16.307744 - (0, 6) train_items_per_sec : 303143.69305324537 items/s
DLL 2023-01-12 22:19:16.307788 - (0, 6) train_iter_time : 1.6889680099993711 
DLL 2023-01-12 22:19:16.308843 - (0, 7) glob_iter/iters_per_epoch : 7/9 
DLL 2023-01-12 22:19:16.795699 - (0, 7) train_loss : 0.0015526365023106337 
DLL 2023-01-12 22:19:18.001102 - (0, 7) train_items_per_sec : 302553.5112155253 items/s
DLL 2023-01-12 22:19:18.001142 - (0, 7) train_iter_time : 1.6922626279992983 
DLL 2023-01-12 22:19:18.002199 - (0, 8) glob_iter/iters_per_epoch : 8/9 
DLL 2023-01-12 22:19:18.483434 - (0, 8) train_loss : 0.0022078529000282288 
DLL 2023-01-12 22:19:19.690851 - (0, 8) train_items_per_sec : 303199.6086812249 items/s
DLL 2023-01-12 22:19:19.690894 - (0, 8) train_iter_time : 1.6886565329914447 
DLL 2023-01-12 22:19:19.756522 - (0,) train_items_per_sec : 280472.15880392364 items/s
DLL 2023-01-12 22:19:19.756599 - (0,) train_loss : 0.0022078529000282288 
DLL 2023-01-12 22:19:19.756644 - (0,) train_epoch_time : 19.41808774799574 
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
DLL 2023-01-12 22:19:20.547404 - (0, 9, 0) val_items_per_sec : 787978.0867426482 items/s
DLL 2023-01-12 22:19:22.306219 - (0, 9, 1) val_items_per_sec : 163879.62785908158 items/s
DLL 2023-01-12 22:19:22.338792 - (0,) val_loss : 0.002052533207461238 None
DLL 2023-01-12 22:19:22.338853 - (0,) val_items_per_sec : 475928.8573008649 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0.pt
Updating symlink ./checkpoint_WaveGlow_last.pt to point to checkpoint_WaveGlow_0.pt
DLL 2023-01-12 22:19:25.583132 - () run_time : 31.55567325699667 s
DLL 2023-01-12 22:19:25.583202 - () val_loss : 0.002052533207461238 None
DLL 2023-01-12 22:19:25.583224 - () train_loss : 0.0022078529000282288 
DLL 2023-01-12 22:19:25.583241 - () train_items_per_sec : 280472.15880392364 items/s
DLL 2023-01-12 22:19:25.583257 - () val_items_per_sec : 475928.8573008649 items/s
DONE!
