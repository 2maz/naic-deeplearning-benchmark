OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.
DLL 2023-01-12 22:09:05.658288 - PARAMETER output : ./ 
DLL 2023-01-12 22:09:05.658337 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2023-01-12 22:09:05.658355 - PARAMETER model_name : WaveGlow 
DLL 2023-01-12 22:09:05.658369 - PARAMETER log_file : nvlog.json 
DLL 2023-01-12 22:09:05.658381 - PARAMETER anneal_steps : None 
DLL 2023-01-12 22:09:05.658394 - PARAMETER anneal_factor : 0.1 
DLL 2023-01-12 22:09:05.658407 - PARAMETER config_file : None 
DLL 2023-01-12 22:09:05.658419 - PARAMETER seed : None 
DLL 2023-01-12 22:09:05.658431 - PARAMETER epochs : 1 
DLL 2023-01-12 22:09:05.658442 - PARAMETER epochs_per_checkpoint : 50 
DLL 2023-01-12 22:09:05.658454 - PARAMETER checkpoint_path :  
DLL 2023-01-12 22:09:05.658466 - PARAMETER resume_from_last : False 
DLL 2023-01-12 22:09:05.658478 - PARAMETER dynamic_loss_scaling : True 
DLL 2023-01-12 22:09:05.658490 - PARAMETER amp : False 
DLL 2023-01-12 22:09:05.658501 - PARAMETER cudnn_enabled : True 
DLL 2023-01-12 22:09:05.658512 - PARAMETER cudnn_benchmark : True 
DLL 2023-01-12 22:09:05.658523 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2023-01-12 22:09:05.658533 - PARAMETER use_saved_learning_rate : False 
DLL 2023-01-12 22:09:05.658544 - PARAMETER learning_rate : 0.0 
DLL 2023-01-12 22:09:05.658556 - PARAMETER weight_decay : 0.0 
DLL 2023-01-12 22:09:05.658567 - PARAMETER grad_clip_thresh : 65504.0 
DLL 2023-01-12 22:09:05.658578 - PARAMETER batch_size : 32 
DLL 2023-01-12 22:09:05.658589 - PARAMETER grad_clip : 5.0 
DLL 2023-01-12 22:09:05.658600 - PARAMETER load_mel_from_disk : False 
DLL 2023-01-12 22:09:05.658611 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2023-01-12 22:09:05.658622 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2023-01-12 22:09:05.658633 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2023-01-12 22:09:05.658646 - PARAMETER max_wav_value : 32768.0 
DLL 2023-01-12 22:09:05.658658 - PARAMETER sampling_rate : 22050 
DLL 2023-01-12 22:09:05.658669 - PARAMETER filter_length : 1024 
DLL 2023-01-12 22:09:05.658679 - PARAMETER hop_length : 256 
DLL 2023-01-12 22:09:05.658690 - PARAMETER win_length : 1024 
DLL 2023-01-12 22:09:05.658701 - PARAMETER mel_fmin : 0.0 
DLL 2023-01-12 22:09:05.658712 - PARAMETER mel_fmax : 8000.0 
DLL 2023-01-12 22:09:05.658723 - PARAMETER rank : 0 
DLL 2023-01-12 22:09:05.658734 - PARAMETER world_size : 2 
DLL 2023-01-12 22:09:05.658745 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2023-01-12 22:09:05.658755 - PARAMETER group_name : group_name 
DLL 2023-01-12 22:09:05.658767 - PARAMETER dist_backend : nccl 
DLL 2023-01-12 22:09:05.658778 - PARAMETER bench_class :  
DLL 2023-01-12 22:09:05.658789 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
DLL 2023-01-12 22:09:12.550336 - (0, 0) glob_iter/iters_per_epoch : 0/9 
DLL 2023-01-12 22:09:17.773189 - (0, 0) train_loss : 0.0018864198355004191 
DLL 2023-01-12 22:09:22.767094 - (0, 0) train_items_per_sec : 50113.547976846436 items/s
DLL 2023-01-12 22:09:22.767155 - (0, 0) train_iter_time : 10.21679806499742 
DLL 2023-01-12 22:09:22.768373 - (0, 1) glob_iter/iters_per_epoch : 1/9 
DLL 2023-01-12 22:09:23.393551 - (0, 1) train_loss : 0.0018738169455900788 
DLL 2023-01-12 22:09:24.769072 - (0, 1) train_items_per_sec : 255909.86419699146 items/s
DLL 2023-01-12 22:09:24.769119 - (0, 1) train_iter_time : 2.0007044339872664 
DLL 2023-01-12 22:09:24.770195 - (0, 2) glob_iter/iters_per_epoch : 2/9 
DLL 2023-01-12 22:09:25.249655 - (0, 2) train_loss : 0.0018178164027631283 
DLL 2023-01-12 22:09:26.456623 - (0, 2) train_items_per_sec : 303599.3700055769 items/s
DLL 2023-01-12 22:09:26.456666 - (0, 2) train_iter_time : 1.6864330120006343 
DLL 2023-01-12 22:09:26.457778 - (0, 3) glob_iter/iters_per_epoch : 3/9 
DLL 2023-01-12 22:09:26.934642 - (0, 3) train_loss : 0.0026260227896273136 
DLL 2023-01-12 22:09:28.234575 - (0, 3) train_items_per_sec : 288158.42699849175 items/s
DLL 2023-01-12 22:09:28.234613 - (0, 3) train_iter_time : 1.7768003710079938 
DLL 2023-01-12 22:09:28.235975 - (0, 4) glob_iter/iters_per_epoch : 4/9 
DLL 2023-01-12 22:09:28.713723 - (0, 4) train_loss : 0.0024943510070443153 
DLL 2023-01-12 22:09:29.919049 - (0, 4) train_items_per_sec : 304204.4105247294 items/s
DLL 2023-01-12 22:09:29.919087 - (0, 4) train_iter_time : 1.6830788189981831 
DLL 2023-01-12 22:09:29.920143 - (0, 5) glob_iter/iters_per_epoch : 5/9 
DLL 2023-01-12 22:09:30.399394 - (0, 5) train_loss : 0.0022164983674883842 
DLL 2023-01-12 22:09:31.607228 - (0, 5) train_items_per_sec : 303481.89166621614 items/s
DLL 2023-01-12 22:09:31.607277 - (0, 5) train_iter_time : 1.6870858329930343 
DLL 2023-01-12 22:09:31.608385 - (0, 6) glob_iter/iters_per_epoch : 6/9 
DLL 2023-01-12 22:09:32.093019 - (0, 6) train_loss : 0.0023194942623376846 
DLL 2023-01-12 22:09:33.300316 - (0, 6) train_items_per_sec : 302611.86708048603 items/s
DLL 2023-01-12 22:09:33.300355 - (0, 6) train_iter_time : 1.6919362909975462 
DLL 2023-01-12 22:09:33.301431 - (0, 7) glob_iter/iters_per_epoch : 7/9 
DLL 2023-01-12 22:09:33.779473 - (0, 7) train_loss : 0.002170068211853504 
DLL 2023-01-12 22:09:34.988385 - (0, 7) train_items_per_sec : 303504.8185159478 items/s
DLL 2023-01-12 22:09:34.988426 - (0, 7) train_iter_time : 1.6869583899970166 
DLL 2023-01-12 22:09:34.989478 - (0, 8) glob_iter/iters_per_epoch : 8/9 
DLL 2023-01-12 22:09:35.477021 - (0, 8) train_loss : 0.002060765866190195 
DLL 2023-01-12 22:09:36.685715 - (0, 8) train_items_per_sec : 301844.072618199 items/s
DLL 2023-01-12 22:09:36.685755 - (0, 8) train_iter_time : 1.6962400339980377 
DLL 2023-01-12 22:09:36.746720 - (0,) train_items_per_sec : 268158.6966203872 items/s
DLL 2023-01-12 22:09:36.746798 - (0,) train_loss : 0.002060765866190195 
DLL 2023-01-12 22:09:36.746843 - (0,) train_epoch_time : 24.500602571002673 
/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/scatter_gather.py:9: UserWarning: is_namedtuple is deprecated, please use the python checks instead
  warnings.warn("is_namedtuple is deprecated, please use the python checks instead")
DLL 2023-01-12 22:09:37.532542 - (0, 9, 0) val_items_per_sec : 795528.9001211389 items/s
DLL 2023-01-12 22:09:39.301940 - (0, 9, 1) val_items_per_sec : 162892.01404808415 items/s
DLL 2023-01-12 22:09:39.331121 - (0,) val_loss : 0.002166449325159192 None
DLL 2023-01-12 22:09:39.331178 - (0,) val_items_per_sec : 479210.4570846115 items/s
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0.pt
DLL 2023-01-12 22:09:41.502937 - () run_time : 35.48789968100027 s
DLL 2023-01-12 22:09:41.503003 - () val_loss : 0.002166449325159192 None
DLL 2023-01-12 22:09:41.503024 - () train_loss : 0.002060765866190195 
DLL 2023-01-12 22:09:41.503042 - () train_items_per_sec : 268158.6966203872 items/s
DLL 2023-01-12 22:09:41.503058 - () val_items_per_sec : 479210.4570846115 items/s
DONE!
