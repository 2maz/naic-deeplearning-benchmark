train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2022-07-01 03:05:06.887170 - PARAMETER output : ./ 
DLL 2022-07-01 03:05:06.887237 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2022-07-01 03:05:06.887263 - PARAMETER model_name : Tacotron2 
DLL 2022-07-01 03:05:06.887282 - PARAMETER log_file : nvlog.json 
DLL 2022-07-01 03:05:06.887298 - PARAMETER anneal_steps : None 
DLL 2022-07-01 03:05:06.887316 - PARAMETER anneal_factor : 0.1 
DLL 2022-07-01 03:05:06.887333 - PARAMETER epochs : 2 
DLL 2022-07-01 03:05:06.887349 - PARAMETER epochs_per_checkpoint : 50 
DLL 2022-07-01 03:05:06.887365 - PARAMETER checkpoint_path :  
DLL 2022-07-01 03:05:06.887379 - PARAMETER resume_from_last : False 
DLL 2022-07-01 03:05:06.887395 - PARAMETER dynamic_loss_scaling : True 
DLL 2022-07-01 03:05:06.887410 - PARAMETER amp : False 
DLL 2022-07-01 03:05:06.887427 - PARAMETER cudnn_enabled : True 
DLL 2022-07-01 03:05:06.887442 - PARAMETER cudnn_benchmark : False 
DLL 2022-07-01 03:05:06.887457 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2022-07-01 03:05:06.887471 - PARAMETER use_saved_learning_rate : False 
DLL 2022-07-01 03:05:06.887486 - PARAMETER learning_rate : 0.0 
DLL 2022-07-01 03:05:06.887501 - PARAMETER weight_decay : 1e-06 
DLL 2022-07-01 03:05:06.887519 - PARAMETER grad_clip_thresh : 1.0 
DLL 2022-07-01 03:05:06.887537 - PARAMETER batch_size : 64 
DLL 2022-07-01 03:05:06.887551 - PARAMETER grad_clip : 5.0 
DLL 2022-07-01 03:05:06.887566 - PARAMETER load_mel_from_disk : False 
DLL 2022-07-01 03:05:06.887583 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2022-07-01 03:05:06.887598 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2022-07-01 03:05:06.887613 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2022-07-01 03:05:06.887630 - PARAMETER max_wav_value : 32768.0 
DLL 2022-07-01 03:05:06.887646 - PARAMETER sampling_rate : 22050 
DLL 2022-07-01 03:05:06.887660 - PARAMETER filter_length : 1024 
DLL 2022-07-01 03:05:06.887674 - PARAMETER hop_length : 256 
DLL 2022-07-01 03:05:06.887688 - PARAMETER win_length : 1024 
DLL 2022-07-01 03:05:06.887702 - PARAMETER mel_fmin : 0.0 
DLL 2022-07-01 03:05:06.887717 - PARAMETER mel_fmax : 8000.0 
DLL 2022-07-01 03:05:06.887732 - PARAMETER rank : 0 
DLL 2022-07-01 03:05:06.887746 - PARAMETER world_size : 8 
DLL 2022-07-01 03:05:06.887760 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2022-07-01 03:05:06.887774 - PARAMETER group_name : group_name 
DLL 2022-07-01 03:05:06.887790 - PARAMETER dist_backend : nccl 
DLL 2022-07-01 03:05:06.887804 - PARAMETER bench_class :  
DLL 2022-07-01 03:05:06.887819 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 03:05:33.119369 - (0, 0) glob_iter/iters_per_epoch : 0/2 
DLL 2022-07-01 03:05:49.895402 - (0, 0) train_loss : 47.19660186767578 
DLL 2022-07-01 03:05:51.699806 - (0, 0) train_items_per_sec : 15678.336469429427 
DLL 2022-07-01 03:05:51.699917 - (0, 0) train_iter_time : 18.580542684998363 
DLL 2022-07-01 03:05:51.705825 - (0, 1) glob_iter/iters_per_epoch : 1/2 
DLL 2022-07-01 03:05:52.485805 - (0, 1) train_loss : 47.17045593261719 
DLL 2022-07-01 03:05:53.907914 - (0, 1) train_items_per_sec : 130871.22047108493 
DLL 2022-07-01 03:05:53.908037 - (0, 1) train_iter_time : 2.2021037089944 
DLL 2022-07-01 03:05:53.982053 - (0,) train_items_per_sec : 73274.77847025718 
DLL 2022-07-01 03:05:53.982205 - (0,) train_loss : 47.17045593261719 
DLL 2022-07-01 03:05:53.982235 - (0,) train_epoch_time : 22.498725557001308 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 03:05:55.046643 - (0, 2, 0) val_items_per_sec : 106709.99585248198 
DLL 2022-07-01 03:05:55.146693 - (0,) val_loss : 48.17047119140625 
DLL 2022-07-01 03:05:55.146739 - (0,) val_items_per_sec : 106709.99585248198 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2022-07-01 03:05:57.158429 - (1, 0) glob_iter/iters_per_epoch : 2/2 
DLL 2022-07-01 03:05:57.909987 - (1, 0) train_loss : 46.488182067871094 
DLL 2022-07-01 03:05:59.319504 - (1, 0) train_items_per_sec : 130924.19427762434 
DLL 2022-07-01 03:05:59.319614 - (1, 0) train_iter_time : 2.161120803997619 
DLL 2022-07-01 03:05:59.335883 - (1, 1) glob_iter/iters_per_epoch : 3/2 
DLL 2022-07-01 03:06:00.064145 - (1, 1) train_loss : 48.87165069580078 
DLL 2022-07-01 03:06:01.459274 - (1, 1) train_items_per_sec : 141312.58683897453 
DLL 2022-07-01 03:06:01.459429 - (1, 1) train_iter_time : 2.123391883993463 
DLL 2022-07-01 03:06:01.565173 - (1,) train_items_per_sec : 136118.39055829943 
DLL 2022-07-01 03:06:01.565343 - (1,) train_loss : 48.87165069580078 
DLL 2022-07-01 03:06:01.565394 - (1,) train_epoch_time : 5.773306171999138 
DLL 2022-07-01 03:06:02.654605 - (1, 4, 0) val_items_per_sec : 109117.65555664316 
DLL 2022-07-01 03:06:02.767041 - (1,) val_loss : 48.1595573425293 
DLL 2022-07-01 03:06:02.767172 - (1,) val_items_per_sec : 109117.65555664316 
DLL 2022-07-01 03:06:02.768407 - () run_time : 52.4128801820043 
DLL 2022-07-01 03:06:02.768444 - () val_loss : 48.1595573425293 
DLL 2022-07-01 03:06:02.768464 - () train_items_per_sec : 136118.39055829943 
DONE!
