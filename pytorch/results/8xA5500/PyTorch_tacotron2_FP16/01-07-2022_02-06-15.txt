train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2022-07-01 02:06:16.739508 - PARAMETER output : ./ 
DLL 2022-07-01 02:06:16.739578 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2022-07-01 02:06:16.739600 - PARAMETER model_name : Tacotron2 
DLL 2022-07-01 02:06:16.739618 - PARAMETER log_file : nvlog.json 
DLL 2022-07-01 02:06:16.739634 - PARAMETER anneal_steps : None 
DLL 2022-07-01 02:06:16.739650 - PARAMETER anneal_factor : 0.1 
DLL 2022-07-01 02:06:16.739666 - PARAMETER epochs : 2 
DLL 2022-07-01 02:06:16.739685 - PARAMETER epochs_per_checkpoint : 50 
DLL 2022-07-01 02:06:16.739700 - PARAMETER checkpoint_path :  
DLL 2022-07-01 02:06:16.739715 - PARAMETER resume_from_last : False 
DLL 2022-07-01 02:06:16.739730 - PARAMETER dynamic_loss_scaling : True 
DLL 2022-07-01 02:06:16.739745 - PARAMETER amp : False 
DLL 2022-07-01 02:06:16.739759 - PARAMETER cudnn_enabled : True 
DLL 2022-07-01 02:06:16.739774 - PARAMETER cudnn_benchmark : False 
DLL 2022-07-01 02:06:16.739788 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2022-07-01 02:06:16.739805 - PARAMETER use_saved_learning_rate : False 
DLL 2022-07-01 02:06:16.739820 - PARAMETER learning_rate : 0.0 
DLL 2022-07-01 02:06:16.739836 - PARAMETER weight_decay : 1e-06 
DLL 2022-07-01 02:06:16.739852 - PARAMETER grad_clip_thresh : 1.0 
DLL 2022-07-01 02:06:16.739868 - PARAMETER batch_size : 80 
DLL 2022-07-01 02:06:16.739885 - PARAMETER grad_clip : 5.0 
DLL 2022-07-01 02:06:16.739900 - PARAMETER load_mel_from_disk : False 
DLL 2022-07-01 02:06:16.739914 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_2500_filelist.txt 
DLL 2022-07-01 02:06:16.739932 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2022-07-01 02:06:16.739948 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2022-07-01 02:06:16.739968 - PARAMETER max_wav_value : 32768.0 
DLL 2022-07-01 02:06:16.739983 - PARAMETER sampling_rate : 22050 
DLL 2022-07-01 02:06:16.739997 - PARAMETER filter_length : 1024 
DLL 2022-07-01 02:06:16.740016 - PARAMETER hop_length : 256 
DLL 2022-07-01 02:06:16.740030 - PARAMETER win_length : 1024 
DLL 2022-07-01 02:06:16.740044 - PARAMETER mel_fmin : 0.0 
DLL 2022-07-01 02:06:16.740059 - PARAMETER mel_fmax : 8000.0 
DLL 2022-07-01 02:06:16.740074 - PARAMETER rank : 0 
DLL 2022-07-01 02:06:16.740088 - PARAMETER world_size : 8 
DLL 2022-07-01 02:06:16.740103 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2022-07-01 02:06:16.740117 - PARAMETER group_name : group_name 
DLL 2022-07-01 02:06:16.740131 - PARAMETER dist_backend : nccl 
DLL 2022-07-01 02:06:16.740145 - PARAMETER bench_class :  
DLL 2022-07-01 02:06:16.740159 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 02:06:42.992894 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2022-07-01 02:06:51.295030 - (0, 0) train_loss : 47.33379364013672 
DLL 2022-07-01 02:06:53.301253 - (0, 0) train_items_per_sec : 35529.50040061545 
DLL 2022-07-01 02:06:53.301380 - (0, 0) train_iter_time : 10.308391501999722 
DLL 2022-07-01 02:06:53.310002 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2022-07-01 02:06:54.158499 - (0, 1) train_loss : 46.6800651550293 
DLL 2022-07-01 02:06:55.730780 - (0, 1) train_items_per_sec : 148695.7400821712 
DLL 2022-07-01 02:06:55.730872 - (0, 1) train_iter_time : 2.4208023700011836 
DLL 2022-07-01 02:06:55.746446 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2022-07-01 02:06:56.450631 - (0, 2) train_loss : 46.877960205078125 
DLL 2022-07-01 02:06:58.071573 - (0, 2) train_items_per_sec : 155149.0995753192 
DLL 2022-07-01 02:06:58.071673 - (0, 2) train_iter_time : 2.3251440130006813 
DLL 2022-07-01 02:06:58.130856 - (0,) train_items_per_sec : 113124.78001936863 
DLL 2022-07-01 02:06:58.130944 - (0,) train_loss : 46.877960205078125 
DLL 2022-07-01 02:06:58.130990 - (0,) train_epoch_time : 16.95980635700107 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 02:06:59.161023 - (0, 3, 0) val_items_per_sec : 106552.56765880654 
DLL 2022-07-01 02:06:59.259964 - (0,) val_loss : 48.19844055175781 
DLL 2022-07-01 02:06:59.260006 - (0,) val_items_per_sec : 106552.56765880654 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2022-07-01 02:07:01.441549 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2022-07-01 02:07:02.188708 - (1, 0) train_loss : 46.523773193359375 
DLL 2022-07-01 02:07:03.780960 - (1, 0) train_items_per_sec : 153621.3245148938 
DLL 2022-07-01 02:07:03.781056 - (1, 0) train_iter_time : 2.339453855998727 
DLL 2022-07-01 02:07:03.798936 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2022-07-01 02:07:04.508935 - (1, 1) train_loss : 47.4537353515625 
DLL 2022-07-01 02:07:06.140627 - (1, 1) train_items_per_sec : 156136.77903495496 
DLL 2022-07-01 02:07:06.140724 - (1, 1) train_iter_time : 2.3417096359989955 
DLL 2022-07-01 02:07:06.154543 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2022-07-01 02:07:06.873465 - (1, 2) train_loss : 46.73383712768555 
DLL 2022-07-01 02:07:08.446388 - (1, 2) train_items_per_sec : 157340.0893728243 
DLL 2022-07-01 02:07:08.446482 - (1, 2) train_iter_time : 2.291857094001898 
DLL 2022-07-01 02:07:08.532753 - (1,) train_items_per_sec : 155699.39764089102 
DLL 2022-07-01 02:07:08.532811 - (1,) train_loss : 46.73383712768555 
DLL 2022-07-01 02:07:08.532842 - (1,) train_epoch_time : 8.787878172999626 
DLL 2022-07-01 02:07:09.672652 - (1, 6, 0) val_items_per_sec : 96824.81589968434 
DLL 2022-07-01 02:07:09.764183 - (1,) val_loss : 48.17317199707031 
DLL 2022-07-01 02:07:09.764288 - (1,) val_items_per_sec : 96824.81589968434 
DLL 2022-07-01 02:07:09.765653 - () run_time : 49.41264758499892 
DLL 2022-07-01 02:07:09.765689 - () val_loss : 48.17317199707031 
DLL 2022-07-01 02:07:09.765708 - () train_items_per_sec : 155699.39764089102 
DONE!
