DLL 2022-07-01 00:07:01.128075 - PARAMETER output : ./ 
DLL 2022-07-01 00:07:01.128141 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2022-07-01 00:07:01.128163 - PARAMETER model_name : Tacotron2 
DLL 2022-07-01 00:07:01.128183 - PARAMETER log_file : nvlog.json 
DLL 2022-07-01 00:07:01.128199 - PARAMETER anneal_steps : None 
DLL 2022-07-01 00:07:01.128215 - PARAMETER anneal_factor : 0.1 
DLL 2022-07-01 00:07:01.128233 - PARAMETER epochs : 2 
DLL 2022-07-01 00:07:01.128249 - PARAMETER epochs_per_checkpoint : 50 
DLL 2022-07-01 00:07:01.128265 - PARAMETER checkpoint_path :  
DLL 2022-07-01 00:07:01.128280 - PARAMETER resume_from_last : False 
DLL 2022-07-01 00:07:01.128295 - PARAMETER dynamic_loss_scaling : True 
DLL 2022-07-01 00:07:01.128311 - PARAMETER amp : False 
DLL 2022-07-01 00:07:01.128328 - PARAMETER cudnn_enabled : True 
DLL 2022-07-01 00:07:01.128343 - PARAMETER cudnn_benchmark : False 
DLL 2022-07-01 00:07:01.128358 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2022-07-01 00:07:01.128373 - PARAMETER use_saved_learning_rate : False 
DLL 2022-07-01 00:07:01.128387 - PARAMETER learning_rate : 0.0 
DLL 2022-07-01 00:07:01.128405 - PARAMETER weight_decay : 1e-06 
DLL 2022-07-01 00:07:01.128423 - PARAMETER grad_clip_thresh : 1.0 
DLL 2022-07-01 00:07:01.128440 - PARAMETER batch_size : 52 
DLL 2022-07-01 00:07:01.128455 - PARAMETER grad_clip : 5.0 
DLL 2022-07-01 00:07:01.128470 - PARAMETER load_mel_from_disk : False 
DLL 2022-07-01 00:07:01.128487 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2022-07-01 00:07:01.128502 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2022-07-01 00:07:01.128517 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2022-07-01 00:07:01.128535 - PARAMETER max_wav_value : 32768.0 
DLL 2022-07-01 00:07:01.128551 - PARAMETER sampling_rate : 22050 
DLL 2022-07-01 00:07:01.128566 - PARAMETER filter_length : 1024 
DLL 2022-07-01 00:07:01.128580 - PARAMETER hop_length : 256 
DLL 2022-07-01 00:07:01.128595 - PARAMETER win_length : 1024 
DLL 2022-07-01 00:07:01.128609 - PARAMETER mel_fmin : 0.0 
DLL 2022-07-01 00:07:01.128624 - PARAMETER mel_fmax : 8000.0 
DLL 2022-07-01 00:07:01.128639 - PARAMETER rank : 0 
DLL 2022-07-01 00:07:01.128653 - PARAMETER world_size : 4 
DLL 2022-07-01 00:07:01.128670 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2022-07-01 00:07:01.128684 - PARAMETER group_name : group_name 
DLL 2022-07-01 00:07:01.128699 - PARAMETER dist_backend : nccl 
DLL 2022-07-01 00:07:01.128713 - PARAMETER bench_class :  
DLL 2022-07-01 00:07:01.128728 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 00:07:24.588670 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2022-07-01 00:07:31.553709 - (0, 0) train_loss : 46.19710922241211 
DLL 2022-07-01 00:07:33.250030 - (0, 0) train_items_per_sec : 13270.912423064434 
DLL 2022-07-01 00:07:33.250135 - (0, 0) train_iter_time : 8.66142404799757 
DLL 2022-07-01 00:07:33.254585 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2022-07-01 00:07:33.953459 - (0, 1) train_loss : 47.811363220214844 
DLL 2022-07-01 00:07:35.399879 - (0, 1) train_items_per_sec : 55569.42246795434 
DLL 2022-07-01 00:07:35.399996 - (0, 1) train_iter_time : 2.1452985239993723 
DLL 2022-07-01 00:07:35.408614 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2022-07-01 00:07:36.110096 - (0, 2) train_loss : 47.29146194458008 
DLL 2022-07-01 00:07:37.560876 - (0, 2) train_items_per_sec : 54732.942404336114 
DLL 2022-07-01 00:07:37.560982 - (0, 2) train_iter_time : 2.1522687220021908 
DLL 2022-07-01 00:07:37.623102 - (0,) train_items_per_sec : 41191.092431784964 
DLL 2022-07-01 00:07:37.623217 - (0,) train_loss : 47.29146194458008 
DLL 2022-07-01 00:07:37.623240 - (0,) train_epoch_time : 14.129679445002694 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:167: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn(
DLL 2022-07-01 00:07:38.846645 - (0, 3, 0) val_items_per_sec : 98892.25726290168 
DLL 2022-07-01 00:07:38.924655 - (0,) val_loss : 47.302734375 
DLL 2022-07-01 00:07:38.924741 - (0,) val_items_per_sec : 98892.25726290168 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2022-07-01 00:07:40.565178 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2022-07-01 00:07:41.514571 - (1, 0) train_loss : 46.484371185302734 
DLL 2022-07-01 00:07:42.965268 - (1, 0) train_items_per_sec : 48231.03021207011 
DLL 2022-07-01 00:07:42.965364 - (1, 0) train_iter_time : 2.400135337997199 
DLL 2022-07-01 00:07:42.977260 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2022-07-01 00:07:43.678980 - (1, 1) train_loss : 46.920108795166016 
DLL 2022-07-01 00:07:45.171640 - (1, 1) train_items_per_sec : 53778.53424580012 
DLL 2022-07-01 00:07:45.171743 - (1, 1) train_iter_time : 2.1943885540022166 
DLL 2022-07-01 00:07:45.182268 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2022-07-01 00:07:45.878842 - (1, 2) train_loss : 47.52989959716797 
DLL 2022-07-01 00:07:47.320931 - (1, 2) train_items_per_sec : 55252.41113460369 
DLL 2022-07-01 00:07:47.321035 - (1, 2) train_iter_time : 2.138675898000656 
DLL 2022-07-01 00:07:47.403245 - (1,) train_items_per_sec : 52420.65853082464 
DLL 2022-07-01 00:07:47.403284 - (1,) train_loss : 47.52989959716797 
DLL 2022-07-01 00:07:47.403304 - (1,) train_epoch_time : 7.928071294998517 
DLL 2022-07-01 00:07:48.655719 - (1, 6, 0) val_items_per_sec : 100957.89459949158 
DLL 2022-07-01 00:07:48.743017 - (1,) val_loss : 47.27960205078125 
DLL 2022-07-01 00:07:48.743059 - (1,) val_items_per_sec : 100957.89459949158 
DLL 2022-07-01 00:07:48.744424 - () run_time : 45.70575021100012 
DLL 2022-07-01 00:07:48.744460 - () val_loss : 47.27960205078125 
DLL 2022-07-01 00:07:48.744480 - () train_items_per_sec : 52420.65853082464 
DONE!
