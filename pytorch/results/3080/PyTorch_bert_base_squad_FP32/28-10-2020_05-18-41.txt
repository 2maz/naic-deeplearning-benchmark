Container nvidia build =  16972326
out dir is .
python   run_squad.py --init_checkpoint=/data/bert_base/bert_base_uncased.pt --do_train --train_file=/data/squad/v1.1/train-v1.1.json --train_batch_size=10  --do_lower_case  --bert_model=bert-large-uncased  --learning_rate=0.0  --seed=1  --num_train_epochs=1.0  --max_seq_length=384  --doc_stride=128  --output_dir=.  --vocab_file=/data/bert_base/bert-base-uncased-vocab.txt  --config_file=/data/bert_base/bert_config.json  --max_steps=100   |& tee ./logfile.txt
Iteration:   0%|          | 0/8865 [00:00<?, ?it/s]/opt/conda/lib/python3.6/site-packages/torch/functional.py:1242: UserWarning: torch.norm is deprecated and may be removed in a future PyTorch release. Use torch.linalg.norm instead.
  "torch.norm is deprecated and may be removed in a future PyTorch release. "
/workspace/examples/bert/optimization.py:150: UserWarning: This overload of add_ is deprecated:
	add_(Number alpha, Tensor other)
Consider using one of the following signatures instead:
	add_(Tensor other, *, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:882.)
  next_m.mul_(beta1).add_(1 - beta1, grad)
Iteration:   0%|          | 1/8865 [00:00<1:38:09,  1.51it/s]Iteration:   0%|          | 2/8865 [00:00<1:18:05,  1.89it/s]Iteration:   0%|          | 3/8865 [00:01<1:03:38,  2.32it/s]Iteration:   0%|          | 4/8865 [00:01<53:33,  2.76it/s]  Iteration:   0%|          | 5/8865 [00:01<46:30,  3.17it/s]Iteration:   0%|          | 6/8865 [00:01<41:35,  3.55it/s]Iteration:   0%|          | 7/8865 [00:01<38:07,  3.87it/s]Iteration:   0%|          | 8/8865 [00:02<35:45,  4.13it/s]Iteration:   0%|          | 9/8865 [00:02<34:04,  4.33it/s]Iteration:   0%|          | 10/8865 [00:02<32:52,  4.49it/s]Iteration:   0%|          | 11/8865 [00:02<31:59,  4.61it/s]Iteration:   0%|          | 12/8865 [00:02<31:24,  4.70it/s]Iteration:   0%|          | 13/8865 [00:03<30:58,  4.76it/s]Iteration:   0%|          | 14/8865 [00:03<30:40,  4.81it/s]Iteration:   0%|          | 15/8865 [00:03<30:28,  4.84it/s]Iteration:   0%|          | 16/8865 [00:03<30:20,  4.86it/s]Iteration:   0%|          | 17/8865 [00:03<30:14,  4.88it/s]Iteration:   0%|          | 18/8865 [00:04<30:13,  4.88it/s]Iteration:   0%|          | 19/8865 [00:04<30:14,  4.87it/s]Iteration:   0%|          | 20/8865 [00:04<30:13,  4.88it/s]Iteration:   0%|          | 21/8865 [00:04<30:10,  4.89it/s]Iteration:   0%|          | 22/8865 [00:04<30:06,  4.90it/s]Iteration:   0%|          | 23/8865 [00:05<30:04,  4.90it/s]Iteration:   0%|          | 24/8865 [00:05<30:02,  4.90it/s]Iteration:   0%|          | 25/8865 [00:05<30:07,  4.89it/s]Iteration:   0%|          | 26/8865 [00:05<30:02,  4.90it/s]Iteration:   0%|          | 27/8865 [00:05<30:01,  4.91it/s]Iteration:   0%|          | 28/8865 [00:06<30:04,  4.90it/s]Iteration:   0%|          | 29/8865 [00:06<30:03,  4.90it/s]Iteration:   0%|          | 30/8865 [00:06<30:01,  4.91it/s]Iteration:   0%|          | 31/8865 [00:06<30:01,  4.90it/s]Iteration:   0%|          | 32/8865 [00:07<31:14,  4.71it/s]Iteration:   0%|          | 33/8865 [00:07<32:04,  4.59it/s]Iteration:   0%|          | 34/8865 [00:07<32:38,  4.51it/s]Iteration:   0%|          | 35/8865 [00:07<33:02,  4.45it/s]Iteration:   0%|          | 36/8865 [00:07<32:05,  4.59it/s]Iteration:   0%|          | 37/8865 [00:08<31:27,  4.68it/s]Iteration:   0%|          | 38/8865 [00:08<31:03,  4.74it/s]Iteration:   0%|          | 39/8865 [00:08<30:43,  4.79it/s]Iteration:   0%|          | 40/8865 [00:08<30:30,  4.82it/s]Iteration:   0%|          | 41/8865 [00:08<30:20,  4.85it/s]Iteration:   0%|          | 42/8865 [00:09<30:13,  4.86it/s]Iteration:   0%|          | 43/8865 [00:09<30:09,  4.88it/s]Iteration:   0%|          | 44/8865 [00:09<30:11,  4.87it/s]Iteration:   1%|          | 45/8865 [00:09<30:07,  4.88it/s]Iteration:   1%|          | 46/8865 [00:09<30:04,  4.89it/s]Iteration:   1%|          | 47/8865 [00:10<30:01,  4.89it/s]Iteration:   1%|          | 48/8865 [00:10<30:00,  4.90it/s]Iteration:   1%|          | 49/8865 [00:10<29:59,  4.90it/s]Iteration:   1%|          | 50/8865 [00:10<29:58,  4.90it/s]Iteration:   1%|          | 51/8865 [00:10<29:57,  4.90it/s]Iteration:   1%|          | 52/8865 [00:11<29:57,  4.90it/s]Iteration:   1%|          | 53/8865 [00:11<29:55,  4.91it/s]Iteration:   1%|          | 54/8865 [00:11<29:55,  4.91it/s]Iteration:   1%|          | 55/8865 [00:11<29:55,  4.91it/s]Iteration:   1%|          | 56/8865 [00:11<29:54,  4.91it/s]Iteration:   1%|          | 57/8865 [00:12<29:52,  4.91it/s]Iteration:   1%|          | 58/8865 [00:12<29:52,  4.91it/s]Iteration:   1%|          | 59/8865 [00:12<29:54,  4.91it/s]Iteration:   1%|          | 60/8865 [00:12<29:55,  4.91it/s]Iteration:   1%|          | 61/8865 [00:13<29:54,  4.91it/s]Iteration:   1%|          | 62/8865 [00:13<29:54,  4.91it/s]Iteration:   1%|          | 63/8865 [00:13<29:55,  4.90it/s]Iteration:   1%|          | 64/8865 [00:13<29:55,  4.90it/s]Iteration:   1%|          | 65/8865 [00:13<29:55,  4.90it/s]Iteration:   1%|          | 66/8865 [00:14<29:55,  4.90it/s]Iteration:   1%|          | 67/8865 [00:14<29:56,  4.90it/s]Iteration:   1%|          | 68/8865 [00:14<29:55,  4.90it/s]Iteration:   1%|          | 69/8865 [00:14<29:55,  4.90it/s]Iteration:   1%|          | 70/8865 [00:14<29:53,  4.90it/s]Iteration:   1%|          | 71/8865 [00:15<29:54,  4.90it/s]Iteration:   1%|          | 72/8865 [00:15<29:53,  4.90it/s]Iteration:   1%|          | 73/8865 [00:15<29:52,  4.90it/s]Iteration:   1%|          | 74/8865 [00:15<29:51,  4.91it/s]Iteration:   1%|          | 75/8865 [00:15<29:52,  4.90it/s]Iteration:   1%|          | 76/8865 [00:16<29:53,  4.90it/s]Iteration:   1%|          | 77/8865 [00:16<29:54,  4.90it/s]Iteration:   1%|          | 78/8865 [00:16<29:51,  4.90it/s]Iteration:   1%|          | 79/8865 [00:16<29:52,  4.90it/s]Iteration:   1%|          | 80/8865 [00:16<29:51,  4.90it/s]Iteration:   1%|          | 81/8865 [00:17<29:51,  4.90it/s]Iteration:   1%|          | 82/8865 [00:17<29:51,  4.90it/s]Iteration:   1%|          | 83/8865 [00:17<29:51,  4.90it/s]Iteration:   1%|          | 84/8865 [00:17<29:50,  4.90it/s]Iteration:   1%|          | 85/8865 [00:17<29:49,  4.91it/s]Iteration:   1%|          | 86/8865 [00:18<29:49,  4.91it/s]Iteration:   1%|          | 87/8865 [00:18<29:53,  4.89it/s]Iteration:   1%|          | 88/8865 [00:18<29:54,  4.89it/s]Iteration:   1%|          | 89/8865 [00:18<29:53,  4.89it/s]Iteration:   1%|          | 90/8865 [00:18<29:53,  4.89it/s]Iteration:   1%|          | 91/8865 [00:19<29:51,  4.90it/s]Iteration:   1%|          | 92/8865 [00:19<29:51,  4.90it/s]Iteration:   1%|          | 93/8865 [00:19<29:54,  4.89it/s]Iteration:   1%|          | 94/8865 [00:19<29:52,  4.89it/s]Iteration:   1%|          | 95/8865 [00:19<29:52,  4.89it/s]Iteration:   1%|          | 96/8865 [00:20<29:51,  4.90it/s]Iteration:   1%|          | 97/8865 [00:20<29:52,  4.89it/s]Iteration:   1%|          | 98/8865 [00:20<29:55,  4.88it/s]Iteration:   1%|          | 99/8865 [00:20<29:52,  4.89it/s]Iteration:   1%|          | 100/8865 [00:20<29:56,  4.88it/s]Iteration:   1%|          | 101/8865 [00:21<29:53,  4.89it/s]device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
DLL 2020-10-28 05:18:42.330156 - PARAMETER Config : ["Namespace(amp=False, bert_model='bert-large-uncased', cache_dir=None, config_file='/data/bert_base/bert_config.json', disable_progress_bar=False, do_eval=False, do_lower_case=True, do_predict=False, do_train=True, doc_stride=128, eval_script='evaluate.py', fp16=False, gradient_accumulation_steps=1, init_checkpoint='/data/bert_base/bert_base_uncased.pt', json_summary='results/dllogger.json', learning_rate=0.0, local_rank=-1, log_freq=50, loss_scale=0, max_answer_length=30, max_query_length=64, max_seq_length=384, max_steps=100.0, n_best_size=20, no_cuda=False, null_score_diff_threshold=0.0, num_train_epochs=1.0, output_dir='.', predict_batch_size=8, predict_file=None, seed=1, skip_cache=False, skip_checkpoint=False, train_batch_size=10, train_file='/data/squad/v1.1/train-v1.1.json', use_env=False, verbose_logging=False, version_2_with_negative=False, vocab_file='/data/bert_base/bert-base-uncased-vocab.txt', warmup_proportion=0.1)"] 
DLL 2020-10-28 05:18:42.330558 - PARAMETER SEED : 1 
WARNING: Output directory . already exists and is not empty. ['file_utils.py', 'modeling.py', 'scripts', 'bind_pyt.py', 'results', 'bind.sh', 'requirements.txt', 'run_squad.py', 'extract_features.py', 'checkpoints', 'triton', 'Dockerfile', 'images', 'run_swag.py', 'bert_config.json', 'data', 'utils.py', 'configurations.yml', 'run.sub', 'run_glue.py', 'inference.py', 'README.md', 'LICENSE', 'tokenization.py', 'vocab', '.git', 'run_pretraining.py', 'schedulers.py', 'NOTICE', '.dockerignore', '.gitmodules', 'create_pretraining_data.py', 'optimization.py', 'processors', '.gitignore', 'pytorch_model.bin', 'logfile.txt', '__pycache__']
DLL 2020-10-28 05:18:50.019242 - PARAMETER loading_checkpoint : True 
DLL 2020-10-28 05:18:50.019331 - PARAMETER loaded_checkpoint : True 
DLL 2020-10-28 05:18:51.061860 - PARAMETER model_weights_num : 109488386 
DLL 2020-10-28 05:18:58.333365 - PARAMETER train_start : True 
DLL 2020-10-28 05:18:58.333454 - PARAMETER training_samples : 87599 
DLL 2020-10-28 05:18:58.333474 - PARAMETER training_features : 88641 
DLL 2020-10-28 05:18:58.333491 - PARAMETER train_batch_size : 10 
DLL 2020-10-28 05:18:58.333505 - PARAMETER steps : 8759.0 
DLL 2020-10-28 05:19:00.262830 - Training Epoch: 0 Training Iteration: 1  step_loss : 5.999619960784912  learning_rate : 0.0 
DLL 2020-10-28 05:19:10.574958 - Training Epoch: 0 Training Iteration: 51  step_loss : 5.853907585144043  learning_rate : 0.0 
DLL 2020-10-28 05:19:20.779977 - Training Epoch: 0 Training Iteration: 101  step_loss : 5.917998313903809  learning_rate : 0.0 
DLL 2020-10-28 05:19:21.514554 -  e2e_train_time : 21.18358874320984  training_sequences_per_second : 47.206354509716334  final_loss : 5.917998313903809 


real	0m41.309s
user	0m39.329s
sys	0m4.808s
DONE!
