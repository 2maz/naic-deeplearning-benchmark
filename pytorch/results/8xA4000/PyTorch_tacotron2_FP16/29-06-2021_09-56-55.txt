train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
DLL 2021-06-29 09:56:57.814638 - PARAMETER output : ./ 
DLL 2021-06-29 09:56:57.814708 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-29 09:56:57.814734 - PARAMETER model_name : Tacotron2 
DLL 2021-06-29 09:56:57.814755 - PARAMETER log_file : nvlog.json 
DLL 2021-06-29 09:56:57.814774 - PARAMETER anneal_steps : None 
DLL 2021-06-29 09:56:57.814793 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-29 09:56:57.814812 - PARAMETER epochs : 3 
DLL 2021-06-29 09:56:57.814831 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-29 09:56:57.814849 - PARAMETER checkpoint_path :  
DLL 2021-06-29 09:56:57.814866 - PARAMETER resume_from_last : False 
DLL 2021-06-29 09:56:57.814904 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-29 09:56:57.814926 - PARAMETER amp : False 
DLL 2021-06-29 09:56:57.814944 - PARAMETER cudnn_enabled : True 
DLL 2021-06-29 09:56:57.814962 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-29 09:56:57.814978 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-29 09:56:57.814995 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-29 09:56:57.815011 - PARAMETER learning_rate : 0.0 
DLL 2021-06-29 09:56:57.815028 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-29 09:56:57.815046 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-29 09:56:57.815063 - PARAMETER batch_size : 48 
DLL 2021-06-29 09:56:57.815079 - PARAMETER grad_clip : 5.0 
DLL 2021-06-29 09:56:57.815095 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-29 09:56:57.815112 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_1250_filelist.txt 
DLL 2021-06-29 09:56:57.815128 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-29 09:56:57.815144 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-29 09:56:57.815163 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-29 09:56:57.815181 - PARAMETER sampling_rate : 22050 
DLL 2021-06-29 09:56:57.815197 - PARAMETER filter_length : 1024 
DLL 2021-06-29 09:56:57.815213 - PARAMETER hop_length : 256 
DLL 2021-06-29 09:56:57.815229 - PARAMETER win_length : 1024 
DLL 2021-06-29 09:56:57.815244 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-29 09:56:57.815260 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-29 09:56:57.815276 - PARAMETER rank : 0 
DLL 2021-06-29 09:56:57.815292 - PARAMETER world_size : 8 
DLL 2021-06-29 09:56:57.815308 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-29 09:56:57.815324 - PARAMETER group_name : group_name 
DLL 2021-06-29 09:56:57.815339 - PARAMETER dist_backend : nccl 
DLL 2021-06-29 09:56:57.815355 - PARAMETER bench_class :  
DLL 2021-06-29 09:56:57.815371 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/workspace/examples/tacotron2/tacotron2/text/__init__.py:74: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  return s in _symbol_to_id and s is not '_' and s is not '~'
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:57:13.407792 - (0, 0) glob_iter/iters_per_epoch : 0/3 
DLL 2021-06-29 09:57:29.491488 - (0, 0) train_loss : 47.575843811035156 
DLL 2021-06-29 09:57:31.773845 - (0, 0) train_items_per_sec : 11954.225870544395 
DLL 2021-06-29 09:57:31.773973 - (0, 0) train_iter_time : 18.366141176986275 
DLL 2021-06-29 09:57:31.781258 - (0, 1) glob_iter/iters_per_epoch : 1/3 
DLL 2021-06-29 09:57:32.903845 - (0, 1) train_loss : 46.056278228759766 
DLL 2021-06-29 09:57:34.788385 - (0, 1) train_items_per_sec : 71182.37229818478 
DLL 2021-06-29 09:57:34.788469 - (0, 1) train_iter_time : 3.007163053000113 
DLL 2021-06-29 09:57:34.796060 - (0, 2) glob_iter/iters_per_epoch : 2/3 
DLL 2021-06-29 09:57:35.598865 - (0, 2) train_loss : 47.68867111206055 
DLL 2021-06-29 09:57:37.485669 - (0, 2) train_items_per_sec : 81362.5451568161 
DLL 2021-06-29 09:57:37.485753 - (0, 2) train_iter_time : 2.689615960000083 
DLL 2021-06-29 09:57:37.546339 - (0,) train_items_per_sec : 54833.04777518176 
DLL 2021-06-29 09:57:37.546472 - (0,) train_loss : 47.68867111206055 
DLL 2021-06-29 09:57:37.546513 - (0,) train_epoch_time : 25.681323227996472 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:57:38.777043 - (0, 3, 0) val_items_per_sec : 77873.14043606281 
DLL 2021-06-29 09:57:38.854373 - (0,) val_loss : 48.035850524902344 
DLL 2021-06-29 09:57:38.854477 - (0,) val_items_per_sec : 77873.14043606281 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-29 09:57:40.413405 - (1, 0) glob_iter/iters_per_epoch : 3/3 
DLL 2021-06-29 09:57:41.349226 - (1, 0) train_loss : 46.66971206665039 
DLL 2021-06-29 09:57:43.226737 - (1, 0) train_items_per_sec : 75666.94187693004 
DLL 2021-06-29 09:57:43.226826 - (1, 0) train_iter_time : 2.8133686220098753 
DLL 2021-06-29 09:57:43.235579 - (1, 1) glob_iter/iters_per_epoch : 4/3 
DLL 2021-06-29 09:57:44.071943 - (1, 1) train_loss : 47.80274963378906 
DLL 2021-06-29 09:57:45.968824 - (1, 1) train_items_per_sec : 80288.05734061632 
DLL 2021-06-29 09:57:45.968905 - (1, 1) train_iter_time : 2.7332583109964617 
DLL 2021-06-29 09:57:45.977328 - (1, 2) glob_iter/iters_per_epoch : 5/3 
DLL 2021-06-29 09:57:46.754320 - (1, 2) train_loss : 47.34687805175781 
DLL 2021-06-29 09:57:48.634027 - (1, 2) train_items_per_sec : 82909.03669702307 
DLL 2021-06-29 09:57:48.634108 - (1, 2) train_iter_time : 2.6567067810101435 
DLL 2021-06-29 09:57:48.714868 - (1,) train_items_per_sec : 79621.34530485648 
DLL 2021-06-29 09:57:48.714930 - (1,) train_loss : 47.34687805175781 
DLL 2021-06-29 09:57:48.714964 - (1,) train_epoch_time : 9.373519482003758 
DLL 2021-06-29 09:57:49.862915 - (1, 6, 0) val_items_per_sec : 90262.33604032852 
DLL 2021-06-29 09:57:49.937127 - (1,) val_loss : 48.01587677001953 
DLL 2021-06-29 09:57:49.937267 - (1,) val_items_per_sec : 90262.33604032852 
DLL 2021-06-29 09:57:51.135602 - (2, 0) glob_iter/iters_per_epoch : 6/3 
DLL 2021-06-29 09:57:52.055920 - (2, 0) train_loss : 48.47684860229492 
DLL 2021-06-29 09:57:53.958767 - (2, 0) train_items_per_sec : 79339.45315937209 
DLL 2021-06-29 09:57:53.958850 - (2, 0) train_iter_time : 2.8231981830031145 
DLL 2021-06-29 09:57:53.972365 - (2, 1) glob_iter/iters_per_epoch : 7/3 
DLL 2021-06-29 09:57:54.763694 - (2, 1) train_loss : 46.46392822265625 
DLL 2021-06-29 09:57:56.662511 - (2, 1) train_items_per_sec : 80100.25875098153 
DLL 2021-06-29 09:57:56.662586 - (2, 1) train_iter_time : 2.6901536069926806 
DLL 2021-06-29 09:57:56.676556 - (2, 2) glob_iter/iters_per_epoch : 8/3 
DLL 2021-06-29 09:57:57.456591 - (2, 2) train_loss : 46.63234329223633 
DLL 2021-06-29 09:57:59.313070 - (2, 2) train_items_per_sec : 81576.66994575094 
DLL 2021-06-29 09:57:59.313158 - (2, 2) train_iter_time : 2.636513603007188 
DLL 2021-06-29 09:57:59.404256 - (2,) train_items_per_sec : 80338.79395203486 
DLL 2021-06-29 09:57:59.404339 - (2,) train_loss : 46.63234329223633 
DLL 2021-06-29 09:57:59.404387 - (2,) train_epoch_time : 9.464873136981623 
DLL 2021-06-29 09:58:00.578874 - (2, 9, 0) val_items_per_sec : 87044.94133366046 
DLL 2021-06-29 09:58:00.667303 - (2,) val_loss : 47.99835968017578 
DLL 2021-06-29 09:58:00.667430 - (2,) val_items_per_sec : 87044.94133366046 
DLL 2021-06-29 09:58:00.668919 - () run_time : 58.76243646998773 
DLL 2021-06-29 09:58:00.668964 - () val_loss : 47.99835968017578 
DLL 2021-06-29 09:58:00.668991 - () train_items_per_sec : 80338.79395203486 
DONE!
