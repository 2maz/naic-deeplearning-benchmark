train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-26 22:31:43.258201 - PARAMETER output : ./ 
DLL 2021-06-26 22:31:43.258274 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-26 22:31:43.258302 - PARAMETER model_name : Tacotron2 
DLL 2021-06-26 22:31:43.258323 - PARAMETER log_file : nvlog.json 
DLL 2021-06-26 22:31:43.258342 - PARAMETER anneal_steps : None 
DLL 2021-06-26 22:31:43.258363 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-26 22:31:43.258383 - PARAMETER epochs : 2 
DLL 2021-06-26 22:31:43.258401 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-26 22:31:43.258420 - PARAMETER checkpoint_path :  
DLL 2021-06-26 22:31:43.258440 - PARAMETER resume_from_last : False 
DLL 2021-06-26 22:31:43.258460 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-26 22:31:43.258480 - PARAMETER amp : False 
DLL 2021-06-26 22:31:43.258501 - PARAMETER cudnn_enabled : True 
DLL 2021-06-26 22:31:43.258520 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-26 22:31:43.258538 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-26 22:31:43.258555 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-26 22:31:43.258572 - PARAMETER learning_rate : 0.0 
DLL 2021-06-26 22:31:43.258590 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-26 22:31:43.258611 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-26 22:31:43.258629 - PARAMETER batch_size : 52 
DLL 2021-06-26 22:31:43.258646 - PARAMETER grad_clip : 5.0 
DLL 2021-06-26 22:31:43.258664 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-26 22:31:43.258681 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-26 22:31:43.258699 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-26 22:31:43.258716 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-26 22:31:43.258736 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-26 22:31:43.258753 - PARAMETER sampling_rate : 22050 
DLL 2021-06-26 22:31:43.258770 - PARAMETER filter_length : 1024 
DLL 2021-06-26 22:31:43.258787 - PARAMETER hop_length : 256 
DLL 2021-06-26 22:31:43.258803 - PARAMETER win_length : 1024 
DLL 2021-06-26 22:31:43.258819 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-26 22:31:43.258836 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-26 22:31:43.258853 - PARAMETER rank : 0 
DLL 2021-06-26 22:31:43.258869 - PARAMETER world_size : 8 
DLL 2021-06-26 22:31:43.258895 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-26 22:31:43.258913 - PARAMETER group_name : group_name 
DLL 2021-06-26 22:31:43.258930 - PARAMETER dist_backend : nccl 
DLL 2021-06-26 22:31:43.258946 - PARAMETER bench_class :  
DLL 2021-06-26 22:31:43.258963 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 22:32:13.188537 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-06-26 22:33:08.765378 - (0, 0) train_loss : 47.13568115234375 
DLL 2021-06-26 22:33:12.923860 - (0, 0) train_items_per_sec : 3919.9224722428166 
DLL 2021-06-26 22:33:12.923946 - (0, 0) train_iter_time : 59.73536508899997 
DLL 2021-06-26 22:33:12.985541 - (0,) train_items_per_sec : 3919.9224722428166 
DLL 2021-06-26 22:33:12.985612 - (0,) train_loss : 47.13568115234375 
DLL 2021-06-26 22:33:12.985872 - (0,) train_epoch_time : 61.58519513599822 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-26 22:33:14.085496 - (0, 1, 0) val_items_per_sec : 90323.09608267168 
DLL 2021-06-26 22:33:14.164718 - (0,) val_loss : 48.05512619018555 
DLL 2021-06-26 22:33:14.164822 - (0,) val_items_per_sec : 90323.09608267168 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
DLL 2021-06-26 22:33:15.726428 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-06-26 22:33:18.799378 - (1, 0) train_loss : 47.039306640625 
DLL 2021-06-26 22:33:20.755513 - (1, 0) train_items_per_sec : 46483.519743021076 
DLL 2021-06-26 22:33:20.755593 - (1, 0) train_iter_time : 5.029137236000679 
DLL 2021-06-26 22:33:20.836017 - (1,) train_items_per_sec : 46483.519743021076 
DLL 2021-06-26 22:33:20.836078 - (1,) train_loss : 47.039306640625 
DLL 2021-06-26 22:33:20.836108 - (1,) train_epoch_time : 6.197437933999026 
DLL 2021-06-26 22:33:22.013366 - (1, 2, 0) val_items_per_sec : 84784.12136699034 
DLL 2021-06-26 22:33:22.100347 - (1,) val_loss : 48.04521942138672 
DLL 2021-06-26 22:33:22.100444 - (1,) val_items_per_sec : 84784.12136699034 
DLL 2021-06-26 22:33:22.102313 - () run_time : 85.12900972100033 
DLL 2021-06-26 22:33:22.102404 - () val_loss : 48.04521942138672 
DLL 2021-06-26 22:33:22.102458 - () train_items_per_sec : 46483.519743021076 
DONE!
