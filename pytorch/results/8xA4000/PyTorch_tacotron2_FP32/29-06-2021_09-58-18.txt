train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
DLL 2021-06-29 09:58:20.609116 - PARAMETER output : ./ 
DLL 2021-06-29 09:58:20.609185 - PARAMETER dataset_path : /data/tacotron2/LJSpeech-1.1 
DLL 2021-06-29 09:58:20.609212 - PARAMETER model_name : Tacotron2 
DLL 2021-06-29 09:58:20.609233 - PARAMETER log_file : nvlog.json 
DLL 2021-06-29 09:58:20.609251 - PARAMETER anneal_steps : None 
DLL 2021-06-29 09:58:20.609272 - PARAMETER anneal_factor : 0.1 
DLL 2021-06-29 09:58:20.609292 - PARAMETER epochs : 2 
DLL 2021-06-29 09:58:20.609310 - PARAMETER epochs_per_checkpoint : 50 
DLL 2021-06-29 09:58:20.609328 - PARAMETER checkpoint_path :  
DLL 2021-06-29 09:58:20.609347 - PARAMETER resume_from_last : False 
DLL 2021-06-29 09:58:20.609366 - PARAMETER dynamic_loss_scaling : True 
DLL 2021-06-29 09:58:20.609384 - PARAMETER amp : False 
DLL 2021-06-29 09:58:20.609405 - PARAMETER cudnn_enabled : True 
DLL 2021-06-29 09:58:20.609422 - PARAMETER cudnn_benchmark : False 
DLL 2021-06-29 09:58:20.609438 - PARAMETER disable_uniform_initialize_bn_weight : False 
DLL 2021-06-29 09:58:20.609455 - PARAMETER use_saved_learning_rate : False 
DLL 2021-06-29 09:58:20.609471 - PARAMETER learning_rate : 0.0 
DLL 2021-06-29 09:58:20.609490 - PARAMETER weight_decay : 1e-06 
DLL 2021-06-29 09:58:20.609509 - PARAMETER grad_clip_thresh : 1.0 
DLL 2021-06-29 09:58:20.609526 - PARAMETER batch_size : 52 
DLL 2021-06-29 09:58:20.609543 - PARAMETER grad_clip : 5.0 
DLL 2021-06-29 09:58:20.609559 - PARAMETER load_mel_from_disk : False 
DLL 2021-06-29 09:58:20.609576 - PARAMETER training_files : filelists/ljs_audio_text_train_subset_625_filelist.txt 
DLL 2021-06-29 09:58:20.609592 - PARAMETER validation_files : filelists/ljs_audio_text_val_filelist.txt 
DLL 2021-06-29 09:58:20.609608 - PARAMETER text_cleaners : ['english_cleaners'] 
DLL 2021-06-29 09:58:20.609627 - PARAMETER max_wav_value : 32768.0 
DLL 2021-06-29 09:58:20.609644 - PARAMETER sampling_rate : 22050 
DLL 2021-06-29 09:58:20.609660 - PARAMETER filter_length : 1024 
DLL 2021-06-29 09:58:20.609676 - PARAMETER hop_length : 256 
DLL 2021-06-29 09:58:20.609692 - PARAMETER win_length : 1024 
DLL 2021-06-29 09:58:20.609707 - PARAMETER mel_fmin : 0.0 
DLL 2021-06-29 09:58:20.609723 - PARAMETER mel_fmax : 8000.0 
DLL 2021-06-29 09:58:20.609739 - PARAMETER rank : 0 
DLL 2021-06-29 09:58:20.609755 - PARAMETER world_size : 8 
DLL 2021-06-29 09:58:20.609773 - PARAMETER dist_url : tcp://localhost:23456 
DLL 2021-06-29 09:58:20.609789 - PARAMETER group_name : group_name 
DLL 2021-06-29 09:58:20.609805 - PARAMETER dist_backend : nccl 
DLL 2021-06-29 09:58:20.609822 - PARAMETER bench_class :  
DLL 2021-06-29 09:58:20.609839 - PARAMETER model_name : Tacotron2_PyT 
Initializing Distributed
Done initializing distributed
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
train.py:402: SyntaxWarning: "is not" with a literal. Did you mean "!="?
  if args.checkpoint_path is not "":
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:58:37.693329 - (0, 0) glob_iter/iters_per_epoch : 0/1 
DLL 2021-06-29 09:58:53.235252 - (0, 0) train_loss : 47.36636734008789 
DLL 2021-06-29 09:58:55.582069 - (0, 0) train_items_per_sec : 13089.630792422702 
DLL 2021-06-29 09:58:55.582150 - (0, 0) train_iter_time : 17.888816248014336 
DLL 2021-06-29 09:58:55.647845 - (0,) train_items_per_sec : 13089.630792422702 
DLL 2021-06-29 09:58:55.647931 - (0,) train_loss : 47.36636734008789 
DLL 2021-06-29 09:58:55.648122 - (0,) train_epoch_time : 18.961373761994764 
/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
DLL 2021-06-29 09:58:56.799127 - (0, 1, 0) val_items_per_sec : 87797.2136322645 
DLL 2021-06-29 09:58:56.894450 - (0,) val_loss : 48.3096923828125 
DLL 2021-06-29 09:58:56.894557 - (0,) val_items_per_sec : 87797.2136322645 
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0.pt
|||| Updating symlink ./checkpoint_Tacotron2_last.pt to point to checkpoint_Tacotron2_0.pt
DLL 2021-06-29 09:58:58.694850 - (1, 0) glob_iter/iters_per_epoch : 1/1 
DLL 2021-06-29 09:58:59.562708 - (1, 0) train_loss : 47.27257537841797 
DLL 2021-06-29 09:59:01.514471 - (1, 0) train_items_per_sec : 82907.74221282263 
DLL 2021-06-29 09:59:01.514555 - (1, 0) train_iter_time : 2.8196642890106887 
DLL 2021-06-29 09:59:01.608108 - (1,) train_items_per_sec : 82907.74221282263 
DLL 2021-06-29 09:59:01.608220 - (1,) train_loss : 47.27257537841797 
DLL 2021-06-29 09:59:01.608253 - (1,) train_epoch_time : 3.996290882001631 
DLL 2021-06-29 09:59:02.821997 - (1, 2, 0) val_items_per_sec : 82098.34442180539 
DLL 2021-06-29 09:59:02.921923 - (1,) val_loss : 48.31068801879883 
DLL 2021-06-29 09:59:02.922004 - (1,) val_items_per_sec : 82098.34442180539 
DLL 2021-06-29 09:59:02.923004 - () run_time : 37.924069665023126 
DLL 2021-06-29 09:59:02.923058 - () val_loss : 48.31068801879883 
DLL 2021-06-29 09:59:02.923084 - () train_items_per_sec : 82907.74221282263 
DONE!
