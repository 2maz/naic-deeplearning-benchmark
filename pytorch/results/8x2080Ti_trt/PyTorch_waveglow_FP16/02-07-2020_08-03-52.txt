:::NVLOGv0.2.2 Tacotron2_PyT 1593677034.974914074 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593677034.997441530 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593677035.013534069 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593677038.110981703 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1593677038.118541718 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 4, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 8, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1593677041.183227301 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1593677096.106581926 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1593677096.108111143 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677096.238245010 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677099.383915186 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024655386805534363
:::NVLOGv0.2.2 Tacotron2_PyT 1593677101.258979797 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677101.259606838 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 50965.83660980695
:::NVLOGv0.2.2 Tacotron2_PyT 1593677101.260134697 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.022972583770752
Batch: 1/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677101.263615370 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677102.156939030 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017093521310016513
:::NVLOGv0.2.2 Tacotron2_PyT 1593677103.157510519 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677103.158172846 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135103.160337059
:::NVLOGv0.2.2 Tacotron2_PyT 1593677103.158678055 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.894848346710205
Batch: 2/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677103.162191629 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593677103.421656847 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002443103352561593
:::NVLOGv0.2.2 Tacotron2_PyT 1593677104.366160393 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593677104.366554260 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 212479.34041952796
:::NVLOGv0.2.2 Tacotron2_PyT 1593677104.366924763 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2048230171203613
Batch: 3/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677104.369540691 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593677104.604204893 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001650616992264986
:::NVLOGv0.2.2 Tacotron2_PyT 1593677105.513069868 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593677105.513458490 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 223739.5628736401
:::NVLOGv0.2.2 Tacotron2_PyT 1593677105.513843298 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1441874504089355
Batch: 4/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677105.516778946 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593677105.770390987 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002337089041247964
:::NVLOGv0.2.2 Tacotron2_PyT 1593677106.635825872 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593677106.636225224 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 228594.8582743666
:::NVLOGv0.2.2 Tacotron2_PyT 1593677106.636607170 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1198852062225342
Batch: 5/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677106.639185667 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593677106.920702457 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021249905694276094
:::NVLOGv0.2.2 Tacotron2_PyT 1593677107.787009716 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593677107.787462234 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222896.89577770382
:::NVLOGv0.2.2 Tacotron2_PyT 1593677107.787812233 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1485130786895752
Batch: 6/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677107.790713310 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593677108.018607855 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001931887585669756
:::NVLOGv0.2.2 Tacotron2_PyT 1593677108.878529787 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593677108.878946781 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235184.89758673817
:::NVLOGv0.2.2 Tacotron2_PyT 1593677108.879297972 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0885052680969238
Batch: 7/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677108.881915569 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593677109.176475763 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018953575054183602
:::NVLOGv0.2.2 Tacotron2_PyT 1593677110.038640499 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593677110.039082766 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 221184.34256303054
:::NVLOGv0.2.2 Tacotron2_PyT 1593677110.039424658 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1574056148529053
Batch: 8/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677110.042091608 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593677110.341670036 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021576990839093924
:::NVLOGv0.2.2 Tacotron2_PyT 1593677111.311146021 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593677111.311792374 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 201609.47529502332
:::NVLOGv0.2.2 Tacotron2_PyT 1593677111.312299013 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2697815895080566
Batch: 9/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677111.315704823 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593677111.544722080 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002273120917379856
:::NVLOGv0.2.2 Tacotron2_PyT 1593677112.513111115 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593677112.513696432 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 213635.87733237937
:::NVLOGv0.2.2 Tacotron2_PyT 1593677112.514191389 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1983006000518799
Batch: 10/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677112.517192125 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593677112.726948977 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002052831929177046
:::NVLOGv0.2.2 Tacotron2_PyT 1593677113.691070557 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593677113.691741467 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 217908.56192851206
:::NVLOGv0.2.2 Tacotron2_PyT 1593677113.692248344 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1748046875
Batch: 11/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677113.695669651 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593677113.938154936 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019450869876891375
:::NVLOGv0.2.2 Tacotron2_PyT 1593677114.888597488 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593677114.889225006 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 214428.52321477284
:::NVLOGv0.2.2 Tacotron2_PyT 1593677114.889729738 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.193871021270752
Batch: 12/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677114.892218590 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593677115.119509935 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021406172309070826
:::NVLOGv0.2.2 Tacotron2_PyT 1593677116.068101645 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593677116.068676233 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 217552.17726053376
:::NVLOGv0.2.2 Tacotron2_PyT 1593677116.069196701 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1767292022705078
Batch: 13/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677116.072223186 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593677116.294364214 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021430763881653547
:::NVLOGv0.2.2 Tacotron2_PyT 1593677117.248894453 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593677117.249324560 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 217410.42500796757
:::NVLOGv0.2.2 Tacotron2_PyT 1593677117.249675751 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1774964332580566
Batch: 14/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677117.252281189 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593677117.443579674 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024446253664791584
:::NVLOGv0.2.2 Tacotron2_PyT 1593677118.435280085 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593677118.435668707 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 216288.59917242668
:::NVLOGv0.2.2 Tacotron2_PyT 1593677118.436023951 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1836037635803223
Batch: 15/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677118.438563347 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593677118.623987198 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002773941494524479
:::NVLOGv0.2.2 Tacotron2_PyT 1593677119.577543259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593677119.578123808 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 224636.97426179386
:::NVLOGv0.2.2 Tacotron2_PyT 1593677119.578617811 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1396164894104004
Batch: 16/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677119.581589222 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593677119.793552399 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020614543464034796
:::NVLOGv0.2.2 Tacotron2_PyT 1593677120.713938713 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593677120.714381456 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 225900.48437219593
:::NVLOGv0.2.2 Tacotron2_PyT 1593677120.714765549 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1332423686981201
Batch: 17/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677120.717088699 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593677120.951238155 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002297415863722563
:::NVLOGv0.2.2 Tacotron2_PyT 1593677121.911689520 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593677121.912092447 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 214218.43124478665
:::NVLOGv0.2.2 Tacotron2_PyT 1593677121.912437201 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1950418949127197
Batch: 18/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677121.914775372 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593677122.107340574 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017768006073310971
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.063487530 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.064165354 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222754.9807251941
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.064669847 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.149244785308838
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.280070066 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.281026363 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 179002.06191414024
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.281881809 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 206131.2318030242
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.282688618 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002138137161780737
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.283448458 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 27.172871351242065
:::NVLOGv0.2.2 Tacotron2_PyT 1593677123.284259081 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593677125.102974892 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0016596519853919744
:::NVLOGv0.2.2 Tacotron2_PyT 1593677125.104904175 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677127.819235325 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677127.909202337 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677128.171140194 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022783828899264336
:::NVLOGv0.2.2 Tacotron2_PyT 1593677129.050271034 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593677129.050730705 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 224151.5211105892
:::NVLOGv0.2.2 Tacotron2_PyT 1593677129.051109552 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1420845985412598
Batch: 1/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677129.053854704 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677129.286984205 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001654153922572732
:::NVLOGv0.2.2 Tacotron2_PyT 1593677130.156888247 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677130.157332659 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 231948.05533701688
:::NVLOGv0.2.2 Tacotron2_PyT 1593677130.157680988 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1036953926086426
Batch: 2/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677130.160306215 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593677130.507817984 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002545011695474386
:::NVLOGv0.2.2 Tacotron2_PyT 1593677131.366479635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593677131.366950989 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 212119.35748335134
:::NVLOGv0.2.2 Tacotron2_PyT 1593677131.367333651 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2068676948547363
Batch: 3/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677131.370150805 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593677131.673116446 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020612007938325405
:::NVLOGv0.2.2 Tacotron2_PyT 1593677132.535237074 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593677132.535636902 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 219607.08368366768
:::NVLOGv0.2.2 Tacotron2_PyT 1593677132.535995245 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1657183170318604
Batch: 4/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677132.538568020 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593677132.785606146 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021991089452058077
:::NVLOGv0.2.2 Tacotron2_PyT 1593677133.646580458 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593677133.646995306 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 230920.66247583245
:::NVLOGv0.2.2 Tacotron2_PyT 1593677133.647378206 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1086058616638184
Batch: 5/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677133.650030136 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593677133.929005384 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002084402833133936
:::NVLOGv0.2.2 Tacotron2_PyT 1593677134.799961567 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593677134.800392628 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222493.8657533798
:::NVLOGv0.2.2 Tacotron2_PyT 1593677134.800794601 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1505935192108154
Batch: 6/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677134.803382635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593677135.004221439 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020895544439554214
:::NVLOGv0.2.2 Tacotron2_PyT 1593677135.874161243 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593677135.874559402 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 238943.4433531158
:::NVLOGv0.2.2 Tacotron2_PyT 1593677135.874922276 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0713832378387451
Batch: 7/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677135.877562284 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593677136.196116924 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001996842212975025
:::NVLOGv0.2.2 Tacotron2_PyT 1593677137.064540148 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593677137.064998627 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 215549.0432761536
:::NVLOGv0.2.2 Tacotron2_PyT 1593677137.065384626 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1876647472381592
Batch: 8/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677137.068073273 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593677137.369237423 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025228378362953663
:::NVLOGv0.2.2 Tacotron2_PyT 1593677138.238394260 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1593677138.238787889 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 218620.39432802246
:::NVLOGv0.2.2 Tacotron2_PyT 1593677138.239148378 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1709794998168945
Batch: 9/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677138.241961241 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593677138.507481575 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023589092306792736
:::NVLOGv0.2.2 Tacotron2_PyT 1593677139.376532078 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1593677139.377022743 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 225500.26241184946
:::NVLOGv0.2.2 Tacotron2_PyT 1593677139.377412081 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.135253667831421
Batch: 10/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677139.380102873 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593677139.689063311 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002241509035229683
:::NVLOGv0.2.2 Tacotron2_PyT 1593677140.546579123 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1593677140.546971321 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 219340.88028319346
:::NVLOGv0.2.2 Tacotron2_PyT 1593677140.547391653 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.167133092880249
Batch: 11/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677140.550100565 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593677140.767652273 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024530792143195868
:::NVLOGv0.2.2 Tacotron2_PyT 1593677141.685360193 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1593677141.685793161 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 225369.58248327163
:::NVLOGv0.2.2 Tacotron2_PyT 1593677141.686143398 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1359119415283203
Batch: 12/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677141.687974930 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593677141.896279573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002786103868857026
:::NVLOGv0.2.2 Tacotron2_PyT 1593677142.759577751 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1593677142.760022640 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 238771.7651433042
:::NVLOGv0.2.2 Tacotron2_PyT 1593677142.760409117 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0721535682678223
Batch: 13/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677142.763241053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593677142.942051172 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002203400246798992
:::NVLOGv0.2.2 Tacotron2_PyT 1593677143.805556774 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1593677143.805942774 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 245455.4279266511
:::NVLOGv0.2.2 Tacotron2_PyT 1593677143.806337357 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.042959213256836
Batch: 14/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677143.811753511 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593677144.101013660 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023730879183858633
:::NVLOGv0.2.2 Tacotron2_PyT 1593677144.984994888 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1593677144.985446453 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 217787.32558373024
:::NVLOGv0.2.2 Tacotron2_PyT 1593677144.985837936 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1754586696624756
Batch: 15/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677144.988696098 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593677145.193370104 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019913106225430965
:::NVLOGv0.2.2 Tacotron2_PyT 1593677146.058440447 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1593677146.058843374 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 239126.44501397244
:::NVLOGv0.2.2 Tacotron2_PyT 1593677146.059226513 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0705633163452148
Batch: 16/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677146.061938286 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593677146.263027430 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022463491186499596
:::NVLOGv0.2.2 Tacotron2_PyT 1593677147.134269953 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1593677147.134687662 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 238576.9007808051
:::NVLOGv0.2.2 Tacotron2_PyT 1593677147.135081530 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0730292797088623
Batch: 17/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677147.137609243 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593677147.335439205 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001992749283090234
:::NVLOGv0.2.2 Tacotron2_PyT 1593677148.194219828 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1593677148.194612741 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 242184.9122669312
:::NVLOGv0.2.2 Tacotron2_PyT 1593677148.194964170 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0570435523986816
Batch: 18/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677148.197360277 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593677148.418603420 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.003183456137776375
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.283615828 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.284008026 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235577.46460332512
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.284360886 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0866913795471191
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.338388681 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.338758230 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 226026.37674917857
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.339103460 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 228528.6522788507
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.339434147 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0022769184341948283
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.339738607 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 21.519612312316895
:::NVLOGv0.2.2 Tacotron2_PyT 1593677149.340037107 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.287822962 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0021319719962775707
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.288948059 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.290677786 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 109.1067521572113
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.291197538 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 109.1067521572113
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.291755915 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 115.40999674797058
:::NVLOGv0.2.2 Tacotron2_PyT 1593677150.292272568 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
