:::NVLOGv0.2.2 Tacotron2_PyT 1591086153.584089518 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1591086153.597644329 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 16, "name": "Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1591086153.607968569 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "62G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1591086153.900063276 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 2, "name": ["Quadro RTX 6000", "Quadro RTX 6000"], "mem": ["24220 MiB", "24220 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1591086153.904098749 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 20, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1591086154.072025776 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1591086172.573096275 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1591086172.574372292 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086172.789439917 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086178.363157511 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019038034370169044
:::NVLOGv0.2.2 Tacotron2_PyT 1591086181.705875158 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086181.706643820 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 35881.76355089505
:::NVLOGv0.2.2 Tacotron2_PyT 1591086181.707223177 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 8.918179273605347
Batch: 1/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086181.710069656 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086182.429346800 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001691160025075078
:::NVLOGv0.2.2 Tacotron2_PyT 1591086184.238187075 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086184.238938808 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 126528.39499096695
:::NVLOGv0.2.2 Tacotron2_PyT 1591086184.239505768 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.52907657623291
Batch: 2/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086184.242293358 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1591086184.913578510 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025601903907954693
:::NVLOGv0.2.2 Tacotron2_PyT 1591086186.628843069 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1591086186.629554272 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134034.7036122175
:::NVLOGv0.2.2 Tacotron2_PyT 1591086186.630108118 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.387441396713257
Batch: 3/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086186.632918596 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1591086187.222097158 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021118330769240856
:::NVLOGv0.2.2 Tacotron2_PyT 1591086188.982936621 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1591086188.983660460 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136115.27014653175
:::NVLOGv0.2.2 Tacotron2_PyT 1591086188.984210253 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3509485721588135
Batch: 4/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086188.987084150 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1591086189.649507523 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018763679545372725
:::NVLOGv0.2.2 Tacotron2_PyT 1591086191.401607752 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1591086191.402326584 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132481.92334396273
:::NVLOGv0.2.2 Tacotron2_PyT 1591086191.402885199 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.41542387008667
Batch: 5/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086191.405701399 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1591086192.056241751 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018961720634251833
:::NVLOGv0.2.2 Tacotron2_PyT 1591086193.832381010 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1591086193.833128929 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 131817.96869805505
:::NVLOGv0.2.2 Tacotron2_PyT 1591086193.833692312 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4275901317596436
Batch: 6/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086193.836501360 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1591086194.468765020 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002198493108153343
:::NVLOGv0.2.2 Tacotron2_PyT 1591086196.244131327 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1591086196.244871140 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132860.6757716013
:::NVLOGv0.2.2 Tacotron2_PyT 1591086196.245442629 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4085381031036377
Batch: 7/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086196.248241425 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1591086196.921982288 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020185746252536774
:::NVLOGv0.2.2 Tacotron2_PyT 1591086198.732953310 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1591086198.733687401 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 128742.02087148563
:::NVLOGv0.2.2 Tacotron2_PyT 1591086198.734243870 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.485590934753418
Batch: 8/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086198.737504005 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1591086199.421955824 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001735753146931529
:::NVLOGv0.2.2 Tacotron2_PyT 1591086201.204176426 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1591086201.205058098 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 129682.8234115566
:::NVLOGv0.2.2 Tacotron2_PyT 1591086201.205708742 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4675588607788086
Batch: 9/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086201.208911657 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1591086201.893625259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002067805966362357
:::NVLOGv0.2.2 Tacotron2_PyT 1591086203.625781298 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1591086203.626526833 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132353.67211726762
:::NVLOGv0.2.2 Tacotron2_PyT 1591086203.627089977 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.41776442527771
Batch: 10/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086203.630255699 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1591086204.253895760 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002057061530649662
:::NVLOGv0.2.2 Tacotron2_PyT 1591086206.058089733 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1591086206.058812141 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 131753.67084780437
:::NVLOGv0.2.2 Tacotron2_PyT 1591086206.059390545 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.428774833679199
Batch: 11/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086206.062438726 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1591086206.670750618 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021865626331418753
:::NVLOGv0.2.2 Tacotron2_PyT 1591086208.414513588 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1591086208.415162325 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136001.0278779468
:::NVLOGv0.2.2 Tacotron2_PyT 1591086208.415668726 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3529233932495117
Batch: 12/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086208.418775320 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1591086209.113428593 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001835504313930869
:::NVLOGv0.2.2 Tacotron2_PyT 1591086210.895635605 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1591086210.896341562 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 129152.0861321009
:::NVLOGv0.2.2 Tacotron2_PyT 1591086210.896898031 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.477699041366577
Batch: 13/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086210.899719000 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1591086211.595656395 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002136622555553913
:::NVLOGv0.2.2 Tacotron2_PyT 1591086213.304558039 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1591086213.305175781 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133028.09763131247
:::NVLOGv0.2.2 Tacotron2_PyT 1591086213.305653811 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4055068492889404
Batch: 14/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086213.308503866 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1591086214.031563282 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017233884427696466
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.709234476 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.709919930 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133254.97413735502
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.710530519 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.401411294937134
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.859539509 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.860243559 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 110889.90759122593
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.860835791 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 125579.27154273729
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.861393929 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.001999952884701391
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.861930847 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 43.28617548942566
:::NVLOGv0.2.2 Tacotron2_PyT 1591086215.862467289 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1591086218.474810362 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.002205109689384699
:::NVLOGv0.2.2 Tacotron2_PyT 1591086218.475899696 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086221.878733635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086222.067744017 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086222.807710648 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001956958556547761
:::NVLOGv0.2.2 Tacotron2_PyT 1591086224.561731100 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1591086224.562545061 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 128226.58447109842
:::NVLOGv0.2.2 Tacotron2_PyT 1591086224.563167334 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.495582342147827
Batch: 1/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086224.566721439 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086225.190849543 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017152699874714017
:::NVLOGv0.2.2 Tacotron2_PyT 1591086227.014240026 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086227.014913082 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 130687.41654198476
:::NVLOGv0.2.2 Tacotron2_PyT 1591086227.015413046 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4485907554626465
Batch: 2/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086227.018258572 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1591086227.632678032 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001878639915958047
:::NVLOGv0.2.2 Tacotron2_PyT 1591086229.367097855 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1591086229.367757082 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136188.04211814853
:::NVLOGv0.2.2 Tacotron2_PyT 1591086229.368259907 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3496923446655273
Batch: 3/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086229.371145964 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1591086230.057106972 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018607339588925242
:::NVLOGv0.2.2 Tacotron2_PyT 1591086231.822167397 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1591086231.822814941 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 130513.08789741431
:::NVLOGv0.2.2 Tacotron2_PyT 1591086231.823313951 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4518613815307617
Batch: 4/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086231.826186180 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1591086232.509430170 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018958637956529856
:::NVLOGv0.2.2 Tacotron2_PyT 1591086234.252697706 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1591086234.253315687 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 131831.47287577027
:::NVLOGv0.2.2 Tacotron2_PyT 1591086234.253826380 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4273414611816406
Batch: 5/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086234.256569862 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1591086234.891342878 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0026844742242246866
:::NVLOGv0.2.2 Tacotron2_PyT 1591086236.673031092 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1591086236.673822641 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132375.57624343867
:::NVLOGv0.2.2 Tacotron2_PyT 1591086236.674421072 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4173643589019775
Batch: 6/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086236.677625656 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1591086237.326927900 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018656722968444228
:::NVLOGv0.2.2 Tacotron2_PyT 1591086239.059639454 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1591086239.060282230 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134291.104659586
:::NVLOGv0.2.2 Tacotron2_PyT 1591086239.060810804 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.382883071899414
Batch: 7/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086239.063879728 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1591086239.668579102 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002334833610802889
:::NVLOGv0.2.2 Tacotron2_PyT 1591086241.397347689 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1591086241.398143053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137078.59949504136
:::NVLOGv0.2.2 Tacotron2_PyT 1591086241.398754835 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3344271183013916
Batch: 8/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086241.402051210 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1591086242.036466360 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002356750424951315
:::NVLOGv0.2.2 Tacotron2_PyT 1591086243.698453903 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1591086243.699297905 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139287.03796045954
:::NVLOGv0.2.2 Tacotron2_PyT 1591086243.699976444 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2974140644073486
Batch: 9/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086243.703095913 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1591086244.363962412 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002001372631639242
:::NVLOGv0.2.2 Tacotron2_PyT 1591086246.147306442 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1591086246.148324251 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 130867.51950078004
:::NVLOGv0.2.2 Tacotron2_PyT 1591086246.149069786 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.445220947265625
Batch: 10/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086246.152166843 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1591086246.773005009 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002215511631220579
:::NVLOGv0.2.2 Tacotron2_PyT 1591086248.570630074 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1591086248.571712971 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132266.8970815646
:::NVLOGv0.2.2 Tacotron2_PyT 1591086248.572705746 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4193506240844727
Batch: 11/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086248.577299356 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1591086249.323413610 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020927537698298693
:::NVLOGv0.2.2 Tacotron2_PyT 1591086251.122273207 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1591086251.123072863 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 125675.54840720729
:::NVLOGv0.2.2 Tacotron2_PyT 1591086251.123651028 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.546239137649536
Batch: 12/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086251.126626253 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1591086251.741872549 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0012316606007516384
:::NVLOGv0.2.2 Tacotron2_PyT 1591086253.478423119 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1591086253.479286432 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136016.53304790525
:::NVLOGv0.2.2 Tacotron2_PyT 1591086253.479949236 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3526551723480225
Batch: 13/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086253.482908249 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1591086254.196249485 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001950023346580565
:::NVLOGv0.2.2 Tacotron2_PyT 1591086255.925427437 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1591086255.926204920 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 130970.03777918206
:::NVLOGv0.2.2 Tacotron2_PyT 1591086255.926808596 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4433069229125977
Batch: 14/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086255.929806232 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1591086256.568971872 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002740373369306326
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.225769043 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.226493835 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139329.1574709804
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.227045536 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.296719551086426
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.271520853 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.272192001 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 131891.59290557046
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.272751331 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 133040.30770337075
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.273272991 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002052059474711617
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.273796082 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 36.39352512359619
:::NVLOGv0.2.2 Tacotron2_PyT 1591086258.274301529 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.175732374 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.002589614363387227
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.176813841 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.178417206 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 106.10568809509277
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.178941727 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 106.10568809509277
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.179494381 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 106.72777557373047
:::NVLOGv0.2.2 Tacotron2_PyT 1591086260.179962873 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
