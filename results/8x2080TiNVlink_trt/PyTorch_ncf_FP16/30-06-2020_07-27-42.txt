:::NVLOGv0.1.0 ncf 1593502063.789167166 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.799355507 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.802655697 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.812921286 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.827767134 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.841056347 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.841582060 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.850879192 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.859456301 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.863546848 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.872199059 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.875242949 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.875673294 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.887521505 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502063.924090624 (ncf.py:171) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.1.0 ncf 1593502063.935458422 (ncf.py:171) mem_info: {"ram": "754G"}
:::NVLOGv0.1.0 ncf 1593502066.926218748 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502066.926996231 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.094559193 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.121102571 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.391381741 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.391565800 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.392412424 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502067.614206791 (ncf.py:171) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.1.0 ncf 1593502070.379150867 (ncf.py:174) args: {"data": "/data/ncf/cache/ml-20m", "epochs": 2, "batch_size": 11200000, "valid_batch_size": 1048576, "factors": 64, "layers": [256, 256, 128, 64], "negative_samples": 4, "learning_rate": 0.0045, "topk": 10, "seed": 1, "threshold": 1.0, "beta1": 0.25, "beta2": 0.5, "eps": 1e-08, "dropout": 0.5, "checkpoint_dir": "/data/checkpoints/", "load_checkpoint_path": null, "mode": "train", "grads_accumulated": 1, "opt_level": "O2", "local_rank": 0, "distributed": true, "world_size": 8}
Saving results to /data/checkpoints/
:::NVLOGv0.1.0 ncf 1593502070.381233931 (ncf.py:184) preproc_hp_sample_eval_replacement: true
:::NVLOGv0.1.0 ncf 1593502070.382153511 (ncf.py:185) input_hp_sample_train_replacement: true
:::NVLOGv0.1.0 ncf 1593502070.382996082 (ncf.py:186) input_step_eval_neg_gen
:::NVLOGv0.1.0 ncf 1593502074.327627420 (ncf.py:194) run_start
:::NVLOGv0.1.0 ncf 1593502074.716229916 (ncf.py:201) preproc_hp_num_eval: 100
:::NVLOGv0.1.0 ncf 1593502075.350887537 (ncf.py:207) input_size: 19861770
:::NVLOGv0.1.0 ncf 1593502075.427515984 (ncf.py:216) input_batch_size: 11200000
:::NVLOGv0.1.0 ncf 1593502075.428448915 (ncf.py:217) input_order
:::NVLOGv0.1.0 ncf 1593502075.430194378 (/workspace/examples/ncf/neumf.py:54) model_hp_mf_dim: 64
:::NVLOGv0.1.0 ncf 1593502075.752710104 (/workspace/examples/ncf/neumf.py:62) model_hp_mlp_layer_sizes: [256, 256, 128, 64]
Selected optimization level O2:  FP16 training with FP32 batchnorm and FP32 master weights.

Defaults for this optimization level are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : True
master_weights         : True
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O2
cast_model_type        : torch.float16
patch_torch_functions  : False
keep_batchnorm_fp32    : False
master_weights         : True
loss_scale             : dynamic
DistributedDataParallel(
  (module): NeuMF(
    (mf_user_embed): Embedding(138493, 64)
    (mf_item_embed): Embedding(26744, 64)
    (mlp_user_embed): Embedding(138493, 128)
    (mlp_item_embed): Embedding(26744, 128)
    (mlp): ModuleList(
      (0): Linear(in_features=256, out_features=256, bias=True)
      (1): Linear(in_features=256, out_features=128, bias=True)
      (2): Linear(in_features=128, out_features=64, bias=True)
    )
    (final): Linear(in_features=128, out_features=1, bias=True)
  )
)
31832577 parameters
:::NVLOGv0.1.0 ncf 1593502076.361162186 (ncf.py:246) opt_learning_rate: 0.0045
:::NVLOGv0.1.0 ncf 1593502076.361528873 (ncf.py:247) opt_name: "Adam"
:::NVLOGv0.1.0 ncf 1593502076.361818075 (ncf.py:248) opt_hp_Adam_beta1: 0.25
:::NVLOGv0.1.0 ncf 1593502076.362098932 (ncf.py:249) opt_hp_Adam_beta2: 0.5
:::NVLOGv0.1.0 ncf 1593502076.362380743 (ncf.py:250) opt_hp_Adam_epsilon: 1e-08
:::NVLOGv0.1.0 ncf 1593502076.362653255 (ncf.py:251) model_hp_loss_fn: "binary_cross_entropy"
:::NVLOGv0.1.0 ncf 1593502076.362925053 (ncf.py:279) train_loop
:::NVLOGv0.1.0 ncf 1593502076.363228321 (ncf.py:282) train_epoch_start: 0
:::NVLOGv0.1.0 ncf 1593502076.363521338 (ncf.py:283) input_hp_num_neg: 4
:::NVLOGv0.1.0 ncf 1593502076.363792419 (ncf.py:284) input_step_train_neg_gen
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0
Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0
:::NVLOGv0.1.0 ncf 1593502077.803148031 (ncf.py:318) train_throughput: 69013152.89380996
:::NVLOGv0.1.0 ncf 1593502077.803501844 (ncf.py:319) train_epoch_stop: 0
:::NVLOGv0.1.0 ncf 1593502077.803789616 (ncf.py:320) eval_start: 0
../aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
:::NVLOGv0.1.0 ncf 1593502077.846680641 (ncf.py:155) eval_size: {"epoch": 0, "value": 13987793}
:::NVLOGv0.1.0 ncf 1593502077.847063065 (ncf.py:156) eval_hp_num_users: 138493
:::NVLOGv0.1.0 ncf 1593502077.847389698 (ncf.py:157) eval_hp_num_neg: 100
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
Epoch 0: HR@10 = 0.8326, NDCG@10 = 0.4915, train_time = 1.44, val_time = 0.05
:::NVLOGv0.1.0 ncf 1593502077.850965261 (ncf.py:333) eval_accuracy: {"epoch": 0, "value": 0.8325835962828446}
:::NVLOGv0.1.0 ncf 1593502077.851294756 (ncf.py:334) eval_target: 1.0
:::NVLOGv0.1.0 ncf 1593502077.851588964 (ncf.py:335) eval_stop: 0
:::NVLOGv0.1.0 ncf 1593502077.851879358 (ncf.py:340) eval_throughput: 292478083.1388533
New best hr! Saving the model to:  /data/checkpoints/model.pth
:::NVLOGv0.1.0 ncf 1593502078.104869843 (ncf.py:282) train_epoch_start: 1
:::NVLOGv0.1.0 ncf 1593502078.105544806 (ncf.py:283) input_hp_num_neg: 4
:::NVLOGv0.1.0 ncf 1593502078.105957031 (ncf.py:284) input_step_train_neg_gen
:::NVLOGv0.1.0 ncf 1593502079.013122797 (ncf.py:318) train_throughput: 109538376.50118025
:::NVLOGv0.1.0 ncf 1593502079.013612986 (ncf.py:319) train_epoch_stop: 1
:::NVLOGv0.1.0 ncf 1593502079.014024496 (ncf.py:320) eval_start: 1
../aten/src/ATen/native/IndexingUtils.h:20: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead.
:::NVLOGv0.1.0 ncf 1593502079.056326151 (ncf.py:155) eval_size: {"epoch": 1, "value": 13987793}
:::NVLOGv0.1.0 ncf 1593502079.056835175 (ncf.py:156) eval_hp_num_users: 138493
:::NVLOGv0.1.0 ncf 1593502079.057292700 (ncf.py:157) eval_hp_num_neg: 100
Epoch 1: HR@10 = 0.8336, NDCG@10 = 0.5429, train_time = 0.91, val_time = 0.05
:::NVLOGv0.1.0 ncf 1593502079.058666229 (ncf.py:333) eval_accuracy: {"epoch": 1, "value": 0.8335872571176882}
:::NVLOGv0.1.0 ncf 1593502079.059093952 (ncf.py:334) eval_target: 1.0
:::NVLOGv0.1.0 ncf 1593502079.059499979 (ncf.py:335) eval_stop: 1
:::NVLOGv0.1.0 ncf 1593502079.059904575 (ncf.py:340) eval_throughput: 306732626.12247545
New best hr! Saving the model to:  /data/checkpoints/model.pth
:::NVLOGv0.1.0 ncf 1593502079.365855217 (ncf.py:356) best_train_throughput: 109538376.50118025
:::NVLOGv0.1.0 ncf 1593502079.366366386 (ncf.py:357) best_eval_throughput: 306732626.12247545
:::NVLOGv0.1.0 ncf 1593502079.367022038 (ncf.py:358) best_accuracy: 0.8335872571176882
:::NVLOGv0.1.0 ncf 1593502079.367436171 (ncf.py:359) time_to_target: 5.039829730987549
:::NVLOGv0.1.0 ncf 1593502079.367857695 (ncf.py:360) time_to_best_model: 5.038027048110962
:::NVLOGv0.1.0 ncf 1593502079.368286610 (ncf.py:362) run_stop: {"success": false}
:::NVLOGv0.1.0 ncf 1593502079.368677378 (ncf.py:363) run_final
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
