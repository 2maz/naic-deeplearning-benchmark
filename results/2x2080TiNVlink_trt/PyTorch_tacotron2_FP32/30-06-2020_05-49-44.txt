:::NVLOGv0.2.2 Tacotron2_PyT 1593496186.749582052 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593496186.776910782 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593496186.795365095 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593496187.065795660 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 2, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1593496187.074880600 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "Tacotron2", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": false, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 1e-06, "grad_clip_thresh": 1.0, "batch_size": 36, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "mask_padding": false, "n_mel_channels": 80, "n_symbols": 148, "symbols_embedding_dim": 512, "encoder_kernel_size": 5, "encoder_n_convolutions": 3, "encoder_embedding_dim": 512, "n_frames_per_step": 1, "decoder_rnn_dim": 1024, "prenet_dim": 256, "max_decoder_steps": 2000, "gate_threshold": 0.5, "p_attention_dropout": 0.1, "p_decoder_dropout": 0.1, "decoder_no_early_stopping": false, "attention_rnn_dim": 1024, "attention_dim": 128, "attention_location_n_filters": 32, "attention_location_kernel_size": 31, "postnet_embedding_dim": 512, "postnet_kernel_size": 5, "postnet_n_convolutions": 5}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1593496187.267538548 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593496196.496479750 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1593496196.497600079 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496197.275785923 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496201.512748003 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 44.34223937988281
:::NVLOGv0.2.2 Tacotron2_PyT 1593496203.256740570 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496203.257206678 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 6319.061279155052
:::NVLOGv0.2.2 Tacotron2_PyT 1593496203.257533073 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.9831671714782715
Batch: 1/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496203.263047695 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496204.221529484 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.394039154052734
:::NVLOGv0.2.2 Tacotron2_PyT 1593496205.712310314 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496205.713895082 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16444.79842025779
:::NVLOGv0.2.2 Tacotron2_PyT 1593496205.714302063 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.45001482963562
Batch: 2/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496205.719377041 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593496206.670461893 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.25709533691406
:::NVLOGv0.2.2 Tacotron2_PyT 1593496208.213351965 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593496208.215169191 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16232.869345416399
:::NVLOGv0.2.2 Tacotron2_PyT 1593496208.216351271 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.49481463432312
Batch: 3/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496208.223475218 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593496209.219510317 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.61220932006836
:::NVLOGv0.2.2 Tacotron2_PyT 1593496210.692103148 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593496210.694308519 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16577.918189196185
:::NVLOGv0.2.2 Tacotron2_PyT 1593496210.696172953 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.469731092453003
Batch: 4/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496210.704050541 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593496211.699498415 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.120662689208984
:::NVLOGv0.2.2 Tacotron2_PyT 1593496213.164633512 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593496213.166362047 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16899.52694575402
:::NVLOGv0.2.2 Tacotron2_PyT 1593496213.167931557 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4617257118225098
Batch: 5/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496213.173977852 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593496214.027774572 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.36920166015625
:::NVLOGv0.2.2 Tacotron2_PyT 1593496215.503168106 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593496215.504656315 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17684.768897388385
:::NVLOGv0.2.2 Tacotron2_PyT 1593496215.506501198 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3299710750579834
Batch: 6/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496215.513727427 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593496216.493282080 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.688934326171875
:::NVLOGv0.2.2 Tacotron2_PyT 1593496218.038748980 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593496218.040992022 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16651.319276950344
:::NVLOGv0.2.2 Tacotron2_PyT 1593496218.042102814 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.525625705718994
Batch: 7/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496218.047504425 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593496218.899290085 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.2726936340332
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.318819046 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.320369005 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17698.08886165363
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.321614504 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.271770715713501
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.434298992 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.435286283 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 13560.65126092851
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.435677767 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 15563.543901971478
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.436063290 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.882134437561035
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.436433315 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 23.937419652938843
:::NVLOGv0.2.2 Tacotron2_PyT 1593496220.436794281 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593496222.796741486 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 49.997840881347656
:::NVLOGv0.2.2 Tacotron2_PyT 1593496222.797710896 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496223.478827238 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496224.387828588 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496225.359360933 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.257049560546875
:::NVLOGv0.2.2 Tacotron2_PyT 1593496226.906481266 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593496226.908271790 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15731.662344932769
:::NVLOGv0.2.2 Tacotron2_PyT 1593496226.909903765 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.521221160888672
Batch: 1/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496226.917022943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496227.889052629 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.03998565673828
:::NVLOGv0.2.2 Tacotron2_PyT 1593496229.472290516 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496229.473846197 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15574.190564390685
:::NVLOGv0.2.2 Tacotron2_PyT 1593496229.474680424 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.556152105331421
Batch: 2/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496229.482350588 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593496230.432695389 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.820884704589844
:::NVLOGv0.2.2 Tacotron2_PyT 1593496231.988577604 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593496231.989883661 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16315.594675119184
:::NVLOGv0.2.2 Tacotron2_PyT 1593496231.991753101 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.507171869277954
Batch: 3/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496231.999963045 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593496232.934352398 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.20598602294922
:::NVLOGv0.2.2 Tacotron2_PyT 1593496234.512867689 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593496234.515415668 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15998.4765487599
:::NVLOGv0.2.2 Tacotron2_PyT 1593496234.516802549 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5137393474578857
Batch: 4/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496234.524862766 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593496235.448272467 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 50.488826751708984
:::NVLOGv0.2.2 Tacotron2_PyT 1593496236.892767668 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593496236.893747807 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17863.53544161521
:::NVLOGv0.2.2 Tacotron2_PyT 1593496236.895319700 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3687360286712646
Batch: 5/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496236.901107311 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593496237.795296192 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.550071716308594
:::NVLOGv0.2.2 Tacotron2_PyT 1593496239.340255976 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593496239.341501236 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16478.785421445602
:::NVLOGv0.2.2 Tacotron2_PyT 1593496239.343389511 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4398036003112793
Batch: 6/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496239.351703405 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593496240.253505230 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.188018798828125
:::NVLOGv0.2.2 Tacotron2_PyT 1593496241.792739391 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593496241.794211626 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16583.98760332273
:::NVLOGv0.2.2 Tacotron2_PyT 1593496241.796145678 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4417529106140137
Batch: 7/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496241.804289579 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593496242.721009493 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.31569290161133
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.299405098 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.300574780 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16398.66711209014
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.302138567 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4957516193389893
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.431686401 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.433575630 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 15488.212800549129
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.435147047 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 16368.112463959527
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.435942888 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.483314514160156
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.436660051 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 20.953676462173462
:::NVLOGv0.2.2 Tacotron2_PyT 1593496244.437345505 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.798005342 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.01448440551758
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.798982859 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.800166607 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 59.53195929527283
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.800552845 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 59.53195929527283
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.800943375 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 60.129777669906616
:::NVLOGv0.2.2 Tacotron2_PyT 1593496246.801276684 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
