:::NVLOGv0.2.2 Tacotron2_PyT 1593034566.661527634 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593034566.688503742 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593034566.709592819 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "692G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593034566.993352175 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 2, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1593034567.002347469 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "Tacotron2", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": false, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 1e-06, "grad_clip_thresh": 1.0, "batch_size": 36, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "mask_padding": false, "n_mel_channels": 80, "n_symbols": 148, "symbols_embedding_dim": 512, "encoder_kernel_size": 5, "encoder_n_convolutions": 3, "encoder_embedding_dim": 512, "n_frames_per_step": 1, "decoder_rnn_dim": 1024, "prenet_dim": 256, "max_decoder_steps": 2000, "gate_threshold": 0.5, "p_attention_dropout": 0.1, "p_decoder_dropout": 0.1, "decoder_no_early_stopping": false, "attention_rnn_dim": 1024, "attention_dim": 128, "attention_location_n_filters": 32, "attention_location_kernel_size": 31, "postnet_embedding_dim": 512, "postnet_kernel_size": 5, "postnet_n_convolutions": 5}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1593034567.202990055 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593034576.923382998 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1593034576.925671101 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034577.706912518 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034581.667811155 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 44.326194763183594
:::NVLOGv0.2.2 Tacotron2_PyT 1593034583.185895920 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034583.186671257 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 6898.529616914209
:::NVLOGv0.2.2 Tacotron2_PyT 1593034583.187195063 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.48058819770813
Batch: 1/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034583.194691181 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034584.142910480 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.36698913574219
:::NVLOGv0.2.2 Tacotron2_PyT 1593034585.581226349 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034585.582154751 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16874.438565726963
:::NVLOGv0.2.2 Tacotron2_PyT 1593034585.582505465 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3876349925994873
Batch: 2/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034585.587922573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593034586.486767530 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.21934127807617
:::NVLOGv0.2.2 Tacotron2_PyT 1593034587.935596943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593034587.936792135 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17243.849959626506
:::NVLOGv0.2.2 Tacotron2_PyT 1593034587.937515736 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3485474586486816
Batch: 3/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034587.943135500 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593034588.921737432 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.56990051269531
:::NVLOGv0.2.2 Tacotron2_PyT 1593034590.361267567 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593034590.362281799 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16926.33376343874
:::NVLOGv0.2.2 Tacotron2_PyT 1593034590.363582373 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.418893575668335
Batch: 4/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034590.378865242 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593034591.437873602 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.074554443359375
:::NVLOGv0.2.2 Tacotron2_PyT 1593034592.874425650 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593034592.875801802 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16661.123985758004
:::NVLOGv0.2.2 Tacotron2_PyT 1593034592.876554012 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.496950387954712
Batch: 5/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034592.884406328 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593034593.797711134 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.34564208984375
:::NVLOGv0.2.2 Tacotron2_PyT 1593034595.264981031 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593034595.265916586 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17301.730742739986
:::NVLOGv0.2.2 Tacotron2_PyT 1593034595.267169714 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3815536499023438
Batch: 6/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034595.274470329 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593034596.279477835 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.654335021972656
:::NVLOGv0.2.2 Tacotron2_PyT 1593034597.747479439 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593034597.748730183 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17000.486495764948
:::NVLOGv0.2.2 Tacotron2_PyT 1593034597.750203848 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.473752737045288
Batch: 7/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034597.755797148 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593034598.648917437 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.21065139770508
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.029970407 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.031720638 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17676.011695109573
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.033928633 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2746081352233887
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.153071880 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.154819250 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 13974.75209632248
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.155493259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 15822.813103134868
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.156023264 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.845951080322266
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.156542063 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 23.22810435295105
:::NVLOGv0.2.2 Tacotron2_PyT 1593034600.157052517 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593034602.684889078 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.025360107421875
:::NVLOGv0.2.2 Tacotron2_PyT 1593034602.685856819 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034603.400563955 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034604.320428371 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034605.341953516 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.244171142578125
:::NVLOGv0.2.2 Tacotron2_PyT 1593034606.990676403 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593034606.992578268 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 14847.405864861117
:::NVLOGv0.2.2 Tacotron2_PyT 1593034606.994348764 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.6713757514953613
Batch: 1/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034607.002017498 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034608.015286446 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.018280029296875
:::NVLOGv0.2.2 Tacotron2_PyT 1593034609.694313288 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034609.696082830 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 14782.284182062589
:::NVLOGv0.2.2 Tacotron2_PyT 1593034609.698083162 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.6930885314941406
Batch: 2/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034609.705430746 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593034610.665789843 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.80072021484375
:::NVLOGv0.2.2 Tacotron2_PyT 1593034612.293509483 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593034612.294882059 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15801.081096533266
:::NVLOGv0.2.2 Tacotron2_PyT 1593034612.296031237 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5888102054595947
Batch: 3/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034612.302120686 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593034613.276268482 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.175926208496094
:::NVLOGv0.2.2 Tacotron2_PyT 1593034614.891770363 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593034614.893462896 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15525.474252351949
:::NVLOGv0.2.2 Tacotron2_PyT 1593034614.894534588 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5903234481811523
Batch: 4/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034614.900470018 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593034615.876037359 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 50.449684143066406
:::NVLOGv0.2.2 Tacotron2_PyT 1593034617.410598993 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593034617.412139416 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16853.102356719537
:::NVLOGv0.2.2 Tacotron2_PyT 1593034617.413777828 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.510754346847534
Batch: 5/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034617.420838356 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593034618.413492203 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.52167510986328
:::NVLOGv0.2.2 Tacotron2_PyT 1593034620.041801453 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593034620.043516397 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15334.471984069723
:::NVLOGv0.2.2 Tacotron2_PyT 1593034620.045623779 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.621870517730713
Batch: 6/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034620.052866697 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593034621.002953291 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.16236877441406
:::NVLOGv0.2.2 Tacotron2_PyT 1593034622.600973368 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593034622.602856398 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15887.155512410929
:::NVLOGv0.2.2 Tacotron2_PyT 1593034622.604353428 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.548851490020752
Batch: 7/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034622.611349344 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593034623.562384129 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.282676696777344
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.129030466 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.130313873 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16251.839269325466
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.131697416 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5182995796203613
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.250570059 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.251487017 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 14852.498100281275
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.252399206 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 15660.351814791822
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.252778292 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.45693778991699
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.253099680 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 21.85053300857544
:::NVLOGv0.2.2 Tacotron2_PyT 1593034625.253414392 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.613464832 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.05854797363281
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.614448547 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.615541220 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 60.41194152832031
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.615876675 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 60.41194152832031
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.616228342 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 61.03146982192993
:::NVLOGv0.2.2 Tacotron2_PyT 1593034627.616528988 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
