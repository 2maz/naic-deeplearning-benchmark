Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  3%|▎         | 2.77M/97.8M [00:00<00:03, 29.0MB/s]  7%|▋         | 6.55M/97.8M [00:00<00:03, 31.1MB/s] 10%|█         | 9.85M/97.8M [00:00<00:02, 31.5MB/s] 13%|█▎        | 12.7M/97.8M [00:00<00:02, 30.3MB/s] 18%|█▊        | 17.8M/97.8M [00:00<00:02, 34.8MB/s] 21%|██▏       | 20.9M/97.8M [00:00<00:03, 26.7MB/s] 25%|██▍       | 24.2M/97.8M [00:00<00:02, 28.7MB/s] 28%|██▊       | 27.1M/97.8M [00:01<00:04, 17.7MB/s] 30%|███       | 29.3M/97.8M [00:01<00:03, 18.1MB/s] 34%|███▎      | 32.8M/97.8M [00:01<00:03, 21.3MB/s] 36%|███▋      | 35.4M/97.8M [00:01<00:02, 22.9MB/s] 39%|███▉      | 38.1M/97.8M [00:01<00:02, 22.9MB/s] 43%|████▎     | 41.7M/97.8M [00:01<00:02, 25.9MB/s] 45%|████▌     | 44.4M/97.8M [00:01<00:02, 26.6MB/s] 50%|████▉     | 48.5M/97.8M [00:01<00:01, 30.0MB/s] 53%|█████▎    | 51.7M/97.8M [00:02<00:02, 20.1MB/s] 55%|█████▌    | 54.2M/97.8M [00:02<00:02, 18.4MB/s] 58%|█████▊    | 56.4M/97.8M [00:02<00:02, 17.7MB/s] 62%|██████▏   | 60.3M/97.8M [00:02<00:01, 21.3MB/s] 64%|██████▍   | 62.9M/97.8M [00:02<00:01, 21.6MB/s] 67%|██████▋   | 65.3M/97.8M [00:02<00:01, 22.1MB/s] 69%|██████▉   | 67.7M/97.8M [00:02<00:01, 21.9MB/s] 72%|███████▏  | 70.0M/97.8M [00:03<00:01, 16.9MB/s] 74%|███████▎  | 72.0M/97.8M [00:03<00:01, 17.7MB/s] 76%|███████▌  | 73.9M/97.8M [00:03<00:01, 16.4MB/s] 78%|███████▊  | 76.0M/97.8M [00:03<00:01, 17.7MB/s] 83%|████████▎ | 80.8M/97.8M [00:03<00:00, 21.6MB/s] 85%|████████▌ | 83.4M/97.8M [00:03<00:00, 22.4MB/s] 88%|████████▊ | 85.9M/97.8M [00:03<00:00, 22.0MB/s] 91%|█████████ | 89.1M/97.8M [00:03<00:00, 24.5MB/s] 95%|█████████▍| 92.4M/97.8M [00:04<00:00, 23.7MB/s] 98%|█████████▊| 95.7M/97.8M [00:04<00:00, 24.9MB/s]100%|██████████| 97.8M/97.8M [00:04<00:00, 23.8MB/s]
DLL 2020-10-28 04:53:19.317581 - PARAMETER dataset path : /data/object_detection  epochs : 1  batch size : 32  eval batch size : 32  no cuda : False  seed : None  checkpoint path : None  mode : benchmark-training  eval on epochs : [21, 31, 37, 42, 48, 53, 59, 64]  lr decay epochs : [43, 54]  learning rate : 0.0  momentum : 0.9  weight decay : 0.0005  lr warmup : None  backbone : resnet50  backbone path : None  num workers : 4  AMP : False  precision : fp32 
Using seed = 6389
loading annotations into memory...
Done (t=0.49s)
creating index...
index created!
/workspace/examples/ssd/src/coco_pipeline.py:63: DeprecationWarning: Argument 'output_dtype' for operator 'CropMirrorNormalize' is now deprecated. Use 'dtype' instead.
  pad_output=pad_output)
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:44: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Traceback (most recent call last):
  File "main.py", line 287, in <module>
    train(train_loop_func, logger, args)
  File "main.py", line 206, in train
    logger, args, mean, std)
  File "/workspace/examples/ssd/src/train.py", line 139, in benchmark_train_loop
    loss.backward()
  File "/opt/conda/lib/python3.6/site-packages/torch/tensor.py", line 214, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/opt/conda/lib/python3.6/site-packages/torch/autograd/__init__.py", line 132, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA out of memory. Tried to allocate 182.00 MiB (GPU 0; 9.78 GiB total capacity; 7.82 GiB already allocated; 11.69 MiB free; 8.23 GiB reserved in total by PyTorch)
Traceback (most recent call last):
  File "/opt/conda/lib/python3.6/runpy.py", line 193, in _run_module_as_main
    "__main__", mod_spec)
  File "/opt/conda/lib/python3.6/runpy.py", line 85, in _run_code
    exec(code, run_globals)
  File "/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py", line 261, in <module>
    main()
  File "/opt/conda/lib/python3.6/site-packages/torch/distributed/launch.py", line 257, in main
    cmd=cmd)
subprocess.CalledProcessError: Command '['/opt/conda/bin/python', '-u', 'main.py', '--local_rank=0', '--mode', 'benchmark-training', '--data', '/data/object_detection', '--batch-size', '32', '--benchmark-warmup', '50', '--benchmark-iterations', '200', '--learning-rate', '0']' returned non-zero exit status 1.
DONE!
