:::NVLOGv0.2.2 Tacotron2_PyT 1583711236.814595222 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583711236.840262413 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583711236.853334665 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583711237.987220526 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.33.01", "num": 2, "name": ["Tesla V100-SXM2-32GB", "Tesla V100-SXM2-32GB"], "mem": ["32510 MiB", "32510 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583711237.994167805 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 30, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1583711238.260147572 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1583711253.422211647 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583711253.423382282 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711253.770632505 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711257.618511915 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002020189305767417
:::NVLOGv0.2.2 Tacotron2_PyT 1583711260.887889624 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711260.888791084 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 67429.2744262185
:::NVLOGv0.2.2 Tacotron2_PyT 1583711260.889502764 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 7.118569850921631
Batch: 1/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711260.892958879 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711261.670283079 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022330512292683125
:::NVLOGv0.2.2 Tacotron2_PyT 1583711263.525995970 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711263.526997328 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 182204.3048656423
:::NVLOGv0.2.2 Tacotron2_PyT 1583711263.527682066 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.6344053745269775
Batch: 2/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711263.533741713 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583711264.200991631 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024136542342603207
:::NVLOGv0.2.2 Tacotron2_PyT 1583711266.007432699 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583711266.008167267 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 193872.56041009657
:::NVLOGv0.2.2 Tacotron2_PyT 1583711266.008693933 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.475853204727173
Batch: 3/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711266.012058258 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583711266.686252117 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020702106412500143
:::NVLOGv0.2.2 Tacotron2_PyT 1583711268.503829479 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583711268.504609585 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 192565.0921297
:::NVLOGv0.2.2 Tacotron2_PyT 1583711268.505113602 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.492663621902466
Batch: 4/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711268.508494377 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583711269.150586128 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002194242551922798
:::NVLOGv0.2.2 Tacotron2_PyT 1583711270.960561991 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583711270.961106062 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195694.99874316834
:::NVLOGv0.2.2 Tacotron2_PyT 1583711270.961597681 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.452796459197998
Batch: 5/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711270.964289188 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583711271.597089291 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002034157980233431
:::NVLOGv0.2.2 Tacotron2_PyT 1583711273.415158987 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583711273.415837526 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195787.41365048327
:::NVLOGv0.2.2 Tacotron2_PyT 1583711273.416313171 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.451638698577881
Batch: 6/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711273.419360161 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583711274.099103451 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0016578661743551493
:::NVLOGv0.2.2 Tacotron2_PyT 1583711275.947166204 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583711275.947913647 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 189822.40513669085
:::NVLOGv0.2.2 Tacotron2_PyT 1583711275.948451519 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.528679370880127
Batch: 7/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711275.951224804 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583711276.626738787 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002133110072463751
:::NVLOGv0.2.2 Tacotron2_PyT 1583711278.432549238 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583711278.433104992 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 193390.44754321387
:::NVLOGv0.2.2 Tacotron2_PyT 1583711278.433607101 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.482025384902954
Batch: 8/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711278.436429977 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583711279.096045256 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022794404067099094
:::NVLOGv0.2.2 Tacotron2_PyT 1583711280.941208601 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583711280.942199707 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 191567.10980731162
:::NVLOGv0.2.2 Tacotron2_PyT 1583711280.942871809 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5056493282318115
Batch: 9/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711280.946117401 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583711281.632139683 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019920466002076864
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.394246340 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.394799471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 196022.13501541535
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.395267487 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4487030506134033
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.622838736 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.623373508 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 158939.80359150827
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.623883963 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 179835.57417279406
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.624362707 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002102796919643879
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.624865532 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 30.20011281967163
:::NVLOGv0.2.2 Tacotron2_PyT 1583711283.625321627 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1583711285.857091904 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.001851110951974988
:::NVLOGv0.2.2 Tacotron2_PyT 1583711285.858361244 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711289.083506107 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711289.394013882 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711290.102152348 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021400467958301306
:::NVLOGv0.2.2 Tacotron2_PyT 1583711292.003826141 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583711292.004696369 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 183690.60405697324
:::NVLOGv0.2.2 Tacotron2_PyT 1583711292.005186558 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.6130895614624023
Batch: 1/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711292.008955240 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711292.687121153 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021101695019751787
:::NVLOGv0.2.2 Tacotron2_PyT 1583711294.550745010 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711294.551510334 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 188761.31738559323
:::NVLOGv0.2.2 Tacotron2_PyT 1583711294.552022696 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.542893886566162
Batch: 2/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711294.555888176 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583711295.195236206 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020066688302904367
:::NVLOGv0.2.2 Tacotron2_PyT 1583711297.050120592 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583711297.050889015 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 192355.44195588466
:::NVLOGv0.2.2 Tacotron2_PyT 1583711297.051386833 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.495380401611328
Batch: 3/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711297.055279016 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583711297.713441610 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002613271586596966
:::NVLOGv0.2.2 Tacotron2_PyT 1583711299.554969788 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583711299.555638075 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 191942.28420046958
:::NVLOGv0.2.2 Tacotron2_PyT 1583711299.556156397 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5007517337799072
Batch: 4/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711299.559516191 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583711300.249905348 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002359556034207344
:::NVLOGv0.2.2 Tacotron2_PyT 1583711302.222622633 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583711302.223377943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 180168.50376084514
:::NVLOGv0.2.2 Tacotron2_PyT 1583711302.223893166 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.664172649383545
Batch: 5/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711302.228705883 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583711302.886028767 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001853710738942027
:::NVLOGv0.2.2 Tacotron2_PyT 1583711304.730271339 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583711304.731022835 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 191729.76930041402
:::NVLOGv0.2.2 Tacotron2_PyT 1583711304.731683254 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.503523588180542
Batch: 6/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711304.735065460 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583711305.391850471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020871281158179045
:::NVLOGv0.2.2 Tacotron2_PyT 1583711307.195688486 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583711307.196239710 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 194993.0424863065
:::NVLOGv0.2.2 Tacotron2_PyT 1583711307.196718454 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4616262912750244
Batch: 7/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711307.199741125 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583711307.871829510 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021986449137330055
:::NVLOGv0.2.2 Tacotron2_PyT 1583711309.684068680 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583711309.684834719 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 193132.4828952117
:::NVLOGv0.2.2 Tacotron2_PyT 1583711309.685312271 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4853405952453613
Batch: 8/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711309.688410044 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583711310.319926262 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002496337052434683
:::NVLOGv0.2.2 Tacotron2_PyT 1583711312.132282734 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583711312.132857323 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 196360.28689588662
:::NVLOGv0.2.2 Tacotron2_PyT 1583711312.133325815 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.444486141204834
Batch: 9/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711312.135991335 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583711312.765106440 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002131350338459015
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.621583462 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.622153997 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 193066.88188590977
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.622622728 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.486185073852539
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.714806080 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.716590881 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 187260.7968610567
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.718187332 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 190620.06148234947
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.719764471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002199688390828669
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.721363544 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 25.63270092010498
:::NVLOGv0.2.2 Tacotron2_PyT 1583711314.722915888 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.294562578 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0020393989980220795
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.296332598 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.298798323 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 78.03751158714294
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.299698353 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 78.03751158714294
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.300695658 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 79.61020231246948
:::NVLOGv0.2.2 Tacotron2_PyT 1583711316.301552057 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
