:::NVLOGv0.2.2 Tacotron2_PyT 1583603804.401542425 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583603804.427840233 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583603804.444673538 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583603805.531572342 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.33.01", "num": 2, "name": ["Tesla V100-SXM2-32GB", "Tesla V100-SXM2-32GB"], "mem": ["32510 MiB", "32510 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583603805.539533615 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 30, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1583603806.000724792 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs1
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs3
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs0
libibverbs: Warning: no userspace device-specific driver found for /sys/class/infiniband_verbs/uverbs2
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1583603821.465806007 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583603821.467090368 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603821.762280226 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603825.524118900 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017778817564249039
:::NVLOGv0.2.2 Tacotron2_PyT 1583603828.737796545 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603828.738360643 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 68788.30289998189
:::NVLOGv0.2.2 Tacotron2_PyT 1583603828.738834620 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 6.977930545806885
Batch: 1/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603828.741891623 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603829.482215166 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002404951024800539
:::NVLOGv0.2.2 Tacotron2_PyT 1583603831.275164127 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603831.275895596 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 189407.8920444234
:::NVLOGv0.2.2 Tacotron2_PyT 1583603831.276403666 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5342133045196533
Batch: 2/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603831.280879259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583603831.973264456 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002072183880954981
:::NVLOGv0.2.2 Tacotron2_PyT 1583603833.768115044 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583603833.768881083 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 192819.08612760372
:::NVLOGv0.2.2 Tacotron2_PyT 1583603833.769376278 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.489380121231079
Batch: 3/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603833.772834301 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583603834.450974464 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018337920773774385
:::NVLOGv0.2.2 Tacotron2_PyT 1583603836.228647709 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583603836.229381084 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195371.4172202834
:::NVLOGv0.2.2 Tacotron2_PyT 1583603836.229887247 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4568588733673096
Batch: 4/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603836.233279228 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583603836.915666103 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002775313798338175
:::NVLOGv0.2.2 Tacotron2_PyT 1583603838.704620123 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583603838.705196619 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 194158.26871889827
:::NVLOGv0.2.2 Tacotron2_PyT 1583603838.705682278 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.472209930419922
Batch: 5/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603838.708566427 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583603839.350647449 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022513149306178093
:::NVLOGv0.2.2 Tacotron2_PyT 1583603841.128413200 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583603841.128978729 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 198294.00250213387
:::NVLOGv0.2.2 Tacotron2_PyT 1583603841.129441977 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4206480979919434
Batch: 6/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603841.132334948 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583603841.800058126 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022409125231206417
:::NVLOGv0.2.2 Tacotron2_PyT 1583603843.584462404 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583603843.585216284 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195671.30008494493
:::NVLOGv0.2.2 Tacotron2_PyT 1583603843.585729837 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4530935287475586
Batch: 7/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603843.589106798 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583603844.222664118 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020500742830336094
:::NVLOGv0.2.2 Tacotron2_PyT 1583603846.031939268 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583603846.032711744 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 196430.8669311287
:::NVLOGv0.2.2 Tacotron2_PyT 1583603846.033370018 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.443607807159424
Batch: 8/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603846.036450863 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583603846.727051258 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002559127751737833
:::NVLOGv0.2.2 Tacotron2_PyT 1583603848.466264248 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583603848.466817379 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 197482.6320634121
:::NVLOGv0.2.2 Tacotron2_PyT 1583603848.467280388 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.430593490600586
Batch: 9/10 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603848.469882965 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583603849.142857075 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002105067251250148
:::NVLOGv0.2.2 Tacotron2_PyT 1583603850.891881943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583603850.892440081 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 198137.3923465295
:::NVLOGv0.2.2 Tacotron2_PyT 1583603850.892920256 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4225614070892334
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.084875107 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.085432053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 162060.6771628403
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.085907698 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 182656.116093934
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.086381674 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002207061927765608
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.086858273 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 29.6185359954834
:::NVLOGv0.2.2 Tacotron2_PyT 1583603851.087322950 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1583603853.211728334 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.002206929959356785
:::NVLOGv0.2.2 Tacotron2_PyT 1583603853.212920666 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603856.173378468 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603856.451565742 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603857.096266270 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001795981195755303
:::NVLOGv0.2.2 Tacotron2_PyT 1583603858.880533934 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583603858.881140232 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 197457.5495371051
:::NVLOGv0.2.2 Tacotron2_PyT 1583603858.881632566 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4309022426605225
Batch: 1/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603858.884606361 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603859.559959888 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002251762431114912
:::NVLOGv0.2.2 Tacotron2_PyT 1583603861.326060534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603861.326614618 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 196541.12995148916
:::NVLOGv0.2.2 Tacotron2_PyT 1583603861.327104330 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.44223690032959
Batch: 2/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603861.329984665 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583603862.003210306 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020264245104044676
:::NVLOGv0.2.2 Tacotron2_PyT 1583603863.819612741 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583603863.820378065 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 192738.73230469952
:::NVLOGv0.2.2 Tacotron2_PyT 1583603863.821039915 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.490417957305908
Batch: 3/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603863.824400187 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583603864.519172907 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020016294438391924
:::NVLOGv0.2.2 Tacotron2_PyT 1583603866.258957863 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583603866.259523392 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 197081.74679662098
:::NVLOGv0.2.2 Tacotron2_PyT 1583603866.259984970 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.435537576675415
Batch: 4/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603866.262907982 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583603866.933641911 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002467087935656309
:::NVLOGv0.2.2 Tacotron2_PyT 1583603868.813142538 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583603868.813686371 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 188163.9410176016
:::NVLOGv0.2.2 Tacotron2_PyT 1583603868.814150572 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.55096697807312
Batch: 5/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603868.817245483 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583603869.484484673 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002135826740413904
:::NVLOGv0.2.2 Tacotron2_PyT 1583603871.265525103 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583603871.266083956 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195994.61723646708
:::NVLOGv0.2.2 Tacotron2_PyT 1583603871.266546965 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4490468502044678
Batch: 6/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603871.269365549 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583603871.954875946 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018949330551549792
:::NVLOGv0.2.2 Tacotron2_PyT 1583603873.721403599 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583603873.721971750 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 195696.00691931671
:::NVLOGv0.2.2 Tacotron2_PyT 1583603873.722436428 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4527838230133057
Batch: 7/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603873.725250721 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583603874.423687696 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022369571961462498
:::NVLOGv0.2.2 Tacotron2_PyT 1583603876.229585171 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583603876.230142832 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 191610.04653995868
:::NVLOGv0.2.2 Tacotron2_PyT 1583603876.230630875 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5050878524780273
Batch: 8/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603876.233263969 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583603876.879691601 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020590589847415686
:::NVLOGv0.2.2 Tacotron2_PyT 1583603878.625830412 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583603878.626377583 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 200572.83927002325
:::NVLOGv0.2.2 Tacotron2_PyT 1583603878.626841784 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3931455612182617
Batch: 9/10 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603878.629771471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583603879.350308657 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002176524605602026
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.122990847 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.123547792 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 192477.49682664408
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.124011517 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.493798017501831
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.203981876 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.204568863 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 191759.74620192262
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.205034494 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 194833.41063999262
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.205496311 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002104618609882891
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.205954313 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 25.031322240829468
:::NVLOGv0.2.2 Tacotron2_PyT 1583603881.206407070 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.668336391 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0024256701581180096
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.669245958 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.670674324 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 76.66918396949768
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.671172857 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 76.66918396949768
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.671694994 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 78.38601517677307
:::NVLOGv0.2.2 Tacotron2_PyT 1583603882.672161341 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
