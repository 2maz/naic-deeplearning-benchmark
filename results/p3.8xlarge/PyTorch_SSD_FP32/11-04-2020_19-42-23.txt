Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth
Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth
  0%|          | 0.00/97.8M [00:00<?, ?B/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s]  7%|▋         | 6.85M/97.8M [00:00<00:01, 71.8MB/s] 15%|█▍        | 14.2M/97.8M [00:00<00:00, 149MB/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s] 18%|█▊        | 17.9M/97.8M [00:00<00:01, 81.1MB/s] 36%|███▌      | 34.8M/97.8M [00:00<00:00, 164MB/s]Downloading: "https://download.pytorch.org/models/resnet50-19c8e357.pth" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth
  6%|▌         | 5.78M/97.8M [00:00<00:01, 60.6MB/s] 30%|███       | 29.6M/97.8M [00:00<00:00, 90.2MB/s]  0%|          | 0.00/97.8M [00:00<?, ?B/s] 58%|█████▊    | 57.1M/97.8M [00:00<00:00, 180MB/s] 23%|██▎       | 22.3M/97.8M [00:00<00:01, 75.3MB/s] 42%|████▏     | 41.2M/97.8M [00:00<00:00, 97.8MB/s]  8%|▊         | 7.48M/97.8M [00:00<00:01, 78.5MB/s] 33%|███▎      | 32.3M/97.8M [00:00<00:00, 82.3MB/s] 72%|███████▏  | 70.3M/97.8M [00:00<00:00, 161MB/s] 57%|█████▋    | 55.5M/97.8M [00:00<00:00, 109MB/s]  24%|██▎       | 23.0M/97.8M [00:00<00:00, 92.9MB/s] 43%|████▎     | 41.8M/97.8M [00:00<00:00, 86.7MB/s] 93%|█████████▎| 90.7M/97.8M [00:00<00:00, 174MB/s]100%|██████████| 97.8M/97.8M [00:00<00:00, 189MB/s]
 74%|███████▍  | 72.1M/97.8M [00:00<00:00, 123MB/s] 39%|███▉      | 38.4M/97.8M [00:00<00:00, 106MB/s]  59%|█████▊    | 57.3M/97.8M [00:00<00:00, 101MB/s]  91%|█████████ | 88.9M/97.8M [00:00<00:00, 135MB/s] 55%|█████▍    | 53.5M/97.8M [00:00<00:00, 118MB/s] 75%|███████▍  | 73.1M/97.8M [00:00<00:00, 114MB/s]100%|██████████| 97.8M/97.8M [00:00<00:00, 136MB/s]
 71%|███████   | 69.2M/97.8M [00:00<00:00, 129MB/s] 91%|█████████ | 89.0M/97.8M [00:00<00:00, 126MB/s]100%|██████████| 97.8M/97.8M [00:00<00:00, 136MB/s]
 88%|████████▊ | 85.9M/97.8M [00:00<00:00, 140MB/s]100%|██████████| 97.8M/97.8M [00:00<00:00, 153MB/s]
Using seed = 8637
loading annotations into memory...
Using seed = 7696
loading annotations into memory...
Done (t=0.55s)
creating index...
Done (t=0.54s)
creating index...
index created!
index created!
WARNING: `ColorTwist` is now deprecated. Use `Hsv/BrightnessContrast` instead
WARNING: `ColorTwist` is now deprecated. Use `Hsv/BrightnessContrast` instead
Using seed = 7669
Using seed = 6399
loading annotations into memory...
loading annotations into memory...
Done (t=0.57s)
creating index...
Done (t=0.56s)
creating index...
index created!
index created!
WARNING: `ColorTwist` is now deprecated. Use `Hsv/BrightnessContrast` instead
WARNING: `ColorTwist` is now deprecated. Use `Hsv/BrightnessContrast` instead
[/opt/dali/dali/operators/color/color_twist.h:181] The Operators: `ColorTwist`, `Hue`, `Saturation`, `Brightness`, `Contrast`, are deprecated, not supported, and will be removed in version 0.20. Please use `BrightnessContrast` and `Hsv` instead.
[/opt/dali/dali/operators/color/color_twist.h:181] The Operators: `ColorTwist`, `Hue`, `Saturation`, `Brightness`, `Contrast`, are deprecated, not supported, and will be removed in version 0.20. Please use `BrightnessContrast` and `Hsv` instead.
[/opt/dali/dali/operators/color/color_twist.h:181] The Operators: `ColorTwist`, `Hue`, `Saturation`, `Brightness`, `Contrast`, are deprecated, not supported, and will be removed in version 0.20. Please use `BrightnessContrast` and `Hsv` instead.
[/opt/dali/dali/operators/color/color_twist.h:181] The Operators: `ColorTwist`, `Hue`, `Saturation`, `Brightness`, `Contrast`, are deprecated, not supported, and will be removed in version 0.20. Please use `BrightnessContrast` and `Hsv` instead.
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.
  warnings.warn(warning.format(ret))
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
/opt/conda/lib/python3.6/site-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
Done benchmarking. Total images: 9600	total time: 70.523	Average images/sec: 136.126	Median images/sec: 136.491
Done benchmarking. Total images: 9600	total time: 70.351	Average images/sec: 136.460	Median images/sec: 136.790
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
total training time: 122.82551431655884
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
total training time: 122.82624340057373
Done benchmarking. Total images: 9600	total time: 70.791	Average images/sec: 135.611	Median images/sec: 136.045
Done benchmarking. Total images: 9600	total time: 71.177	Average images/sec: 134.876	Median images/sec: 135.173
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
total training time: 122.8268404006958
Training performance = 544.4982299804688 FPS
epoch: 0	time: 122.91807889938354
WARNING:root:DALI iterator does not support resetting while epoch is not finished. Ignoring...
total training time: 122.91807889938354
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
DONE!
