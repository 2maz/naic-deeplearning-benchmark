:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.148117542 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.161290169 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 24, "name": "Intel(R) Core(TM) i9-7920X CPU @ 2.90GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.175841570 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "62G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.483828306 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.44", "num": 1, "name": ["Quadro RTX 5000"], "mem": ["16125 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.487186909 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "Tacotron2", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 1, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": false, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 1e-06, "grad_clip_thresh": 1.0, "batch_size": 100, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 1, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "mask_padding": false, "n_mel_channels": 80, "n_symbols": 148, "symbols_embedding_dim": 512, "encoder_kernel_size": 5, "encoder_n_convolutions": 3, "encoder_embedding_dim": 512, "n_frames_per_step": 1, "decoder_rnn_dim": 1024, "prenet_dim": 256, "max_decoder_steps": 2000, "gate_threshold": 0.5, "p_attention_dropout": 0.1, "p_decoder_dropout": 0.1, "decoder_no_early_stopping": false, "attention_rnn_dim": 1024, "attention_dim": 128, "attention_location_n_filters": 32, "attention_location_kernel_size": 31, "postnet_embedding_dim": 512, "postnet_kernel_size": 5, "postnet_n_convolutions": 5}
:::NVLOGv0.2.2 Tacotron2_PyT 1583425564.487721920 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1583425569.541382074 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583425569.542019129 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425571.779020071 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425576.112521172 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.603912353515625
:::NVLOGv0.2.2 Tacotron2_PyT 1583425578.727707386 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425578.728207350 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 8194.488677162895
:::NVLOGv0.2.2 Tacotron2_PyT 1583425578.728627920 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 6.9510133266448975
Batch: 1/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425578.735326767 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583425580.404460430 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.43607711791992
:::NVLOGv0.2.2 Tacotron2_PyT 1583425582.964372635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583425582.967065573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 14097.125245891439
:::NVLOGv0.2.2 Tacotron2_PyT 1583425582.967712879 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.2297985553741455
Batch: 2/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425582.975226164 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583425584.222176552 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.01849365234375
:::NVLOGv0.2.2 Tacotron2_PyT 1583425586.787866354 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583425586.789343596 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 14868.886932216301
:::NVLOGv0.2.2 Tacotron2_PyT 1583425586.792139530 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 3.8133318424224854
Batch: 3/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425586.805734873 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583425588.114493370 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 43.52051544189453
:::NVLOGv0.2.2 Tacotron2_PyT 1583425590.764162064 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583425590.764918089 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 13365.660914410257
:::NVLOGv0.2.2 Tacotron2_PyT 1583425590.766467094 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 3.9597742557525635
Batch: 4/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425590.781539679 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583425592.028683424 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.90544891357422
:::NVLOGv0.2.2 Tacotron2_PyT 1583425594.523378849 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583425594.524871826 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15073.301332758496
:::NVLOGv0.2.2 Tacotron2_PyT 1583425594.526601553 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 3.74277663230896
Batch: 5/6 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425594.534607410 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583425595.795131445 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.659637451171875
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.438264132 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.439196825 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 14644.792247369445
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.440359116 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 3.904186487197876
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.546134472 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.548571587 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 11715.477343657969
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.551569223 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 13374.042558301473
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.553582191 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.35734748840332
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.555916309 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 29.004793405532837
:::NVLOGv0.2.2 Tacotron2_PyT 1583425598.557885170 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425601.974550247 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 45.521732330322266
:::NVLOGv0.2.2 Tacotron2_PyT 1583425601.983510017 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583425602.236919641 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 37.748674392700195
:::NVLOGv0.2.2 Tacotron2_PyT 1583425602.237397671 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 37.748674392700195
:::NVLOGv0.2.2 Tacotron2_PyT 1583425602.237865686 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 38.19367575645447
:::NVLOGv0.2.2 Tacotron2_PyT 1583425602.238281965 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
