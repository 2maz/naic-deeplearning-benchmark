:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.021339417 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.036049604 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 24, "name": "Intel(R) Core(TM) i9-7920X CPU @ 2.90GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.048056126 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "62G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.290669680 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.44", "num": 1, "name": ["Quadro RTX 8000"], "mem": ["48598 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.293254137 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 1, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 52, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 1, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435815.293761730 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1583435821.331763268 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583435821.332708120 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435821.606075287 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435826.752297878 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002169397659599781
:::NVLOGv0.2.2 Tacotron2_PyT 1583435833.367471933 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435833.367967844 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 35361.87250897509
:::NVLOGv0.2.2 Tacotron2_PyT 1583435833.368411064 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 11.764082908630371
Batch: 1/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435833.372820854 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583435834.851553202 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019401722820475698
:::NVLOGv0.2.2 Tacotron2_PyT 1583435838.550235987 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583435838.550738335 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 80324.29604105453
:::NVLOGv0.2.2 Tacotron2_PyT 1583435838.551180363 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.179005861282349
Batch: 2/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435838.553868294 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583435839.859008789 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019242513226345181
:::NVLOGv0.2.2 Tacotron2_PyT 1583435843.773017168 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583435843.773519278 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79696.15430747726
:::NVLOGv0.2.2 Tacotron2_PyT 1583435843.773964643 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.219825267791748
Batch: 3/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435843.776591301 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583435845.132729292 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002298812847584486
:::NVLOGv0.2.2 Tacotron2_PyT 1583435849.034494162 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583435849.035011768 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79108.3430324145
:::NVLOGv0.2.2 Tacotron2_PyT 1583435849.035431862 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.258610963821411
Batch: 4/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435849.038139105 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583435850.389252663 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020180633291602135
:::NVLOGv0.2.2 Tacotron2_PyT 1583435854.222614288 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583435854.223119020 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 80228.63769342095
:::NVLOGv0.2.2 Tacotron2_PyT 1583435854.223544359 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.185180902481079
Batch: 5/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435854.226242304 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583435855.615979433 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001712169498205185
:::NVLOGv0.2.2 Tacotron2_PyT 1583435859.511202812 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583435859.511702538 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 78703.30823273292
:::NVLOGv0.2.2 Tacotron2_PyT 1583435859.512140751 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.28567361831665
Batch: 6/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435859.514843702 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583435860.953536749 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002381709171459079
:::NVLOGv0.2.2 Tacotron2_PyT 1583435864.744185448 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583435864.744697809 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79540.65907275116
:::NVLOGv0.2.2 Tacotron2_PyT 1583435864.745117664 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.230029582977295
Batch: 7/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435864.747815371 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583435866.178636074 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024643871001899242
:::NVLOGv0.2.2 Tacotron2_PyT 1583435870.105085611 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583435870.105591774 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 77641.73937776714
:::NVLOGv0.2.2 Tacotron2_PyT 1583435870.106044054 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.357942819595337
Batch: 8/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435870.108647823 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583435871.460958242 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019234016072005033
:::NVLOGv0.2.2 Tacotron2_PyT 1583435875.227350473 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583435875.227852583 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 81260.12014998769
:::NVLOGv0.2.2 Tacotron2_PyT 1583435875.228291512 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.1193623542785645
Batch: 9/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435875.231026173 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583435876.633116484 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022895385045558214
:::NVLOGv0.2.2 Tacotron2_PyT 1583435880.490497112 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583435880.491012573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79085.09748763252
:::NVLOGv0.2.2 Tacotron2_PyT 1583435880.491466999 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.260156631469727
Batch: 10/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435880.493952036 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1583435881.984328747 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024454069789499044
:::NVLOGv0.2.2 Tacotron2_PyT 1583435885.853233576 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1583435885.853758097 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 77614.5552685342
:::NVLOGv0.2.2 Tacotron2_PyT 1583435885.854201317 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.359819412231445
Batch: 11/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435885.856704950 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1583435887.218936682 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018891376676037908
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.093332529 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.093833923 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79431.97406177968
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.094291210 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.237185716629028
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.211044788 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.212486982 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 71437.57241177816
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.213834286 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 75666.39643621065
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.215184927 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021213706640992314
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.216511011 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 69.87919425964355
:::NVLOGv0.2.2 Tacotron2_PyT 1583435891.217826843 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435895.787021637 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0016419041203334928
:::NVLOGv0.2.2 Tacotron2_PyT 1583435895.789263010 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435905.091547728 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 89.7963318824768
:::NVLOGv0.2.2 Tacotron2_PyT 1583435905.092958450 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 89.7963318824768
:::NVLOGv0.2.2 Tacotron2_PyT 1583435905.094758034 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 90.17468643188477
:::NVLOGv0.2.2 Tacotron2_PyT 1583435905.095993042 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
