:::NVLOGv0.2.2 Tacotron2_PyT 1583435616.910734653 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583435616.924389362 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 24, "name": "Intel(R) Core(TM) i9-7920X CPU @ 2.90GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435616.940154791 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "62G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435617.157589912 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.44", "num": 1, "name": ["Quadro RTX 8000"], "mem": ["48598 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435617.164850235 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 1, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 52, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 1, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
:::NVLOGv0.2.2 Tacotron2_PyT 1583435617.166051388 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1583435623.331519842 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583435623.332120657 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435623.614819288 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435628.758909702 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021604816429316998
:::NVLOGv0.2.2 Tacotron2_PyT 1583435635.330608606 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435635.331119299 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 35500.54959986993
:::NVLOGv0.2.2 Tacotron2_PyT 1583435635.331545353 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 11.718128442764282
Batch: 1/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435635.334218264 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583435636.898407698 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019824900664389133
:::NVLOGv0.2.2 Tacotron2_PyT 1583435640.765400648 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583435640.765933037 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 76584.18314922813
:::NVLOGv0.2.2 Tacotron2_PyT 1583435640.766360760 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.431931018829346
Batch: 2/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435640.768989086 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583435642.126221895 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002016721060499549
:::NVLOGv0.2.2 Tacotron2_PyT 1583435646.142679691 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583435646.143203259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 77404.15897244845
:::NVLOGv0.2.2 Tacotron2_PyT 1583435646.143624783 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.374388217926025
Batch: 3/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435646.146289349 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583435647.843942404 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020591181237250566
:::NVLOGv0.2.2 Tacotron2_PyT 1583435651.852364063 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583435651.852898359 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 72895.67298121512
:::NVLOGv0.2.2 Tacotron2_PyT 1583435651.853336573 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.7067859172821045
Batch: 4/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435651.856059074 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583435653.357159376 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020547688473016024
:::NVLOGv0.2.2 Tacotron2_PyT 1583435657.160330772 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583435657.160831213 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 78417.23207464068
:::NVLOGv0.2.2 Tacotron2_PyT 1583435657.161266088 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.304956436157227
Batch: 5/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435657.163917065 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583435658.634809017 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019617644138634205
:::NVLOGv0.2.2 Tacotron2_PyT 1583435662.127524376 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583435662.128024101 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 83798.53872846006
:::NVLOGv0.2.2 Tacotron2_PyT 1583435662.128465891 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.964287042617798
Batch: 6/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435662.132880688 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583435663.799568415 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0027453782968223095
:::NVLOGv0.2.2 Tacotron2_PyT 1583435667.790670156 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583435667.791179419 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 73506.31973536502
:::NVLOGv0.2.2 Tacotron2_PyT 1583435667.791637182 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.659377336502075
Batch: 7/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435667.794318438 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583435669.232179403 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023022894747555256
:::NVLOGv0.2.2 Tacotron2_PyT 1583435672.963297129 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1583435672.963819504 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 80468.85034074375
:::NVLOGv0.2.2 Tacotron2_PyT 1583435672.964239836 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.1697022914886475
Batch: 8/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435672.966909647 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583435674.458936214 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018222329672425985
:::NVLOGv0.2.2 Tacotron2_PyT 1583435678.228683472 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1583435678.229181528 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79050.42847230012
:::NVLOGv0.2.2 Tacotron2_PyT 1583435678.229611158 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.262463569641113
Batch: 9/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435678.232273817 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583435679.578787804 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022702831774950027
:::NVLOGv0.2.2 Tacotron2_PyT 1583435683.322850704 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1583435683.323379278 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 81708.3099852761
:::NVLOGv0.2.2 Tacotron2_PyT 1583435683.323811769 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.091281414031982
Batch: 10/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435683.326251745 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1583435684.724522591 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002596391597762704
:::NVLOGv0.2.2 Tacotron2_PyT 1583435688.570855141 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1583435688.571360350 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 79311.73380886814
:::NVLOGv0.2.2 Tacotron2_PyT 1583435688.571796894 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.2451255321502686
Batch: 11/12 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435688.574262857 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1583435690.158821344 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019379324512556195
:::NVLOGv0.2.2 Tacotron2_PyT 1583435693.973399639 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1583435693.973916531 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 77041.33857076948
:::NVLOGv0.2.2 Tacotron2_PyT 1583435693.974340200 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.399698495864868
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.100873709 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.102367163 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 70538.96519989904
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.103762388 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 74640.60970159875
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.105097055 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021591543433411666
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.106427431 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 70.76939654350281
:::NVLOGv0.2.2 Tacotron2_PyT 1583435694.107742786 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435698.672574520 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.001780073274858296
:::NVLOGv0.2.2 Tacotron2_PyT 1583435698.673588276 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583435700.761450291 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 83.59482884407043
:::NVLOGv0.2.2 Tacotron2_PyT 1583435700.761945009 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 83.59482884407043
:::NVLOGv0.2.2 Tacotron2_PyT 1583435700.762408972 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 83.95263481140137
:::NVLOGv0.2.2 Tacotron2_PyT 1583435700.762819290 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
