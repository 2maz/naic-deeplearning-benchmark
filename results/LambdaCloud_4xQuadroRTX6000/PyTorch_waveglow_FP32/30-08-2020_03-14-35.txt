:::NVLOGv0.2.2 Tacotron2_PyT 1598757278.678601027 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1598757278.692963839 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 24, "name": "AMD EPYC Processor (with IBPB)"}
:::NVLOGv0.2.2 Tacotron2_PyT 1598757278.708226919 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "180G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1598757279.712549686 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "450.57", "num": 4, "name": ["Quadro RTX 6000", "Quadro RTX 6000", "Quadro RTX 6000", "Quadro RTX 6000"], "mem": ["24220 MiB", "24220 MiB", "24220 MiB", "24220 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1598757279.716111898 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 10, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 4, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1598757281.087329865 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1598758531.398840427 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1598758531.399466753 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758532.075316429 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758536.019909382 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021594443824142218
:::NVLOGv0.2.2 Tacotron2_PyT 1598758538.718067408 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758538.718669415 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 48163.87737043888
:::NVLOGv0.2.2 Tacotron2_PyT 1598758538.719141960 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 6.643983364105225
Batch: 1/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758538.723043680 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758539.592326403 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021893102675676346
:::NVLOGv0.2.2 Tacotron2_PyT 1598758541.310715914 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758541.311327696 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 123616.079277728
:::NVLOGv0.2.2 Tacotron2_PyT 1598758541.311820030 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5886600017547607
Batch: 2/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758541.315757990 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598758541.881596088 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002472066320478916
:::NVLOGv0.2.2 Tacotron2_PyT 1598758543.609875917 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598758543.610472441 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139422.2490180444
:::NVLOGv0.2.2 Tacotron2_PyT 1598758543.610942602 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2951860427856445
Batch: 3/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758543.615109444 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598758544.178932190 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002794660860672593
:::NVLOGv0.2.2 Tacotron2_PyT 1598758545.916212082 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598758545.916835070 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139011.45460518711
:::NVLOGv0.2.2 Tacotron2_PyT 1598758545.917378664 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.301968574523926
Batch: 4/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758545.922131062 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598758546.483386278 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002413397189229727
:::NVLOGv0.2.2 Tacotron2_PyT 1598758548.222586155 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598758548.223188400 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139031.62862533802
:::NVLOGv0.2.2 Tacotron2_PyT 1598758548.232119799 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3016345500946045
Batch: 5/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758548.236447573 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598758548.803198099 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001612447202205658
:::NVLOGv0.2.2 Tacotron2_PyT 1598758550.529300928 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598758550.529942751 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139492.17834930838
:::NVLOGv0.2.2 Tacotron2_PyT 1598758550.530458450 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2940354347229004
Batch: 6/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758550.542767525 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598758551.107723475 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00249772728420794
:::NVLOGv0.2.2 Tacotron2_PyT 1598758552.837576628 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598758552.838122606 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139404.43737797232
:::NVLOGv0.2.2 Tacotron2_PyT 1598758552.838681459 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2954792976379395
Batch: 7/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758552.841187000 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598758553.406803131 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025749895721673965
:::NVLOGv0.2.2 Tacotron2_PyT 1598758555.146032333 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598758555.146595478 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 138794.5188990519
:::NVLOGv0.2.2 Tacotron2_PyT 1598758555.147105455 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3055665493011475
Batch: 8/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758555.150056601 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598758555.741721153 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025367585476487875
:::NVLOGv0.2.2 Tacotron2_PyT 1598758557.486921549 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598758557.487538338 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136878.258077912
:::NVLOGv0.2.2 Tacotron2_PyT 1598758557.488030434 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.337843894958496
Batch: 9/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758557.490880966 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598758558.054461241 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002491012681275606
:::NVLOGv0.2.2 Tacotron2_PyT 1598758559.796520710 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598758559.797179222 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 138733.60392115638
:::NVLOGv0.2.2 Tacotron2_PyT 1598758559.797684669 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3065788745880127
Batch: 10/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758559.800331593 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598758560.367118359 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021139667369425297
:::NVLOGv0.2.2 Tacotron2_PyT 1598758562.098520517 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598758562.099128723 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139192.74103064314
:::NVLOGv0.2.2 Tacotron2_PyT 1598758562.099621058 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2989704608917236
Batch: 11/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758562.102367640 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598758562.666985750 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018883509328588843
:::NVLOGv0.2.2 Tacotron2_PyT 1598758564.399669170 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598758564.400310040 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 139240.22021117108
:::NVLOGv0.2.2 Tacotron2_PyT 1598758564.400804043 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.2981865406036377
Batch: 12/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758564.403563738 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598758564.970962524 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021281244698911905
:::NVLOGv0.2.2 Tacotron2_PyT 1598758566.713633299 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598758566.724416256 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 138471.60334920834
:::NVLOGv0.2.2 Tacotron2_PyT 1598758566.724952936 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.310943126678467
Batch: 13/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758566.734359741 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598758567.299705267 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020697624422609806
:::NVLOGv0.2.2 Tacotron2_PyT 1598758569.058532000 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598758569.059123993 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137628.50646137912
:::NVLOGv0.2.2 Tacotron2_PyT 1598758569.059610367 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3250997066497803
Batch: 14/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758569.062051296 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598758569.639241695 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002282500034198165
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.398532629 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.399165392 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136920.4556421017
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.399690390 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.337123394012451
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.582460165 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.592448950 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 119451.45950254938
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.593272924 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 131600.12081444272
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.593917131 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002281634594934682
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.594444275 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 40.18368649482727
:::NVLOGv0.2.2 Tacotron2_PyT 1598758571.594952822 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1598758574.085511446 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0018429714255034924
:::NVLOGv0.2.2 Tacotron2_PyT 1598758574.086487532 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758577.950634718 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758578.060933590 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758578.649675369 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023788507096469402
:::NVLOGv0.2.2 Tacotron2_PyT 1598758580.420205593 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598758580.420821905 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135535.6221757885
:::NVLOGv0.2.2 Tacotron2_PyT 1598758580.421348572 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3610029220581055
Batch: 1/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758580.440166235 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758581.014180183 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022339331917464733
:::NVLOGv0.2.2 Tacotron2_PyT 1598758582.774667025 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758582.775334120 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137033.93990579192
:::NVLOGv0.2.2 Tacotron2_PyT 1598758582.775867701 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3351879119873047
Batch: 2/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758582.779794216 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598758583.352960587 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001978663494810462
:::NVLOGv0.2.2 Tacotron2_PyT 1598758585.107317924 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598758585.107987404 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137431.01633605492
:::NVLOGv0.2.2 Tacotron2_PyT 1598758585.108463526 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3284409046173096
Batch: 3/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758585.113048315 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598758585.684036255 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001588407321833074
:::NVLOGv0.2.2 Tacotron2_PyT 1598758587.440215588 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598758587.440831423 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137424.86709330327
:::NVLOGv0.2.2 Tacotron2_PyT 1598758587.441356659 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.328545093536377
Batch: 4/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758587.456247091 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598758588.030721426 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00204718136228621
:::NVLOGv0.2.2 Tacotron2_PyT 1598758589.784915686 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598758589.785599947 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137361.999104297
:::NVLOGv0.2.2 Tacotron2_PyT 1598758589.786094666 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.329610824584961
Batch: 5/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758589.789703608 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598758590.358165741 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020564531441777945
:::NVLOGv0.2.2 Tacotron2_PyT 1598758592.134672403 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598758592.135281563 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136394.57172527828
:::NVLOGv0.2.2 Tacotron2_PyT 1598758592.139425039 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3461344242095947
Batch: 6/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758592.161313534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598758592.730633020 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002242689486593008
:::NVLOGv0.2.2 Tacotron2_PyT 1598758594.499831438 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598758594.500450134 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136791.66842899416
:::NVLOGv0.2.2 Tacotron2_PyT 1598758594.512355089 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3393237590789795
Batch: 7/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758594.518368959 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598758595.095828772 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018978073494508862
:::NVLOGv0.2.2 Tacotron2_PyT 1598758596.855851889 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598758596.856400728 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136833.25461193066
:::NVLOGv0.2.2 Tacotron2_PyT 1598758596.856840849 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3386127948760986
Batch: 8/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758596.860137939 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598758597.433102846 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024448935873806477
:::NVLOGv0.2.2 Tacotron2_PyT 1598758599.196122408 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598758599.196729422 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136913.24865690747
:::NVLOGv0.2.2 Tacotron2_PyT 1598758599.197393894 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3372464179992676
Batch: 9/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758599.210191011 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598758599.804932117 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021098298020660877
:::NVLOGv0.2.2 Tacotron2_PyT 1598758601.567840815 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598758601.568388939 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135662.57512384144
:::NVLOGv0.2.2 Tacotron2_PyT 1598758601.568921566 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3587934970855713
Batch: 10/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758601.571935177 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598758602.144373178 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023477922659367323
:::NVLOGv0.2.2 Tacotron2_PyT 1598758603.910129309 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598758603.910745382 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136789.32629759694
:::NVLOGv0.2.2 Tacotron2_PyT 1598758603.911262274 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3393638134002686
Batch: 11/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758603.914016724 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598758604.487600803 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023816858883947134
:::NVLOGv0.2.2 Tacotron2_PyT 1598758606.246026039 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598758606.246646643 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137167.6415831225
:::NVLOGv0.2.2 Tacotron2_PyT 1598758606.247165680 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.332911729812622
Batch: 12/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758606.250006437 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598758606.823175669 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020626098848879337
:::NVLOGv0.2.2 Tacotron2_PyT 1598758608.597523928 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598758608.598117590 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136261.41761988838
:::NVLOGv0.2.2 Tacotron2_PyT 1598758608.598615646 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3484270572662354
Batch: 13/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758608.601091146 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598758609.172446728 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022572858724743128
:::NVLOGv0.2.2 Tacotron2_PyT 1598758610.928942919 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598758610.929602861 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 137422.4891584189
:::NVLOGv0.2.2 Tacotron2_PyT 1598758610.930099726 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.328585386276245
Batch: 14/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758610.932529688 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598758611.508022547 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002753460081294179
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.279847860 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.280473948 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136288.44004263173
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.280956984 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.34796142578125
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.327851772 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.328383207 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 135678.1540827311
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.328831673 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 136754.13852425638
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.329326868 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021854362295319636
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.329767942 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 35.37783980369568
:::NVLOGv0.2.2 Tacotron2_PyT 1598758613.329970837 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.948265553 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.002091276692226529
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.949795485 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.959845066 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 1333.8715052604675
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.960333347 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 1333.8715052604675
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.960838318 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 1336.4082975387573
:::NVLOGv0.2.2 Tacotron2_PyT 1598758614.964585304 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
