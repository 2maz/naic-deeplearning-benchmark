:::NVLOGv0.2.2 Tacotron2_PyT 1592885902.256185532 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1592885902.284101725 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1592885902.303422928 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "692G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1592885906.640871286 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 8, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1592885906.649613380 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 4, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 8, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1592885910.025630474 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1592885962.751311302 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1592885962.770425081 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885963.884770632 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885977.473439217 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019021900370717049
:::NVLOGv0.2.2 Tacotron2_PyT 1592885979.301555157 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885979.302534580 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16603.66823325048
:::NVLOGv0.2.2 Tacotron2_PyT 1592885979.303391933 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 15.418279647827148
Batch: 1/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885979.308039665 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592885980.122078180 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020983414724469185
:::NVLOGv0.2.2 Tacotron2_PyT 1592885981.089072466 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592885981.089550495 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 143645.56339523307
:::NVLOGv0.2.2 Tacotron2_PyT 1592885981.089900732 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.7821643352508545
Batch: 2/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885981.092574358 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1592885981.341964245 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025115003809332848
:::NVLOGv0.2.2 Tacotron2_PyT 1592885982.240075350 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1592885982.240481615 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222970.35193347657
:::NVLOGv0.2.2 Tacotron2_PyT 1592885982.240826845 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.148134708404541
Batch: 3/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885982.243333340 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1592885982.544157982 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002346155932173133
:::NVLOGv0.2.2 Tacotron2_PyT 1592885983.432009220 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1592885983.432499647 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 215240.4475110999
:::NVLOGv0.2.2 Tacotron2_PyT 1592885983.432856321 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1893675327301025
Batch: 4/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885983.435606480 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1592885983.755145788 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002437304938212037
:::NVLOGv0.2.2 Tacotron2_PyT 1592885984.638687372 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1592885984.639102697 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 212668.55143439223
:::NVLOGv0.2.2 Tacotron2_PyT 1592885984.639459610 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2037510871887207
Batch: 5/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885984.641951799 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1592885984.941908836 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002993080299347639
:::NVLOGv0.2.2 Tacotron2_PyT 1592885985.825558424 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1592885985.826091528 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 216154.58003588143
:::NVLOGv0.2.2 Tacotron2_PyT 1592885985.826453924 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1843376159667969
Batch: 6/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885985.829202175 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1592885986.104659796 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022651851177215576
:::NVLOGv0.2.2 Tacotron2_PyT 1592885986.998180866 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1592885986.998620749 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 218864.23811632028
:::NVLOGv0.2.2 Tacotron2_PyT 1592885986.998976946 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1696748733520508
Batch: 7/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885987.001612425 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1592885987.252704144 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002471769927069545
:::NVLOGv0.2.2 Tacotron2_PyT 1592885988.140112400 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1592885988.140507460 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 224731.80558494446
:::NVLOGv0.2.2 Tacotron2_PyT 1592885988.140845299 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1391355991363525
Batch: 8/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885988.143401623 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1592885988.409682989 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002682560123503208
:::NVLOGv0.2.2 Tacotron2_PyT 1592885989.293293476 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1592885989.293688059 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222511.29433448255
:::NVLOGv0.2.2 Tacotron2_PyT 1592885989.294074297 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.150503396987915
Batch: 9/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885989.297094584 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1592885989.509504795 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017991947242990136
:::NVLOGv0.2.2 Tacotron2_PyT 1592885990.390693426 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1592885990.391198397 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 233930.3238535366
:::NVLOGv0.2.2 Tacotron2_PyT 1592885990.391570807 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0943429470062256
Batch: 10/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885990.394607306 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1592885990.649851799 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019040988991037011
:::NVLOGv0.2.2 Tacotron2_PyT 1592885991.549863100 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1592885991.550288677 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 221466.64403341114
:::NVLOGv0.2.2 Tacotron2_PyT 1592885991.550644159 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1559302806854248
Batch: 11/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885991.553163290 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1592885991.750316620 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020982548594474792
:::NVLOGv0.2.2 Tacotron2_PyT 1592885992.737109423 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1592885992.737782001 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 216097.41775958956
:::NVLOGv0.2.2 Tacotron2_PyT 1592885992.738292456 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1846508979797363
Batch: 12/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885992.741613865 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1592885992.947482109 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019324837485328317
:::NVLOGv0.2.2 Tacotron2_PyT 1592885993.933305740 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1592885993.934085846 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 214635.29492663266
:::NVLOGv0.2.2 Tacotron2_PyT 1592885993.934603453 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.192720890045166
Batch: 13/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885993.938135386 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1592885994.141275406 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019239248940721154
:::NVLOGv0.2.2 Tacotron2_PyT 1592885995.128275394 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1592885995.128876448 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 214929.76552210064
:::NVLOGv0.2.2 Tacotron2_PyT 1592885995.129384279 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.191086769104004
Batch: 14/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885995.132394791 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1592885995.335947037 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001694693579338491
:::NVLOGv0.2.2 Tacotron2_PyT 1592885996.356927633 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1592885996.357425928 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 208908.33236863482
:::NVLOGv0.2.2 Tacotron2_PyT 1592885996.357838392 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2254178524017334
Batch: 15/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885996.361515999 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1592885996.588037014 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002131441840901971
:::NVLOGv0.2.2 Tacotron2_PyT 1592885997.525962591 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1592885997.526387453 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 219659.2874904234
:::NVLOGv0.2.2 Tacotron2_PyT 1592885997.526738882 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1654412746429443
Batch: 16/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885997.529330254 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1592885997.746757746 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002200016751885414
:::NVLOGv0.2.2 Tacotron2_PyT 1592885998.632113218 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1592885998.632565737 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 232003.4346492935
:::NVLOGv0.2.2 Tacotron2_PyT 1592885998.632923365 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1034319400787354
Batch: 17/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885998.635436535 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1592885998.905477285 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002144054975360632
:::NVLOGv0.2.2 Tacotron2_PyT 1592885999.805466652 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1592885999.805893898 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 218715.78159176192
:::NVLOGv0.2.2 Tacotron2_PyT 1592885999.806267738 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.170468807220459
Batch: 18/19 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592885999.808786869 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1592886000.087579966 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018637722823768854
:::NVLOGv0.2.2 Tacotron2_PyT 1592886000.980266809 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1592886000.980656862 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 218444.53368781123
:::NVLOGv0.2.2 Tacotron2_PyT 1592886000.981009245 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.171922206878662
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.250952244 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.252436399 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 126383.12578445095
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.253852367 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 204851.6482348566
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.254644394 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021789486728314507
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.255424738 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 38.48615050315857
:::NVLOGv0.2.2 Tacotron2_PyT 1592886001.256178617 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1592886002.977650166 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.00319849606603384
:::NVLOGv0.2.2 Tacotron2_PyT 1592886002.979060411 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1592886005.740075350 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886005.838034868 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592886006.036552429 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002393897157162428
:::NVLOGv0.2.2 Tacotron2_PyT 1592886006.934494972 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1592886006.934929609 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 233259.36118491227
:::NVLOGv0.2.2 Tacotron2_PyT 1592886006.935321331 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0974907875061035
Batch: 1/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886006.938106060 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886007.229240417 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020703275222331285
:::NVLOGv0.2.2 Tacotron2_PyT 1592886008.119582653 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886008.119971991 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 216552.725418734
:::NVLOGv0.2.2 Tacotron2_PyT 1592886008.120329142 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1821601390838623
Batch: 2/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886008.123047590 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1592886008.311899424 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00174442189745605
:::NVLOGv0.2.2 Tacotron2_PyT 1592886009.201681137 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1592886009.202174187 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 237172.24125995688
:::NVLOGv0.2.2 Tacotron2_PyT 1592886009.202537775 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0793843269348145
Batch: 3/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886009.204758883 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1592886009.473788023 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0016466000815853477
:::NVLOGv0.2.2 Tacotron2_PyT 1592886010.362035513 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1592886010.362466097 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 221086.10759475426
:::NVLOGv0.2.2 Tacotron2_PyT 1592886010.362823963 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1579198837280273
Batch: 4/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886010.365567684 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1592886010.598247528 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021550015080720186
:::NVLOGv0.2.2 Tacotron2_PyT 1592886011.492501974 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1592886011.492903471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 227050.12205292511
:::NVLOGv0.2.2 Tacotron2_PyT 1592886011.493266344 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1275043487548828
Batch: 5/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886011.495664835 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1592886011.731529236 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024474277161061764
:::NVLOGv0.2.2 Tacotron2_PyT 1592886012.621094227 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1592886012.621565104 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 227348.1829792568
:::NVLOGv0.2.2 Tacotron2_PyT 1592886012.621974230 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1260261535644531
Batch: 6/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886012.623932123 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1592886012.846842527 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019278776599094272
:::NVLOGv0.2.2 Tacotron2_PyT 1592886013.735953808 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1592886013.736359119 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 230095.0118021693
:::NVLOGv0.2.2 Tacotron2_PyT 1592886013.736747980 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.112583875656128
Batch: 7/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886013.739556551 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1592886013.922952414 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022846225183457136
:::NVLOGv0.2.2 Tacotron2_PyT 1592886014.812361717 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1592886014.812780857 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 238475.05926108704
:::NVLOGv0.2.2 Tacotron2_PyT 1592886014.813134670 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0734875202178955
Batch: 8/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886014.815796137 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1592886015.071816206 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020782679785043
:::NVLOGv0.2.2 Tacotron2_PyT 1592886015.961764097 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1592886015.962182999 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 223282.4894871877
:::NVLOGv0.2.2 Tacotron2_PyT 1592886015.962561846 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1465296745300293
Batch: 9/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886015.965170145 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1592886016.203543186 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019667886663228273
:::NVLOGv0.2.2 Tacotron2_PyT 1592886017.096661568 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1592886017.097156048 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 226125.93652125422
:::NVLOGv0.2.2 Tacotron2_PyT 1592886017.097549677 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1321125030517578
Batch: 10/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886017.100346327 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1592886017.313646317 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0027258219197392464
:::NVLOGv0.2.2 Tacotron2_PyT 1592886018.202195883 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1592886018.202593327 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 232218.2355475353
:::NVLOGv0.2.2 Tacotron2_PyT 1592886018.202950001 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1024112701416016
Batch: 11/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886018.205295801 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1592886018.404741287 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017215474508702755
:::NVLOGv0.2.2 Tacotron2_PyT 1592886019.287745237 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1592886019.288147926 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 236379.34401948552
:::NVLOGv0.2.2 Tacotron2_PyT 1592886019.288517475 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0830049514770508
Batch: 12/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886019.290981054 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1592886019.530570507 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002091999165713787
:::NVLOGv0.2.2 Tacotron2_PyT 1592886020.422281742 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1592886020.422723532 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 226170.9475702789
:::NVLOGv0.2.2 Tacotron2_PyT 1592886020.423084021 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1318871974945068
Batch: 13/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886020.425678253 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1592886020.723047018 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022107765544205904
:::NVLOGv0.2.2 Tacotron2_PyT 1592886021.611969471 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1592886021.612390757 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 215690.0676352957
:::NVLOGv0.2.2 Tacotron2_PyT 1592886021.612750292 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1868882179260254
Batch: 14/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886021.615520239 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1592886021.816884279 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019041582709178329
:::NVLOGv0.2.2 Tacotron2_PyT 1592886022.704083443 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1592886022.704492092 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235029.22461544658
:::NVLOGv0.2.2 Tacotron2_PyT 1592886022.704826355 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.089226245880127
Batch: 15/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886022.707404137 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1592886022.879041910 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018707734998315573
:::NVLOGv0.2.2 Tacotron2_PyT 1592886023.767577648 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 15
:::NVLOGv0.2.2 Tacotron2_PyT 1592886023.767966747 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 241319.52701686788
:::NVLOGv0.2.2 Tacotron2_PyT 1592886023.768316746 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.0608341693878174
Batch: 16/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886023.770481825 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1592886024.057824373 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022908186074346304
:::NVLOGv0.2.2 Tacotron2_PyT 1592886024.940138102 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 16
:::NVLOGv0.2.2 Tacotron2_PyT 1592886024.940530539 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 218747.99692538308
:::NVLOGv0.2.2 Tacotron2_PyT 1592886024.940877199 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1702964305877686
Batch: 17/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886024.942514896 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1592886025.234456778 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00276343640871346
:::NVLOGv0.2.2 Tacotron2_PyT 1592886026.119688272 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 17
:::NVLOGv0.2.2 Tacotron2_PyT 1592886026.120157719 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 217375.34585465348
:::NVLOGv0.2.2 Tacotron2_PyT 1592886026.120521545 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1776864528656006
Batch: 18/19 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886026.125451088 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1592886026.327180147 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022792809177190065
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.277257442 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 18
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.277739763 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 221977.13912651048
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.278116703 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.1532719135284424
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.334409475 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.334829092 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 225236.94766169452
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.335182905 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 227650.2666249313
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.335543633 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021354655526872528
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.335891962 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 21.595036029815674
:::NVLOGv0.2.2 Tacotron2_PyT 1592886027.336235046 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.210820436 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0008968101465143263
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.211473465 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.212758541 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 118.18649578094482
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.213107824 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 118.18649578094482
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.213509798 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 126.04614067077637
:::NVLOGv0.2.2 Tacotron2_PyT 1592886028.213863850 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
