:::NVLOGv0.2.2 Tacotron2_PyT 1593626849.853828907 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593626849.881322861 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 80, "name": "Intel(R) Xeon(R) Gold 6230 CPU @ 2.10GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593626849.900484085 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "754G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1593626850.148371458 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.82", "num": 2, "name": ["GeForce RTX 2080 Ti", "GeForce RTX 2080 Ti"], "mem": ["11019 MiB", "11019 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1593626850.156676054 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "Tacotron2", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": false, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 1e-06, "grad_clip_thresh": 1.0, "batch_size": 36, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "mask_padding": false, "n_mel_channels": 80, "n_symbols": 148, "symbols_embedding_dim": 512, "encoder_kernel_size": 5, "encoder_n_convolutions": 3, "encoder_embedding_dim": 512, "n_frames_per_step": 1, "decoder_rnn_dim": 1024, "prenet_dim": 256, "max_decoder_steps": 2000, "gate_threshold": 0.5, "p_attention_dropout": 0.1, "p_decoder_dropout": 0.1, "decoder_no_early_stopping": false, "attention_rnn_dim": 1024, "attention_dim": 128, "attention_location_n_filters": 32, "attention_location_kernel_size": 31, "postnet_embedding_dim": 512, "postnet_kernel_size": 5, "postnet_n_convolutions": 5}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1593626851.274742603 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1593626858.971095800 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1593626858.977079391 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626859.824888229 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626863.772678137 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 44.28813552856445
:::NVLOGv0.2.2 Tacotron2_PyT 1593626865.314467669 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626865.315238714 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 6885.394883024279
:::NVLOGv0.2.2 Tacotron2_PyT 1593626865.315750360 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.4910430908203125
Batch: 1/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626865.323290586 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626866.272554159 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.34122848510742
:::NVLOGv0.2.2 Tacotron2_PyT 1593626867.743269444 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626867.744191408 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16642.45384359481
:::NVLOGv0.2.2 Tacotron2_PyT 1593626867.744535923 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.42091703414917
Batch: 2/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626867.749623537 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593626868.712316513 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.18470764160156
:::NVLOGv0.2.2 Tacotron2_PyT 1593626870.172916651 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593626870.173949003 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16706.899992052808
:::NVLOGv0.2.2 Tacotron2_PyT 1593626870.174715042 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4240283966064453
Batch: 3/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626870.178955317 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593626871.087227106 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.55742645263672
:::NVLOGv0.2.2 Tacotron2_PyT 1593626872.545201063 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593626872.546968460 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17297.366392054755
:::NVLOGv0.2.2 Tacotron2_PyT 1593626872.547984123 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3670077323913574
Batch: 4/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626872.553570986 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593626873.410499334 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.059181213378906
:::NVLOGv0.2.2 Tacotron2_PyT 1593626874.860407352 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593626874.861524105 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 18028.928604211393
:::NVLOGv0.2.2 Tacotron2_PyT 1593626874.863035917 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.30751371383667
Batch: 5/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626874.868741274 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593626875.723802328 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.314945220947266
:::NVLOGv0.2.2 Tacotron2_PyT 1593626877.193090200 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593626877.194561958 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17722.314949195043
:::NVLOGv0.2.2 Tacotron2_PyT 1593626877.195647478 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3250348567962646
Batch: 6/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626877.201057196 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593626878.078393698 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.62333679199219
:::NVLOGv0.2.2 Tacotron2_PyT 1593626879.552293539 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593626879.553352118 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17882.305485531157
:::NVLOGv0.2.2 Tacotron2_PyT 1593626879.553954601 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3517661094665527
Batch: 7/8 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626879.560202599 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593626880.373418570 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.200355529785156
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.824664354 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.827215195 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17751.708222014215
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.828651667 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.264908790588379
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.935795784 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.937563658 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 14137.620176773049
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.938273907 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 16114.67154645981
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.938786745 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.82116460800171
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.939287901 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 22.960512161254883
:::NVLOGv0.2.2 Tacotron2_PyT 1593626881.939778090 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1593626884.357543230 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.01598358154297
:::NVLOGv0.2.2 Tacotron2_PyT 1593626884.358545065 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626885.036864996 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626885.908353806 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626886.877501011 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.206764221191406
:::NVLOGv0.2.2 Tacotron2_PyT 1593626888.439973354 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1593626888.441274166 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15649.933123380231
:::NVLOGv0.2.2 Tacotron2_PyT 1593626888.443160534 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5343878269195557
Batch: 1/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626888.451704741 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626889.402589321 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 45.996212005615234
:::NVLOGv0.2.2 Tacotron2_PyT 1593626890.936769009 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626890.938031197 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16013.948034034782
:::NVLOGv0.2.2 Tacotron2_PyT 1593626890.939301491 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4859578609466553
Batch: 2/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626890.946730852 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593626891.816047907 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.750938415527344
:::NVLOGv0.2.2 Tacotron2_PyT 1593626893.425736904 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1593626893.428668499 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16494.86215463574
:::NVLOGv0.2.2 Tacotron2_PyT 1593626893.430042505 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.479923725128174
Batch: 3/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626893.437280416 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593626894.360735178 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.1536979675293
:::NVLOGv0.2.2 Tacotron2_PyT 1593626895.996832609 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1593626895.998584986 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 15705.910151104486
:::NVLOGv0.2.2 Tacotron2_PyT 1593626895.999738932 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5605647563934326
Batch: 4/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626896.006670475 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593626896.906414270 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 50.428184509277344
:::NVLOGv0.2.2 Tacotron2_PyT 1593626898.424103975 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1593626898.426150799 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 17496.56057914853
:::NVLOGv0.2.2 Tacotron2_PyT 1593626898.427613020 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4184181690216064
Batch: 5/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626898.434385061 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593626899.372613430 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.50531768798828
:::NVLOGv0.2.2 Tacotron2_PyT 1593626900.937696218 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1593626900.940050840 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16054.130457237901
:::NVLOGv0.2.2 Tacotron2_PyT 1593626900.941371918 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.5043399333953857
Batch: 6/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626900.948404551 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593626901.844199419 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.13251495361328
:::NVLOGv0.2.2 Tacotron2_PyT 1593626903.375611544 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1593626903.376892090 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16679.21991943615
:::NVLOGv0.2.2 Tacotron2_PyT 1593626903.378452539 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.42781138420105
Batch: 7/8 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626903.383561373 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593626904.286933899 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.257476806640625
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.826135635 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.827702761 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 16752.808238628462
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.829739571 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.442993402481079
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.944659948 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.946050167 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 15521.669500450256
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.947245121 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 16355.921582200785
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.947845697 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.42888832092285
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.948350191 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 20.9085111618042
:::NVLOGv0.2.2 Tacotron2_PyT 1593626905.948839903 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.305600882 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.029022216796875
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.306573391 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.307597399 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 57.032222270965576
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.307910681 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 57.032222270965576
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.308238506 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 58.541943311691284
:::NVLOGv0.2.2 Tacotron2_PyT 1593626908.308518648 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
