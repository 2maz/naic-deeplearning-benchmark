=> creating model '('resnet50', 'classic')'
Version: {'net': <class 'image_classification.resnet.ResNet'>, 'block': <class 'image_classification.resnet.Bottleneck'>, 'layers': [3, 4, 6, 3], 'widths': [64, 128, 256, 512], 'expansion': 4, 'num_classes': 1000}
Config: {'conv': <class 'torch.nn.modules.conv.Conv2d'>, 'conv_init': 'fan_out', 'nonlinearity': 'relu', 'last_bn_0_init': False, 'activation': <function <lambda> at 0x7fd6cabaa840>}
read 1281167 files from 1000 directories
read 50000 files from 1000 directories
DLL 2020-06-18 08:04:26.260174 - PARAMETER data : /data/imagenet  data_backend : dali-cpu  arch : resnet50  model_config : classic  workers : 5  epochs : 2  batch_size : 928  optimizer_batch_size : -1  lr : 0.1  lr_schedule : step  warmup : 0  label_smoothing : 0.0  mixup : 0.0  momentum : 0.9  weight_decay : 0.0001  bn_weight_decay : False  nesterov : False  print_freq : 1  resume :   pretrained_weights :   fp16 : True  static_loss_scale : 256.0  dynamic_loss_scale : False  prof : 100  amp : False  seed : None  gather_checkpoints : False  raport_file : benchmark.json  evaluate : False  training_only : True  save_checkpoints : True  workspace : ./  distributed : True  local_rank : 0  gpu : 0  world_size : 4 
 ! Weight decay NOT applied to BN parameters 
98
63
Warning:  FP16_Optimizer is deprecated and dangerous, and will be deleted soon.  If it still works, you're probably getting lucky.  For mixed precision, use the documented API https://nvidia.github.io/apex/amp.html, with opt_level=O1.
Traceback (most recent call last):
  File "./main.py", line 475, in <module>
    main(args)
  File "./main.py", line 460, in main
    checkpoint_dir=args.workspace)
  File "/workspace/examples/resnet50v1.5/image_classification/training.py", line 492, in train_loop
    batch_size_multiplier=batch_size_multiplier)
  File "/workspace/examples/resnet50v1.5/image_classification/training.py", line 318, in train
    loss = step(input, target, optimizer_step=optimizer_step)
  File "/workspace/examples/resnet50v1.5/image_classification/training.py", line 230, in _step
    loss, output = model_and_loss(input_var, target_var)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/examples/resnet50v1.5/image_classification/training.py", line 86, in forward
    output = self.model(data)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/apex/parallel/distributed.py", line 560, in forward
    result = self.module(*inputs, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/examples/resnet50v1.5/image_classification/resnet.py", line 237, in forward
    x = self.layer4(x)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py", line 100, in forward
    input = module(input)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/workspace/examples/resnet50v1.5/image_classification/resnet.py", line 173, in forward
    out = self.conv3(out)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py", line 532, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 345, in forward
    return self.conv2d_forward(input, self.weight)
  File "/opt/conda/lib/python3.6/site-packages/torch/nn/modules/conv.py", line 342, in conv2d_forward
    self.padding, self.dilation, self.groups)
RuntimeError: CUDA out of memory. Tried to allocate 4.08 GiB (GPU 1; 47.46 GiB total capacity; 37.63 GiB already allocated; 4.08 GiB free; 37.96 GiB reserved in total by PyTorch)
['/opt/conda/bin/python', '-u', './main.py', '/data/imagenet', '--arch', 'resnet50', '--fp16', '--static-loss-scale', '256', '--epochs', '2', '--prof', '100', '--batch-size', '928', '--raport-file', 'benchmark.json', '--print-freq', '1', '--training-only']
['/opt/conda/bin/python', '-u', './main.py', '/data/imagenet', '--arch', 'resnet50', '--fp16', '--static-loss-scale', '256', '--epochs', '2', '--prof', '100', '--batch-size', '928', '--raport-file', 'benchmark.json', '--print-freq', '1', '--training-only']
['/opt/conda/bin/python', '-u', './main.py', '/data/imagenet', '--arch', 'resnet50', '--fp16', '--static-loss-scale', '256', '--epochs', '2', '--prof', '100', '--batch-size', '928', '--raport-file', 'benchmark.json', '--print-freq', '1', '--training-only']
['/opt/conda/bin/python', '-u', './main.py', '/data/imagenet', '--arch', 'resnet50', '--fp16', '--static-loss-scale', '256', '--epochs', '2', '--prof', '100', '--batch-size', '928', '--raport-file', 'benchmark.json', '--print-freq', '1', '--training-only']
DONE!
