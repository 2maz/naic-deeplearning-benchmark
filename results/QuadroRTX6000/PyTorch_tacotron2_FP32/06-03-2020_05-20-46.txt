:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.133294582 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.147181749 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 24, "name": "Intel(R) Core(TM) i9-7920X CPU @ 2.90GHz"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.162030220 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "62G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.314321041 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.44", "num": 1, "name": ["Quadro RTX 6000"], "mem": ["24217 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.322077751 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "Tacotron2", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 1, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": false, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 1e-06, "grad_clip_thresh": 1.0, "batch_size": 80, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 1, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "mask_padding": false, "n_mel_channels": 80, "n_symbols": 148, "symbols_embedding_dim": 512, "encoder_kernel_size": 5, "encoder_n_convolutions": 3, "encoder_embedding_dim": 512, "n_frames_per_step": 1, "decoder_rnn_dim": 1024, "prenet_dim": 256, "max_decoder_steps": 2000, "gate_threshold": 0.5, "p_attention_dropout": 0.1, "p_decoder_dropout": 0.1, "decoder_no_early_stopping": false, "attention_rnn_dim": 1024, "attention_dim": 128, "attention_location_n_filters": 32, "attention_location_kernel_size": 31, "postnet_embedding_dim": 512, "postnet_kernel_size": 5, "postnet_n_convolutions": 5}
:::NVLOGv0.2.2 Tacotron2_PyT 1583472048.323532820 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1583472052.803586960 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1583472052.804419041 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472054.551390409 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472056.849018335 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.723114013671875
:::NVLOGv0.2.2 Tacotron2_PyT 1583472061.106925011 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472061.107445955 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 6997.860944635292
:::NVLOGv0.2.2 Tacotron2_PyT 1583472061.107869864 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 6.557861089706421
Batch: 1/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472061.115319967 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583472061.925049543 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 48.79445266723633
:::NVLOGv0.2.2 Tacotron2_PyT 1583472066.073190451 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1583472066.074084282 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 9402.22839961198
:::NVLOGv0.2.2 Tacotron2_PyT 1583472066.074530602 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.958611726760864
Batch: 2/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472066.080114126 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583472066.906187534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 49.616859436035156
:::NVLOGv0.2.2 Tacotron2_PyT 1583472071.019562960 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1583472071.020725965 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 9641.974855816032
:::NVLOGv0.2.2 Tacotron2_PyT 1583472071.022576094 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.940170526504517
Batch: 3/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472071.029594421 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583472071.894655466 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 44.36491012573242
:::NVLOGv0.2.2 Tacotron2_PyT 1583472076.295318127 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1583472076.296861410 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 8158.259641558991
:::NVLOGv0.2.2 Tacotron2_PyT 1583472076.299140930 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.266319274902344
Batch: 4/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472076.306553602 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583472077.148194313 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 44.18880081176758
:::NVLOGv0.2.2 Tacotron2_PyT 1583472081.416707516 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1583472081.418606043 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 8433.588967331223
:::NVLOGv0.2.2 Tacotron2_PyT 1583472081.420367718 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.110872745513916
Batch: 5/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472081.426857233 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583472082.236612797 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 46.951515197753906
:::NVLOGv0.2.2 Tacotron2_PyT 1583472086.165222645 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1583472086.166863441 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 9320.157382162786
:::NVLOGv0.2.2 Tacotron2_PyT 1583472086.168854952 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.738868474960327
Batch: 6/7 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472086.181723118 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583472087.016832113 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 47.746971130371094
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.248818636 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.250834227 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 9112.267801302598
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.253716230 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 5.068002939224243
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.345289230 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.346545935 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 8213.483570775816
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.347697735 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 8723.762570345558
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.348258018 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 47.05523191179548
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.348682165 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 38.541624546051025
:::NVLOGv0.2.2 Tacotron2_PyT 1583472091.349127769 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472094.520588398 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 50.36447525024414
:::NVLOGv0.2.2 Tacotron2_PyT 1583472094.523120642 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_Tacotron2_0
:::NVLOGv0.2.2 Tacotron2_PyT 1583472095.430630922 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 47.105555295944214
:::NVLOGv0.2.2 Tacotron2_PyT 1583472095.432206392 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 47.105555295944214
:::NVLOGv0.2.2 Tacotron2_PyT 1583472095.433843374 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 47.40138268470764
:::NVLOGv0.2.2 Tacotron2_PyT 1583472095.435173035 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
