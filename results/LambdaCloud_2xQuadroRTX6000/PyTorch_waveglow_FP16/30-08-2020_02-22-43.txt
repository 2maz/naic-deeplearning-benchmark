:::NVLOGv0.2.2 Tacotron2_PyT 1598754167.092385054 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1598754167.106802464 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 12, "name": "AMD EPYC Processor (with IBPB)"}
:::NVLOGv0.2.2 Tacotron2_PyT 1598754167.123989105 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "90G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1598754167.462875843 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "450.57", "num": 2, "name": ["Quadro RTX 6000", "Quadro RTX 6000"], "mem": ["24220 MiB", "24220 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1598754167.467758656 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": true, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 20, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 2, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1598754168.559269667 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.

Defaults for this optimization level are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
Processing user overrides (additional kwargs that are not None)...
After processing overrides, optimization options are:
enabled                : True
opt_level              : O1
cast_model_type        : None
patch_torch_functions  : True
keep_batchnorm_fp32    : None
master_weights         : None
loss_scale             : dynamic
:::NVLOGv0.2.2 Tacotron2_PyT 1598754821.021929026 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1598754821.022577047 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754821.768835783 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754826.938702583 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001888026250526309
:::NVLOGv0.2.2 Tacotron2_PyT 1598754829.931350946 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754829.931964636 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 39198.822321510845
:::NVLOGv0.2.2 Tacotron2_PyT 1598754829.932446957 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 8.16351056098938
Batch: 1/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754829.936139107 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754830.431242943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002142892684787512
:::NVLOGv0.2.2 Tacotron2_PyT 1598754832.297613621 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754832.298218727 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135465.73315988205
:::NVLOGv0.2.2 Tacotron2_PyT 1598754832.309335709 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3622210025787354
Batch: 2/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754832.312773705 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598754832.802938700 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002379964105784893
:::NVLOGv0.2.2 Tacotron2_PyT 1598754834.678133488 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598754834.678729534 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135240.7158226255
:::NVLOGv0.2.2 Tacotron2_PyT 1598754834.679251909 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3661513328552246
Batch: 3/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754834.683330297 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598754835.186918259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0017017880454659462
:::NVLOGv0.2.2 Tacotron2_PyT 1598754837.047912121 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598754837.048575401 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135279.23711781608
:::NVLOGv0.2.2 Tacotron2_PyT 1598754837.049118280 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3654775619506836
Batch: 4/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754837.053291321 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598754837.547010422 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00247233547270298
:::NVLOGv0.2.2 Tacotron2_PyT 1598754839.410350323 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598754839.411018133 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135718.94236529095
:::NVLOGv0.2.2 Tacotron2_PyT 1598754839.411606073 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.357813835144043
Batch: 5/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754839.415729761 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598754839.909776688 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002312874188646674
:::NVLOGv0.2.2 Tacotron2_PyT 1598754841.777633190 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598754841.778293610 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135424.8919443023
:::NVLOGv0.2.2 Tacotron2_PyT 1598754841.779164076 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.362933397293091
Batch: 6/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754841.786068678 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598754842.281996965 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002190147526562214
:::NVLOGv0.2.2 Tacotron2_PyT 1598754844.155227184 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598754844.155920029 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135006.70719685845
:::NVLOGv0.2.2 Tacotron2_PyT 1598754844.160480022 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3702526092529297
Batch: 7/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754844.167742014 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598754844.672898769 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024599339812994003
:::NVLOGv0.2.2 Tacotron2_PyT 1598754846.534645796 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598754846.535418034 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135157.43711301565
:::NVLOGv0.2.2 Tacotron2_PyT 1598754846.537152290 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3676092624664307
Batch: 8/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754846.549268007 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598754847.042891264 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023660229053348303
:::NVLOGv0.2.2 Tacotron2_PyT 1598754848.894406557 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598754848.895081282 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 136403.99763367276
:::NVLOGv0.2.2 Tacotron2_PyT 1598754848.895660400 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3459722995758057
Batch: 9/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754848.899395943 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598754849.400213242 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025194070767611265
:::NVLOGv0.2.2 Tacotron2_PyT 1598754851.300081253 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598754851.300622940 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133256.32360210788
:::NVLOGv0.2.2 Tacotron2_PyT 1598754851.301141500 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4013869762420654
Batch: 10/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754851.305118561 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598754851.808667183 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018097256543114781
:::NVLOGv0.2.2 Tacotron2_PyT 1598754853.679848433 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598754853.680437326 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134714.4065454926
:::NVLOGv0.2.2 Tacotron2_PyT 1598754853.680923700 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3753955364227295
Batch: 11/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754853.684641838 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598754854.181067705 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021030548959970474
:::NVLOGv0.2.2 Tacotron2_PyT 1598754856.054718256 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598754856.055370808 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134970.2410821293
:::NVLOGv0.2.2 Tacotron2_PyT 1598754856.055857420 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3708930015563965
Batch: 12/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754856.062158823 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598754856.558957338 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001963155111297965
:::NVLOGv0.2.2 Tacotron2_PyT 1598754858.424708366 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598754858.425310135 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135377.60268653746
:::NVLOGv0.2.2 Tacotron2_PyT 1598754858.425781488 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3637588024139404
Batch: 13/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754858.432061911 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598754858.927695036 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024119094014167786
:::NVLOGv0.2.2 Tacotron2_PyT 1598754860.797085762 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598754860.797863483 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135269.72061724027
:::NVLOGv0.2.2 Tacotron2_PyT 1598754860.798353434 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3656439781188965
Batch: 14/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754860.805701017 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598754861.363605976 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002094588242471218
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.242840052 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.243622303 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 131251.72770760898
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.244186878 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.438063144683838
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.415920973 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.416986704 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 113223.50682841029
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.417940855 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 128515.76712773941
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.418910980 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021877217028910914
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.420070410 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 42.394023418426514
:::NVLOGv0.2.2 Tacotron2_PyT 1598754863.421102047 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1598754865.365464687 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0025176960043609142
:::NVLOGv0.2.2 Tacotron2_PyT 1598754865.366848230 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754868.048021317 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754868.290511370 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754868.836349249 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018817782402038574
:::NVLOGv0.2.2 Tacotron2_PyT 1598754870.726776600 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1598754870.727499723 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 131275.75946493514
:::NVLOGv0.2.2 Tacotron2_PyT 1598754870.728124142 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4376168251037598
Batch: 1/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754870.733134985 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754871.230961323 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002596199745312333
:::NVLOGv0.2.2 Tacotron2_PyT 1598754873.104991436 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754873.105743170 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134842.34470916179
:::NVLOGv0.2.2 Tacotron2_PyT 1598754873.106354475 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3731417655944824
Batch: 2/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754873.117457151 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598754873.650569201 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002002512104809284
:::NVLOGv0.2.2 Tacotron2_PyT 1598754875.612877607 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1598754875.613641024 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 128167.81004563489
:::NVLOGv0.2.2 Tacotron2_PyT 1598754875.614279985 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.4967267513275146
Batch: 3/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754875.616818905 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598754876.112441063 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022585277911275625
:::NVLOGv0.2.2 Tacotron2_PyT 1598754877.999004126 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1598754877.999652386 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134290.9165495195
:::NVLOGv0.2.2 Tacotron2_PyT 1598754878.000145912 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3828864097595215
Batch: 4/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754878.002900839 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598754878.515798807 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002544852439314127
:::NVLOGv0.2.2 Tacotron2_PyT 1598754880.397491693 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1598754880.398086071 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133584.69683862114
:::NVLOGv0.2.2 Tacotron2_PyT 1598754880.398624420 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.39548397064209
Batch: 5/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754880.401275396 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598754880.899559498 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019317991100251675
:::NVLOGv0.2.2 Tacotron2_PyT 1598754882.756108046 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1598754882.756722450 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135848.5903268741
:::NVLOGv0.2.2 Tacotron2_PyT 1598754882.757676840 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3555636405944824
Batch: 6/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754882.760624170 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598754883.258972883 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019474418368190527
:::NVLOGv0.2.2 Tacotron2_PyT 1598754885.130458832 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1598754885.131052494 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134976.83773542402
:::NVLOGv0.2.2 Tacotron2_PyT 1598754885.131583691 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.370777130126953
Batch: 7/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754885.145878315 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598754885.643236637 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001770850969478488
:::NVLOGv0.2.2 Tacotron2_PyT 1598754887.536372423 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1598754887.536977053 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133825.67231039944
:::NVLOGv0.2.2 Tacotron2_PyT 1598754887.537478209 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3911705017089844
Batch: 8/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754887.551279068 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598754888.062254190 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021037831902503967
:::NVLOGv0.2.2 Tacotron2_PyT 1598754889.932329178 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1598754889.933057308 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134343.4465973258
:::NVLOGv0.2.2 Tacotron2_PyT 1598754889.933572292 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3819546699523926
Batch: 9/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754889.938835382 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598754890.437630415 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019362198654562235
:::NVLOGv0.2.2 Tacotron2_PyT 1598754892.303505421 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1598754892.304188013 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135256.40249165415
:::NVLOGv0.2.2 Tacotron2_PyT 1598754892.304726124 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3658769130706787
Batch: 10/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754892.309525490 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598754892.825093269 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0020841953810304403
:::NVLOGv0.2.2 Tacotron2_PyT 1598754894.718502045 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1598754894.719102383 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 132763.20092332424
:::NVLOGv0.2.2 Tacotron2_PyT 1598754894.720123053 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.410306453704834
Batch: 11/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754894.724534035 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598754895.228852749 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002688737353309989
:::NVLOGv0.2.2 Tacotron2_PyT 1598754897.106783390 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1598754897.107439280 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134261.24206855442
:::NVLOGv0.2.2 Tacotron2_PyT 1598754897.107914686 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.383413076400757
Batch: 12/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754897.110616684 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598754897.611610174 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0015170221449807286
:::NVLOGv0.2.2 Tacotron2_PyT 1598754899.492872238 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1598754899.493469715 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 134283.27166489963
:::NVLOGv0.2.2 Tacotron2_PyT 1598754899.493944168 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3830220699310303
Batch: 13/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754899.496471405 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598754899.993700266 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002328387927263975
:::NVLOGv0.2.2 Tacotron2_PyT 1598754901.862696648 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1598754901.863376856 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 135200.11910544397
:::NVLOGv0.2.2 Tacotron2_PyT 1598754901.863858938 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3668618202209473
Batch: 14/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754901.866284847 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598754902.365453243 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002614074619486928
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.261581659 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.262166262 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 133561.67306191984
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.262651682 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 2.3958969116210938
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.308560610 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.309079409 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 132373.04867510995
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.309508324 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 133765.46559291283
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.309943438 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021470921812579034
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.310377359 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 36.261157751083374
:::NVLOGv0.2.2 Tacotron2_PyT 1598754904.310808182 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.765443563 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0020478712394833565
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.766761065 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.768981218 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 737.208756685257
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.769461393 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 737.208756685257
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.769984007 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 738.7961146831512
:::NVLOGv0.2.2 Tacotron2_PyT 1598754905.770442724 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
