:::NVLOGv0.2.2 Tacotron2_PyT 1587239046.690055847 (/workspace/examples/tacotron2/dllogger/logger.py:279) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1587239046.710148573 (/workspace/examples/tacotron2/dllogger/logger.py:251) cpu_info: {"num": 92, "name": "Intel Xeon Processor (Skylake, IBRS)"}
:::NVLOGv0.2.2 Tacotron2_PyT 1587239046.726407528 (/workspace/examples/tacotron2/dllogger/logger.py:251) mem_info: {"ram": "440G"}
:::NVLOGv0.2.2 Tacotron2_PyT 1587239072.501914263 (/workspace/examples/tacotron2/dllogger/logger.py:251) gpu_info: {"driver_version": "440.64", "num": 8, "name": ["Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB", "Tesla V100-SXM2-16GB"], "mem": ["16160 MiB", "16160 MiB", "16160 MiB", "16160 MiB", "16160 MiB", "16160 MiB", "16160 MiB", "16160 MiB"]}
:::NVLOGv0.2.2 Tacotron2_PyT 1587239072.508061409 (/workspace/examples/tacotron2/dllogger/logger.py:251) args: {"output_directory": "./", "dataset_path": "/data/tacotron2/LJSpeech-1.1", "model_name": "WaveGlow", "log_file": "nvlog.json", "anneal_steps": null, "anneal_factor": 0.1, "epochs": 2, "epochs_per_checkpoint": 50, "checkpoint_path": "", "seed": 1234, "dynamic_loss_scaling": true, "amp_run": false, "cudnn_enabled": true, "cudnn_benchmark": true, "disable_uniform_initialize_bn_weight": false, "use_saved_learning_rate": false, "learning_rate": 0.0, "weight_decay": 0.0, "grad_clip_thresh": 65504.0, "batch_size": 5, "grad_clip": 5.0, "load_mel_from_disk": false, "training_files": "filelists/ljs_audio_text_train_subset_625_filelist.txt", "validation_files": "filelists/ljs_audio_text_val_filelist.txt", "text_cleaners": ["english_cleaners"], "max_wav_value": 32768.0, "sampling_rate": 22050, "filter_length": 1024, "hop_length": 256, "win_length": 1024, "mel_fmin": 0.0, "mel_fmax": 8000.0, "rank": 0, "world_size": 8, "dist_url": "tcp://localhost:23456", "group_name": "group_name", "dist_backend": "nccl", "n_mel_channels": 80, "flows": 12, "groups": 8, "early_every": 4, "early_size": 2, "sigma": 1.0, "segment_length": 8000, "wn_kernel_size": 3, "wn_channels": 512, "wn_layers": 8}
Initializing Distributed
Done initializing distributed
:::NVLOGv0.2.2 Tacotron2_PyT 1587239076.751036406 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_start
:::NVLOGv0.2.2 Tacotron2_PyT 1587239144.636317730 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_loop
:::NVLOGv0.2.2 Tacotron2_PyT 1587239144.645243645 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 0
Batch: 0/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239145.059071779 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239154.591361284 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022846923675388098
:::NVLOGv0.2.2 Tacotron2_PyT 1587239156.881455421 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239156.881983995 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 27061.456353599984
:::NVLOGv0.2.2 Tacotron2_PyT 1587239156.882372141 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 11.824936389923096
Batch: 1/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239156.886440039 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239160.593573332 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002489612437784672
:::NVLOGv0.2.2 Tacotron2_PyT 1587239161.490593910 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239161.491144896 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 69476.89719476197
:::NVLOGv0.2.2 Tacotron2_PyT 1587239161.491570711 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 4.605847597122192
Batch: 2/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239161.496407032 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1587239161.962945700 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0024867120664566755
:::NVLOGv0.2.2 Tacotron2_PyT 1587239162.807123661 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1587239162.807634830 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 243982.81511708355
:::NVLOGv0.2.2 Tacotron2_PyT 1587239162.808015108 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.311567783355713
Batch: 3/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239162.811518669 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1587239163.410519600 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018544277409091592
:::NVLOGv0.2.2 Tacotron2_PyT 1587239164.266634941 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1587239164.267229795 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 219809.90101344857
:::NVLOGv0.2.2 Tacotron2_PyT 1587239164.267646313 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.455803394317627
Batch: 4/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239164.271139860 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1587239164.740419388 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002346044173464179
:::NVLOGv0.2.2 Tacotron2_PyT 1587239165.646095276 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1587239165.646601915 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 232603.57333800098
:::NVLOGv0.2.2 Tacotron2_PyT 1587239165.647034645 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3757312297821045
Batch: 5/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239165.650604486 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1587239166.108635902 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00201231287792325
:::NVLOGv0.2.2 Tacotron2_PyT 1587239166.943095922 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1587239166.943585873 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 247420.95511414425
:::NVLOGv0.2.2 Tacotron2_PyT 1587239166.943974257 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2933423519134521
Batch: 6/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239166.947893858 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1587239167.599396706 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001866693259216845
:::NVLOGv0.2.2 Tacotron2_PyT 1587239168.509975195 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1587239168.510476828 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 204740.29865864004
:::NVLOGv0.2.2 Tacotron2_PyT 1587239168.510857105 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.562955617904663
Batch: 7/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239168.514409542 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1587239169.078503847 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0028150274883955717
:::NVLOGv0.2.2 Tacotron2_PyT 1587239169.935458660 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1587239169.935945988 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 225047.39791038728
:::NVLOGv0.2.2 Tacotron2_PyT 1587239169.936326504 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4219226837158203
Batch: 8/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239169.939743280 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1587239170.530511856 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002170907100662589
:::NVLOGv0.2.2 Tacotron2_PyT 1587239171.377237320 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1587239171.377727270 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222515.7302981466
:::NVLOGv0.2.2 Tacotron2_PyT 1587239171.378095388 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4381005764007568
Batch: 9/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239171.380879879 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1587239171.921534538 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001812916249036789
:::NVLOGv0.2.2 Tacotron2_PyT 1587239172.793243408 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1587239172.793732166 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 226470.55309898022
:::NVLOGv0.2.2 Tacotron2_PyT 1587239172.794082403 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.412987232208252
Batch: 10/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239172.796671391 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1587239173.430424929 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.00230410392396152
:::NVLOGv0.2.2 Tacotron2_PyT 1587239174.284764767 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1587239174.285254002 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 214907.91243419115
:::NVLOGv0.2.2 Tacotron2_PyT 1587239174.285613775 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4890098571777344
Batch: 11/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239174.288223743 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1587239174.929696560 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0018732835305854678
:::NVLOGv0.2.2 Tacotron2_PyT 1587239175.768374681 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1587239175.768886805 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 216059.69156482053
:::NVLOGv0.2.2 Tacotron2_PyT 1587239175.769243479 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.481072187423706
Batch: 12/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239175.772060633 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1587239176.305361509 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019272509962320328
:::NVLOGv0.2.2 Tacotron2_PyT 1587239177.151883125 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1587239177.152369261 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 231755.1910968032
:::NVLOGv0.2.2 Tacotron2_PyT 1587239177.152725935 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3807673454284668
Batch: 13/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239177.154752254 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1587239177.686194658 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0016329220961779356
:::NVLOGv0.2.2 Tacotron2_PyT 1587239178.516060829 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1587239178.516542196 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 234980.89675564357
:::NVLOGv0.2.2 Tacotron2_PyT 1587239178.516891956 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3618128299713135
Batch: 14/15 epoch 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239178.518886566 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1587239179.066361427 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0022173949982970953
:::NVLOGv0.2.2 Tacotron2_PyT 1587239179.896221876 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1587239179.896735430 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 232244.35385073264
:::NVLOGv0.2.2 Tacotron2_PyT 1587239179.897112846 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.377859115600586
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.162998199 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.163895130 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 135135.2603819238
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.164275408 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 203271.84158662564
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.164593935 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.0021396200871095063
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.164911032 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 35.5199670791626
:::NVLOGv0.2.2 Tacotron2_PyT 1587239180.165228367 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 0
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
/opt/conda/lib/python3.6/site-packages/torch/distributed/distributed_c10d.py:101: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  warnings.warn("torch.distributed.reduce_op is deprecated, please use "
:::NVLOGv0.2.2 Tacotron2_PyT 1587239184.202876091 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0018286327831447124
:::NVLOGv0.2.2 Tacotron2_PyT 1587239184.205341101 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 0
Saving model and optimizer state at epoch 0 to ./checkpoint_WaveGlow_0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239189.048476219 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_start: 1
Batch: 0/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239189.172450781 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239189.532492399 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023396003525704145
:::NVLOGv0.2.2 Tacotron2_PyT 1587239190.384612799 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 0
:::NVLOGv0.2.2 Tacotron2_PyT 1587239190.385111094 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 263241.33590472944
:::NVLOGv0.2.2 Tacotron2_PyT 1587239190.385483503 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.2156145572662354
Batch: 1/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239190.389090300 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239190.869174957 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0021198554895818233
:::NVLOGv0.2.2 Tacotron2_PyT 1587239191.700786829 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239191.701285601 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 243837.5173861164
:::NVLOGv0.2.2 Tacotron2_PyT 1587239191.701648712 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3123493194580078
Batch: 2/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239191.705703020 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1587239192.362500191 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019020591862499714
:::NVLOGv0.2.2 Tacotron2_PyT 1587239193.212637663 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 2
:::NVLOGv0.2.2 Tacotron2_PyT 1587239193.213120699 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 212247.64605437565
:::NVLOGv0.2.2 Tacotron2_PyT 1587239193.213941574 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.5076727867126465
Batch: 3/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239193.217807770 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1587239193.718509674 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002275104634463787
:::NVLOGv0.2.2 Tacotron2_PyT 1587239194.561829567 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 3
:::NVLOGv0.2.2 Tacotron2_PyT 1587239194.562335491 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 237980.98212169082
:::NVLOGv0.2.2 Tacotron2_PyT 1587239194.562717676 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3446452617645264
Batch: 4/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239194.566959620 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1587239195.163141727 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0019354233518242836
:::NVLOGv0.2.2 Tacotron2_PyT 1587239195.992927313 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 4
:::NVLOGv0.2.2 Tacotron2_PyT 1587239195.993429422 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 224299.65416960095
:::NVLOGv0.2.2 Tacotron2_PyT 1587239195.993778944 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4266629219055176
Batch: 5/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239195.997777462 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1587239196.507802963 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0026781675405800343
:::NVLOGv0.2.2 Tacotron2_PyT 1587239197.351757765 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 5
:::NVLOGv0.2.2 Tacotron2_PyT 1587239197.352242470 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 236181.1005817347
:::NVLOGv0.2.2 Tacotron2_PyT 1587239197.352622271 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3548924922943115
Batch: 6/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239197.359167337 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1587239197.930984259 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0023710329551249743
:::NVLOGv0.2.2 Tacotron2_PyT 1587239198.761244774 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 6
:::NVLOGv0.2.2 Tacotron2_PyT 1587239198.761912346 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 227900.4447716661
:::NVLOGv0.2.2 Tacotron2_PyT 1587239198.762470722 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4041218757629395
Batch: 7/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239198.765262127 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1587239199.283049583 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001934318570420146
:::NVLOGv0.2.2 Tacotron2_PyT 1587239200.125403643 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 7
:::NVLOGv0.2.2 Tacotron2_PyT 1587239200.126085520 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 235102.2787545359
:::NVLOGv0.2.2 Tacotron2_PyT 1587239200.126628637 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.361109733581543
Batch: 8/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239200.129062176 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1587239200.660506725 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002485816366970539
:::NVLOGv0.2.2 Tacotron2_PyT 1587239201.495413780 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 8
:::NVLOGv0.2.2 Tacotron2_PyT 1587239201.496079922 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 234086.82008897263
:::NVLOGv0.2.2 Tacotron2_PyT 1587239201.496640205 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3670141696929932
Batch: 9/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239201.499218702 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1587239202.041356564 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001850466593168676
:::NVLOGv0.2.2 Tacotron2_PyT 1587239202.897330523 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 9
:::NVLOGv0.2.2 Tacotron2_PyT 1587239202.898134947 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 228729.16998978864
:::NVLOGv0.2.2 Tacotron2_PyT 1587239202.898695946 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3990345001220703
Batch: 10/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239202.901409388 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1587239203.544686556 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.001964153256267309
:::NVLOGv0.2.2 Tacotron2_PyT 1587239204.415156126 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 10
:::NVLOGv0.2.2 Tacotron2_PyT 1587239204.415879488 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 211278.16322466749
:::NVLOGv0.2.2 Tacotron2_PyT 1587239204.416359663 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.5145909786224365
Batch: 11/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239204.418969154 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1587239205.004518986 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025357056874781847
:::NVLOGv0.2.2 Tacotron2_PyT 1587239205.856748343 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 11
:::NVLOGv0.2.2 Tacotron2_PyT 1587239205.857464552 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 222440.05725666208
:::NVLOGv0.2.2 Tacotron2_PyT 1587239205.857996702 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.4385898113250732
Batch: 12/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239205.860853672 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1587239206.349150658 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0025507055688649416
:::NVLOGv0.2.2 Tacotron2_PyT 1587239207.199066162 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 12
:::NVLOGv0.2.2 Tacotron2_PyT 1587239207.199780941 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 238942.28418946866
:::NVLOGv0.2.2 Tacotron2_PyT 1587239207.200300217 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.339235544204712
Batch: 13/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239207.202654839 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1587239207.730540037 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.002261250978335738
:::NVLOGv0.2.2 Tacotron2_PyT 1587239208.581237555 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 13
:::NVLOGv0.2.2 Tacotron2_PyT 1587239208.582004070 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 232033.40563106307
:::NVLOGv0.2.2 Tacotron2_PyT 1587239208.582512140 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3791117668151855
Batch: 14/15 epoch 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239208.584916592 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_start: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1587239209.139772892 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iteration_loss: 0.0027676504105329514
:::NVLOGv0.2.2 Tacotron2_PyT 1587239209.981203556 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_stop: 14
:::NVLOGv0.2.2 Tacotron2_PyT 1587239209.981764555 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_iter_items/sec: 229091.86121256542
:::NVLOGv0.2.2 Tacotron2_PyT 1587239209.982392073 (/workspace/examples/tacotron2/dllogger/logger.py:251) iter_time: 1.3968195915222168
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.029003382 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.029448032 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_items/sec: 228775.84804317544
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.029776096 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_items/sec: 231826.1814225092
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.030098200 (/workspace/examples/tacotron2/dllogger/logger.py:251) train_epoch_avg_loss: 0.002264754062828918
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.030414820 (/workspace/examples/tacotron2/dllogger/logger.py:251) epoch_time: 20.98123574256897
:::NVLOGv0.2.2 Tacotron2_PyT 1587239210.030730486 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_start: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.690994024 (/workspace/examples/tacotron2/dllogger/logger.py:251) val_iter_loss: 0.0026200611609965563
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.692804813 (/workspace/examples/tacotron2/dllogger/logger.py:251) eval_stop: 1
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.694853306 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 134.94282221794128
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.695656776 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_final
training time 134.94282221794128
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.696553469 (/workspace/examples/tacotron2/dllogger/logger.py:251) run_time: 165.1163079738617
:::NVLOGv0.2.2 Tacotron2_PyT 1587239211.697381258 (/workspace/examples/tacotron2/dllogger/logger.py:282) run_stop
DONE!
